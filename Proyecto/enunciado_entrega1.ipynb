{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.dii.uchile.cl/wp-content/uploads/2021/06/Magi%CC%81ster-en-Ciencia-de-Datos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos**\n",
    "\n",
    "### üë®‚Äçüè´üë©‚Äçüè´ Cuerpo Docente:\n",
    "\n",
    "- Profesores: Diego Cortez, Gabriel Iturra\n",
    "- Auxiliares: Melanie Pe√±a, Valentina Rojas\n",
    "- Ayudantes: Nicol√°s Cabello, Cristopher Urbina\n",
    "\n",
    "### üë®‚Äçüíªüë©‚Äçüíª Estudiantes:\n",
    "- Estudiante n¬∞1: Josefa Anselmo.\n",
    "- Estudiante n¬∞2: Tamara Carrasco.\n",
    "\n",
    "_Por favor, lean detalladamente las instrucciones de la tarea antes de empezar a escribir._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìñ Enunciado "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src='https://github.com/MDS7202/MDS7202/blob/main/recursos/2025-01/proyecto/proyecto.png?raw=true' style=\"border-radius: 12px\"> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el competitivo universo de las bebidas gaseosas, la empresa **SodAI Drinks ü•§** ha logrado destacarse por su creatividad, diversidad de productos y enfoque centrado en el cliente. Ofrece una extensa gama de bebidas carbonatadas que abarca distintos segmentos del mercado: desde productos premium en presentaciones sofisticadas, hasta gaseosas accesibles para el consumo masivo, disponibles en diversos tama√±os y tipos de envases. \n",
    "\n",
    "La compa√±√≠a opera en m√∫ltiples regiones y zonas, sirviendo a una variedad de puntos de venta que incluyen desde tiendas de conveniencia y minimarkets hasta el canal fr√≠o tradicional. Cada tipo de cliente tiene sus particularidades: algunos reciben entregas hasta 4 veces por semana, mientras que otros son visitados por la fuerza de ventas solo una vez semanalmente. Esta diversidad de perfiles representa tanto una oportunidad como un desaf√≠o comercial: ¬øc√≥mo saber qu√© productos tienen m√°s chances de ser comprados por cada cliente en un momento dado?\n",
    "\n",
    "Con el objetivo de aumentar la facturaci√≥n de forma inteligente y mejorar la eficiencia de su estrategia de ventas, **SodAI Drinks** decide crear una nueva c√©lula interna de innovaci√≥n: el equipo **Deep Drinkers ü§ñ**, cuyo prop√≥sito es aplicar ciencia de datos para anticiparse a las necesidades del cliente y potenciar el negocio desde una perspectiva basada en informaci√≥n.\n",
    "\n",
    "El coraz√≥n de esta iniciativa es el desarrollo de un sistema predictivo personalizado para cada cliente. Para ello, **Deep Drinkers** convoca a un equipo de Data Scientists y especialistas en *machine learning* con una misi√≥n clara: construir un modelo predictivo que, cada semana, pueda estimar la probabilidad de compra de cada producto del portafolio para cada cliente activo.\n",
    "\n",
    "El modelo deber√° tener en cuenta m√∫ltiples factores, incluyendo:\n",
    "- **Tipo de cliente**, ej. \"TIENDA DE CONVENIENCIA\", \"MINIMARKET\".\n",
    "- **Frecuencia de entregas y visitas**, indicadores del nivel de actividad comercial.\n",
    "- **Ubicaci√≥n geogr√°fica** (por regi√≥n y zona).\n",
    "- **Preferencias hist√≥ricas de consumo**, inferidas por patrones de compra anteriores.\n",
    "- **Caracter√≠sticas del producto**, como marca, categor√≠a, segmento, tipo de envase y tama√±o\n",
    "\n",
    "El objetivo final es que, **cada semana**, se genere una tabla de productos priorizados: para cada cliente, un listado de productos ordenado por su probabilidad estimada de compra. Esta informaci√≥n ser√° enviada al equipo comercial, que podr√° usarla en call center, para incrementar las chances de concretar ventas al ofrecer justo lo que el cliente probablemente quiere comprar.\n",
    "\n",
    "Este proyecto representa un cambio de paradigma en la forma en que **SodAI Drinks** gestiona su fuerza de ventas: de un enfoque reactivo y generalista, a uno proactivo, basado en datos y profundamente personalizado. As√≠, la empresa no solo espera aumentar su rentabilidad, sino tambi√©n construir relaciones m√°s s√≥lidas con sus clientes, ofreci√©ndoles recomendaciones m√°s relevantes y oportunas.\n",
    "\n",
    "Para lograr lo anterior, el equipo **Deep Drinkers** contar√° con los siguientes conjuntos de datos, junto a sus respectivos atributos:\n",
    "\n",
    "- **Datos transaccionales** (`transacciones.parquet`): contiene el historial de compras realizadas por los clientes.\n",
    "\t- `customer_id`: identificador √∫nico del cliente que realiz√≥ la compra.\n",
    "\t- `product_id`: identificador √∫nico del producto comprado.\n",
    "\t- `purchase_date`: fecha en que se realiz√≥ la transacci√≥n.\n",
    "\t- `order_id`: identificar de la orden de su pedido.\n",
    "\t- `items`: cantidad de bultos comprados por cliente en aquella transacci√≥n.\n",
    "\n",
    "- **Datos de clientes** (`clientes.parquet`): incluye las caracter√≠sticas de cada cliente.\n",
    "\t- `customer_id`: identificador √∫nico del cliente.\n",
    "\t- `region_id`: identificador de la regi√≥n geogr√°fica donde se encuentra el cliente.\n",
    "\t- `customer_type`: tipo de cliente seg√∫n el canal comercial, por ejemplo, ‚ÄúTIENDA DE CONVENIENCIA‚Äù.\n",
    "\t- `Y`: coordenada geogr√°fica de latitud.\n",
    "\t- `X`: coordenada geogr√°fica de longitud.\n",
    "\t- `num_deliver_per_week`: cantidad de entregas semanales que recibe el cliente.\n",
    "\t- `num_visit_per_week`: frecuencia de visitas de la fuerza de ventas por semana.\n",
    "\n",
    "- **Datos de productos** (`productos.parquet`): describe las caracter√≠sticas de los productos del portafolio.\n",
    "\t- `product_id`: identificador √∫nico del producto.\n",
    "\t- `brand`: marca comercial del producto.\n",
    "\t- `category`: categor√≠a general del producto, como ‚ÄúBEBIDAS CARBONATADAS‚Äù.\n",
    "\t- `sub_category`: subcategor√≠a dentro de la categor√≠a principal, por ejemplo, ‚ÄúGASEOSAS‚Äù.\n",
    "\t- `segment`: segmento de mercado al que pertenece el producto, como ‚ÄúPREMIUM‚Äù.\n",
    "\t- `package`: tipo de envase del producto.\n",
    "\t- `size`: tama√±o del producto en litros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Reglas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://media1.tenor.com/m/0Qtv_cQ4ITsAAAAd/necohaus-grey-name.gif\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "El proyecto consta de **dos entregas parciales** y una **entrega final** en donde la primera entrega la idea es poder reflejar lo aprendido durante la primera mitad del curso, que ser√° sobre los contenidos relacionados a *machine learning*, la segunda ser√° sobre los contenidos de la segunda mitad del curso relacionados a *MLOps* y por √∫ltimo la entrega final constar√° de dos partes, donde la primera ser√° relacionada con experimentaci√≥n sobre nuevos datasets que ser√°n disponibilizados durante las √∫ltimas semanas del curso de manera incremental y una segunda parte que ser√° el informe final escrito que deber√° explicar el desarrollo del proyecto completo, como tambien los resultados y an√°lisis de los experimentos realizados sobre los datasets incrementales. La idea es que todo el c√≥digo est√© desarrollado durante las primeras dos entregas y luego en la entrega final s√≥lo se ejecute el c√≥digo sobre nuevos conjuntos de datos.\n",
    "\n",
    "La idea de generar el proyecto por etapas es poder aliviar la carga de trabajo en las √∫ltimas semanas del semestre donde sabemos que est√°n muy cargado con entregas, pruebas y ex√°menes de otros ramos, y as√≠ garantizamos que habiendo la desarrollado las dos primeras entregas parciales, tendr√°n el grueso del proyecto listo para luego experimentar y documentar.\n",
    "\n",
    "---\n",
    "### **Fechas de entrega**\n",
    "- **Entrega parcial 1**: 12 de Septiembre\n",
    "- **Entrega parcial 2**: Por definir\n",
    "- **Entrega final**: Por definir\n",
    "\n",
    "---\n",
    "\n",
    "### **Requisitos del proyecto**\n",
    "- **Grupos**: Formar equipos de **2 personas**. No se aceptar√°n trabajos individuales o grupos con m√°s integrantes.\n",
    "- **Consultas**: Cualquier duda fuera del horario de clases debe ser planteada en el foro correspondiente. Los mensajes enviados al equipo docente ser√°n respondidos √∫nicamente por este medio. Por favor, revisen las respuestas anteriores en el foro antes de realizar nuevas consultas.\n",
    "- **Plagio**: La copia o reutilizaci√≥n no autorizada de trabajos de otros grupos est√° **estrictamente prohibida**. El incumplimiento de esta norma implicar√° la anulaci√≥n inmediata del proyecto y una posible sanci√≥n acad√©mica.\n",
    "- **Material permitido**: Pueden usar cualquier material del curso, ya sea notas, lecturas, c√≥digos, o referencias proporcionadas por los docentes, que consideren √∫til para el desarrollo del proyecto.\n",
    "\n",
    "---\n",
    "\n",
    "### **Entregables y etapas**\n",
    "\n",
    "#### **1. Entrega Parcial 1**  \n",
    "- Dispondr√°n de los archivos de datos **productos.parquet**, **clientes.parquet** y **transacciones.parquet** para el modelamiento inicial.  \n",
    "- Utilizar√°n estos archivos para desarrollar lo solicitado para la entrega 1. \n",
    "- En esta etapa, se espera que apliquen todos los conocimientos aprendidos durante la primera parte del curso relacionados con *machine learning*.\n",
    "- **Informe**: No se exige un avance del informe en esta etapa, s√≥lo un notebook con su desarrollo actual, pero se **recomienda comenzar** a redactar el informe final en paralelo para disminuir la carga acad√©mica en las etapas posteriores.  \n",
    "\n",
    "#### **2. Entrega Parcial 2**  \n",
    "- En esta entrega, deber√°n aplicar los conocimientos aprendidos durante la segunda mitad del curso sobre *MLOps*  \n",
    "- Se espera que implementen estos conocimientos para desplegar su modelo elegido en la primera entrega y crear *pipelines* automatizados que simulen un entorno productivo.\n",
    "- **Informe**: similar a la primera etapa, no se exige un avance del informe, pero se **recomienda avanzar con su redacci√≥n** para evitar una acumulaci√≥n de trabajo en la etapa final.  \n",
    "\n",
    "#### **3. Entrega Final**  \n",
    "- En la entrega final, deber√°n realizar dos etapas:\n",
    "\t- La primera etapa es sobre experimentaci√≥n utilizando datasets incrementales que se ir√°n disponibilizando de manera parcial, para que vayan generando predicciones con su modelo ya desplegado. El objetivo de esta etapa es poder testear su soluci√≥n *end-to-end* y que vayan analizando los resultados obtenidos a medida que se van agregando m√°s datos.\n",
    "\t- La segunda etapa consiste en redactar un informe final que deber√° explicar el desarrollo completo de tu proyecto y un an√°lisis profundo de sus resultados de experimentaci√≥n. Este informe debera incluir a lo menos las siguientes secciones:\n",
    "\t\t- An√°lisis exploratorio de datos  \n",
    "\t\t- Metodolog√≠a aplicada  \n",
    "\t\t- Selecci√≥n y entrenamiento de modelos  \n",
    "\t\t- Evaluaci√≥n de resultados  \n",
    "\t\t- Optimizaci√≥n de modelos\n",
    "\t\t- Interpretabilidad\n",
    "\t\t- Re-entrenamiento\n",
    "\t\t- Tracking con MLFlow\n",
    "\t\t- Creaci√≥n de la aplicaci√≥n web con Gradio y FastAPI\n",
    "\n",
    "Es **altamente recomendable** ir redactando el informe en paralelo al desarrollo de los modelos para garantizar que toda la informaci√≥n relevante quede documentada adecuadamente.  \n",
    "\n",
    "### Nota Final\n",
    "\n",
    "La calificaci√≥n final de su proyecto se calcular√° utilizando la siguiente ponderaci√≥n: \n",
    "\n",
    "$$Nota Final = 0.30 * EntregaParcial1 + 0.40 * EntregaParcial2 + 0.30 * EntregaFinal$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Instrucciones importantes**\n",
    "\n",
    "1. **Formato del informe**:  \n",
    "   - El informe debe estar integrado dentro de un **Jupyter Notebook**. No es necesario subirlo a una plataforma externa, pero debe cumplir con los siguientes requisitos:  \n",
    "     - Estructura clara y ordenada.  \n",
    "     - C√≥digo acompa√±ado de explicaciones detalladas.  \n",
    "     - Resultados presentados de forma visual y anal√≠tica.  \n",
    "\n",
    "2. **Descuento por informes deficientes**:  \n",
    "   - Cualquier secci√≥n del informe que no tenga una explicaci√≥n adecuada o no respete el formato ser√° penalizada con un descuento en la nota. Esto incluye c√≥digo sin comentarios o an√°lisis que no sean coherentes con los resultados presentados.\n",
    "   - Comentarios sin formatear de ChatGPT o herramientas similares ser√°n penalizados (e.g: \"Inserta tu modelo ac√°\", etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì¨ Entrega Parcial 1 (30% del Proyecto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì™ Fecha de Entrega: 12 de Septiembre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Abstract [0.25 puntos]\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.redd.it/h5ptnsyabqvd1.gif\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta secci√≥n, deben redactar un Abstract claro y conciso para su proyecto. El Abstract debe responder a las siguientes preguntas clave:\n",
    "\n",
    "- **Descripci√≥n del problema**: ¬øCu√°l es el objetivo del proyecto? ¬øQu√© se intenta predecir o analizar?\n",
    "- **Datos de entrada**: ¬øQu√© datos tienen disponibles? ¬øCu√°les son sus principales caracter√≠sticas?\n",
    "- **M√©trica de evaluaci√≥n**: ¬øC√≥mo medir√°n el desempe√±o de sus modelos? Expliquen por qu√© eligieron esta m√©trica bas√°ndose en el an√°lisis exploratorio de los datos.\n",
    "- **Modelos y transformaciones**: ¬øQu√© modelos utilizar√°n y por qu√©? ¬øQu√© transformaciones o preprocesamientos aplicaron a los datos?\n",
    "- **Resultados generales**: ¬øEl modelo final cumpli√≥ con los objetivos del proyecto? ¬øCu√°les fueron las conclusiones m√°s importantes?\n",
    "\n",
    "**Importante**: Escriban esto despues de haber resuelto el resto de la tarea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [Escriba aqu√≠ su Abstract]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Pre-procesamiento [0.5 puntos]\n",
    "\n",
    "<center>\n",
    "<img src=\"https://media0.giphy.com/media/10zsjaH4g0GgmY/giphy.gif?cid=6c09b9523xtlunksc9amikw09zk1bmiqwjqnt70ae82rk877&ep=v1_gifs_search&rid=giphy.gif&ct=g\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal como en muchos otros problemas de negocio, los datos probablemente deben ser pre procesados antes de aplicar cualquier t√©cnica de anal√≠tica. Bajo esa premisa, en esta secci√≥n deben desarrollar c√≥digo que les permita **preparar los datos** de tal forma que les permita resolver el problema planteado. Para esto, pueden aplicar procesamientos como:\n",
    "\n",
    "- Transformaciones de tipo de dato (str, int, etc)\n",
    "- Cruce de informaci√≥n\n",
    "- Eliminaci√≥n de duplicados\n",
    "- Filtros de fila y/o columnas\n",
    "\n",
    "*Hint: ¬øQu√© forma deber√≠a tener la data para resolver un problema de aprendizaje supervisado?*\n",
    "\n",
    "Todo proceso llevado a cabo debe estar bien documentado y justificado en el informe, explicando el por qu√© se decidi√≥ realizar en funcion de los datos presentados y los objetivos planteados del proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desarrolle aqu√≠ su c√≥digo\n",
    "\n",
    "# librer√≠as para EDA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Carga de archivos\n",
    "\n",
    "clientes = pd.read_parquet(\"clientes.parquet\")\n",
    "productos = pd.read_parquet(\"productos.parquet\")\n",
    "transacciones = pd.read_parquet(\"transacciones.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplicamos .head() para ver c√≥mo es cada tabla gr√°ficamente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Primeros 3 registros del dataset Clientes ==========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>region_id</th>\n",
       "      <th>zone_id</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>Y</th>\n",
       "      <th>X</th>\n",
       "      <th>num_deliver_per_week</th>\n",
       "      <th>num_visit_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10705</th>\n",
       "      <td>256017</td>\n",
       "      <td>80</td>\n",
       "      <td>5148</td>\n",
       "      <td>ABARROTES</td>\n",
       "      <td>-46.474800</td>\n",
       "      <td>-108.045140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10706</th>\n",
       "      <td>255780</td>\n",
       "      <td>80</td>\n",
       "      <td>5148</td>\n",
       "      <td>ABARROTES</td>\n",
       "      <td>-46.520282</td>\n",
       "      <td>-107.961052</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10707</th>\n",
       "      <td>254655</td>\n",
       "      <td>80</td>\n",
       "      <td>5148</td>\n",
       "      <td>ABARROTES</td>\n",
       "      <td>-46.537640</td>\n",
       "      <td>-107.909280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id  region_id  zone_id customer_type          Y           X  \\\n",
       "10705       256017         80     5148     ABARROTES -46.474800 -108.045140   \n",
       "10706       255780         80     5148     ABARROTES -46.520282 -107.961052   \n",
       "10707       254655         80     5148     ABARROTES -46.537640 -107.909280   \n",
       "\n",
       "       num_deliver_per_week  num_visit_per_week  \n",
       "10705                     1                   1  \n",
       "10706                     1                   1  \n",
       "10707                     1                   1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=\"*10 + \" Primeros 3 registros del dataset Clientes \"+ \"=\"*10)\n",
    "clientes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Primeros 3 registros del dataset Productos ==========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>segment</th>\n",
       "      <th>package</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34092</td>\n",
       "      <td>Brand 31</td>\n",
       "      <td>BEBIDAS CARBONATADAS</td>\n",
       "      <td>GASEOSAS</td>\n",
       "      <td>PREMIUM</td>\n",
       "      <td>BOTELLA</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57290</td>\n",
       "      <td>Brand 31</td>\n",
       "      <td>BEBIDAS CARBONATADAS</td>\n",
       "      <td>GASEOSAS</td>\n",
       "      <td>PREMIUM</td>\n",
       "      <td>BOTELLA</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56714</td>\n",
       "      <td>Brand 31</td>\n",
       "      <td>BEBIDAS CARBONATADAS</td>\n",
       "      <td>GASEOSAS</td>\n",
       "      <td>PREMIUM</td>\n",
       "      <td>BOTELLA</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id     brand              category sub_category  segment  package  \\\n",
       "0       34092  Brand 31  BEBIDAS CARBONATADAS     GASEOSAS  PREMIUM  BOTELLA   \n",
       "1       57290  Brand 31  BEBIDAS CARBONATADAS     GASEOSAS  PREMIUM  BOTELLA   \n",
       "2       56714  Brand 31  BEBIDAS CARBONATADAS     GASEOSAS  PREMIUM  BOTELLA   \n",
       "\n",
       "   size  \n",
       "0  0.66  \n",
       "1  0.66  \n",
       "2  0.66  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=\"*10 + \" Primeros 3 registros del dataset Productos \"+ \"=\"*10)\n",
    "productos.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Primeros 3 registros del dataset Transacciones ==========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>61353</td>\n",
       "      <td>61364</td>\n",
       "      <td>411145</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>61899</td>\n",
       "      <td>1370</td>\n",
       "      <td>411156</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>3.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>154077</td>\n",
       "      <td>30500</td>\n",
       "      <td>417911</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     customer_id  product_id  order_id purchase_date     items\n",
       "124        61353       61364    411145    2024-04-27 -0.333333\n",
       "127        61899        1370    411156    2024-04-27  3.666667\n",
       "344       154077       30500    417911    2024-04-29  2.333333"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=\"*10 + \" Primeros 3 registros del dataset Transacciones \"+ \"=\"*10)\n",
    "transacciones.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Revisamos los .shape (dimensiones) de las tablas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Dimensiones de los datasets ==========\n",
      "Clientes:  (1569, 8)\n",
      "Productos:  (971, 7)\n",
      "Transacciones:  (254936, 5)\n"
     ]
    }
   ],
   "source": [
    "# dimensiones de los dataset\n",
    "\n",
    "print(\"=\"*10 + \" Dimensiones de los datasets \" + \"=\"*10)\n",
    "\n",
    "print(\"Clientes: \", clientes.shape)\n",
    "\n",
    "print(\"Productos: \", productos.shape)\n",
    "\n",
    "print(\"Transacciones: \", transacciones.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplicamos .tolist() para poder tener identificados los nombres de las variables que usamos en cada tabla**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columnas del archivo cliente:  ['customer_id', 'region_id', 'zone_id', 'customer_type', 'Y', 'X', 'num_deliver_per_week', 'num_visit_per_week']\n",
      "Columnas del archivo productos:  ['product_id', 'brand', 'category', 'sub_category', 'segment', 'package', 'size']\n",
      "Columnas del archivo transacciones ['customer_id', 'product_id', 'order_id', 'purchase_date', 'items']\n"
     ]
    }
   ],
   "source": [
    "# Nombres de columnas identificadas de cada archivo\n",
    "\n",
    "client_columns = clientes.columns.tolist()\n",
    "\n",
    "products_columns = productos.columns.tolist()\n",
    "\n",
    "transactions_columns = transacciones.columns.tolist()\n",
    "\n",
    "print(\"columnas del archivo cliente: \", client_columns)\n",
    "\n",
    "print(\"Columnas del archivo productos: \", products_columns)\n",
    "\n",
    "print(\"Columnas del archivo transacciones\", transactions_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aqu√≠ dejo los tipos de dato que tiene cada tabla con .dtypes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================Tipo de valores en las columnas (Cliente) ==============================\n",
      "customer_id               int64\n",
      "region_id                 int64\n",
      "zone_id                   int64\n",
      "customer_type            object\n",
      "Y                       float64\n",
      "X                       float64\n",
      "num_deliver_per_week      int64\n",
      "num_visit_per_week        int64\n",
      "dtype: object\n",
      "==============================Tipo de valores en las columnas (productos) ==============================\n",
      "product_id        int64\n",
      "brand            object\n",
      "category         object\n",
      "sub_category     object\n",
      "segment          object\n",
      "package          object\n",
      "size            float64\n",
      "dtype: object\n",
      "==============================Tipo de valores en las columnas (transacciones) ==============================\n",
      "customer_id               int64\n",
      "product_id                int64\n",
      "order_id                  int64\n",
      "purchase_date    datetime64[ns]\n",
      "items                   float64\n",
      "dtype: object\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Tipo de datos identificados en las columnas\n",
    "print(\"=\"*30 + \"Tipo de valores en las columnas (Cliente) \"+ \"=\"*30)\n",
    "print(clientes.dtypes)\n",
    "\n",
    "\n",
    "print(\"=\"*30 + \"Tipo de valores en las columnas (productos) \"+ \"=\"*30)\n",
    "print(productos.dtypes)\n",
    "\n",
    "\n",
    "print(\"=\"*30 + \"Tipo de valores en las columnas (transacciones) \"+ \"=\"*30)\n",
    "print(transacciones.dtypes)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Las columnas que funcionana como un id (\"customer_id\", \"region_id\" y \"zone_id\", product_id, \"order_id\") en las 3 tablas ahora estan como n√∫mero y no deberiamos tratarlas porque estas son m√°s bien identificadores nominales o sea que deberian ser texto en el fondo. En las tablas, las varibales customer_type, brand, category, sub_category, segmente y package estan como object, pero para orden y para que sea m√°s explicita la convertiremos en category directamete. Adem√°s, esto disminuye el costo computacional del c√≥digo porque si usamos clase object, pandas considera cada valor como un puntero a un objeto de Python mientras qeu al estar como category se crea como \"un diccionario\" interno y eso pesa menos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificamos dtypes pues hab√≠an ciertas incongruencias con los dtypes actuales\n",
    "\n",
    "# Clientes\n",
    "clientes = clientes.astype({\n",
    "    \"customer_id\": \"string\",\n",
    "    \"region_id\": \"string\",\n",
    "    \"zone_id\": \"string\",\n",
    "    \"customer_type\": \"category\"\n",
    "})\n",
    "\n",
    "# Productos\n",
    "productos = productos.astype({\n",
    "    \"product_id\": \"string\", # Podr√≠a considerarse como category??\n",
    "    \"brand\": \"category\",\n",
    "    \"category\": \"category\",\n",
    "    \"sub_category\": \"category\",\n",
    "    \"segment\": \"category\",\n",
    "    \"package\": \"category\"\n",
    "})\n",
    "\n",
    "# Transacciones\n",
    "transacciones = transacciones.astype({\n",
    "    \"customer_id\": \"string\",\n",
    "    \"product_id\": \"string\",\n",
    "    \"order_id\": \"string\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================Tipo de valores en las columnas (Cliente) ==============================\n",
      "customer_id             string[python]\n",
      "region_id               string[python]\n",
      "zone_id                 string[python]\n",
      "customer_type                 category\n",
      "Y                              float64\n",
      "X                              float64\n",
      "num_deliver_per_week             int64\n",
      "num_visit_per_week               int64\n",
      "dtype: object\n",
      "==============================Tipo de valores en las columnas (productos) ==============================\n",
      "product_id      string[python]\n",
      "brand                 category\n",
      "category              category\n",
      "sub_category          category\n",
      "segment               category\n",
      "package               category\n",
      "size                   float64\n",
      "dtype: object\n",
      "==============================Tipo de valores en las columnas (transacciones) ==============================\n",
      "customer_id      string[python]\n",
      "product_id       string[python]\n",
      "order_id         string[python]\n",
      "purchase_date    datetime64[ns]\n",
      "items                   float64\n",
      "dtype: object\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Confirmo cambios\n",
    "print(\"=\"*30 + \"Tipo de valores en las columnas (Cliente) \"+ \"=\"*30)\n",
    "print(clientes.dtypes)\n",
    "\n",
    "\n",
    "print(\"=\"*30 + \"Tipo de valores en las columnas (productos) \"+ \"=\"*30)\n",
    "print(productos.dtypes)\n",
    "\n",
    "\n",
    "print(\"=\"*30 + \"Tipo de valores en las columnas (transacciones) \"+ \"=\"*30)\n",
    "print(transacciones.dtypes)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplico estad√≠sticas descriptivas b√°sicas ahora que tengo correcto el tipo de dato -> solo se aplica a las columnas num√©ricas en este caso**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Estad√≠stica descriptiva clientes (num√©rico)==========\n",
      "                 Y            X  num_deliver_per_week  num_visit_per_week\n",
      "count  1569.000000  1568.000000           1569.000000              1569.0\n",
      "mean    -46.700549  -107.743548              3.104525                 1.0\n",
      "std       2.700406     2.693112              0.515610                 0.0\n",
      "min    -109.002508  -108.620920              1.000000                 1.0\n",
      "25%     -46.586122  -107.934477              3.000000                 1.0\n",
      "50%     -46.555514  -107.894765              3.000000                 1.0\n",
      "75%     -46.513968  -107.862156              3.000000                 1.0\n",
      "max     -46.161950   -46.442785              6.000000                 1.0\n",
      "==========Estad√≠stica descriptiva productos (num√©rico)==========\n",
      "             size\n",
      "count  971.000000\n",
      "mean     1.420525\n",
      "std      3.897778\n",
      "min      0.125000\n",
      "25%      0.310000\n",
      "50%      0.500000\n",
      "75%      1.000000\n",
      "max     20.000000\n",
      "==========Estad√≠stica descriptiva transacciones (num√©rico)==========\n",
      "                       purchase_date          items\n",
      "count                         254936  254936.000000\n",
      "mean   2024-07-11 07:49:38.893526016       4.378552\n",
      "min              2024-01-01 00:00:00    -399.666667\n",
      "25%              2024-03-26 00:00:00       1.000000\n",
      "50%              2024-07-23 00:00:00       2.333333\n",
      "75%              2024-10-23 00:00:00       3.666667\n",
      "max              2024-12-31 00:00:00    1000.333333\n",
      "std                              NaN      12.098818\n"
     ]
    }
   ],
   "source": [
    "# Aplico la funci√≥n definida sobre el dataset clientes\n",
    "print(\"=\"*10 + \"Estad√≠stica descriptiva clientes (num√©rico)\" + \"=\"*10)\n",
    "print(clientes.describe())\n",
    "print(\"=\"*10 + \"Estad√≠stica descriptiva productos (num√©rico)\" + \"=\"*10)\n",
    "print(productos.describe())\n",
    "print(\"=\"*10 + \"Estad√≠stica descriptiva transacciones (num√©rico)\" + \"=\"*10)\n",
    "print(transacciones.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplico para string y separado para category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Estad√≠stica descriptiva clientes (string)==========\n",
      "       customer_id region_id zone_id\n",
      "count         1569      1569    1569\n",
      "unique        1569         1       1\n",
      "top         255780        80    5148\n",
      "freq             1      1569    1569\n",
      "==========Estad√≠stica descriptiva productos (string)==========\n",
      "       product_id\n",
      "count         971\n",
      "unique        971\n",
      "top         50254\n",
      "freq            1\n",
      "==========Estad√≠stica descriptiva transacciones (string)==========\n",
      "       customer_id product_id order_id\n",
      "count       254936     254936   254936\n",
      "unique        1490        114    64600\n",
      "top         183105       1370    23039\n",
      "freq          1619      37710       47\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*10 + \"Estad√≠stica descriptiva clientes (string)\" + \"=\"*10)\n",
    "print(clientes.describe(include=\"string\"))\n",
    "print(\"=\"*10 + \"Estad√≠stica descriptiva productos (string)\" + \"=\"*10)\n",
    "print(productos.describe(include=\"string\"))\n",
    "print(\"=\"*10 + \"Estad√≠stica descriptiva transacciones (string)\" + \"=\"*10)\n",
    "print(transacciones.describe(include=\"string\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transacciones no tiene una varible tipo category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Estad√≠stica descriptiva clientes (category)==========\n",
      "       customer_type\n",
      "count           1569\n",
      "unique             7\n",
      "top        ABARROTES\n",
      "freq            1160\n",
      "==========Estad√≠stica descriptiva productos (category)==========\n",
      "          brand              category sub_category  segment  package\n",
      "count       971                   971          971      971      971\n",
      "unique       61                     2            3        4        4\n",
      "top     Brand 7  BEBIDAS CARBONATADAS     GASEOSAS  PREMIUM  BOTELLA\n",
      "freq        104                   743          673      310      597\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*10 + \"Estad√≠stica descriptiva clientes (category)\" + \"=\"*10)\n",
    "print(clientes.describe(include=\"category\"))\n",
    "print(\"=\"*10 + \"Estad√≠stica descriptiva productos (category)\" + \"=\"*10)\n",
    "print(productos.describe(include=\"category\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las estad√≠sticas que importan del dataset de ``clientes.parquet`` son de las columnas ``num_deliver_per_week``, ``num_visit_per_week`` y ``customer_type``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ac√° se identifica que tal vez sea m√°s conveniente transformar la columna fecha de compra -> que aparezcan 3 columnas extras (a√±o, mes, d√≠a).\n",
    "\n",
    "Las columnas cuyas estad√≠sticas importan: ``items``: Se identifca un valor negativo, cuando esta columna representa a cantidad de bultos comprados por el cliente en aquella transacci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La variable purchase_date tiene otro tipo de dato (datetime64[ns]) por lo que la revisaremos por separado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124   2024-04-27\n",
      "127   2024-04-27\n",
      "344   2024-04-29\n",
      "349   2024-04-29\n",
      "354   2024-04-26\n",
      "359   2024-04-29\n",
      "362   2024-04-29\n",
      "363   2024-04-29\n",
      "365   2024-04-28\n",
      "367   2024-04-29\n",
      "Name: purchase_date, dtype: datetime64[ns]\n",
      "Min: 2024-01-01 00:00:00\n",
      "Max: 2024-12-31 00:00:00\n",
      "Unique: 366\n",
      "Nulos: 0\n"
     ]
    }
   ],
   "source": [
    "# Tipo de dato\n",
    "transacciones[\"purchase_date\"].dtype\n",
    "\n",
    "# Ver encabezado para saber como \n",
    "print(transacciones[\"purchase_date\"].head(3))\n",
    "\n",
    "# Reviso rango\n",
    "print(\"Min:\", transacciones[\"purchase_date\"].min())\n",
    "print(\"Max:\", transacciones[\"purchase_date\"].max())\n",
    "\n",
    "# Veo nulos y √∫nicos\n",
    "print(\"Unique:\", transacciones[\"purchase_date\"].nunique())\n",
    "print(\"Nulos:\", transacciones[\"purchase_date\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Si bien pareciera que solo se presenta en la columna el a√±o, mes y d√≠a (en ese orden), queremos confirmar que no hayan registos de hora que en el fondo igual son soportados por lo que se muestra en la estad√≠stica b√°sica de los m√≠nimos y m√°ximos.**\n",
    "**Transacciones de un a√±o**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from datetime import time # Para poder trabajar directamente con fechas/tiempo\n",
    "\n",
    "print(transacciones[\"purchase_date\"].dt.time.nunique())  # quiero saber si la parte del tiempo es el mismo en todas, o sea como 00:00:00 y as√≠ asegurarme que es como \"por defecto\" o si es que de hecho la columna captura esa informaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregaremos las variables de fecha espec√≠fica (d√≠a, mes y a√±o) para posibles futuros desarrollos\n",
    "transacciones[\"year\"] = transacciones[\"purchase_date\"].dt.year\n",
    "transacciones[\"month\"] = transacciones[\"purchase_date\"].dt.month\n",
    "transacciones[\"day\"] = transacciones[\"purchase_date\"].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>items</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>61353</td>\n",
       "      <td>61364</td>\n",
       "      <td>411145</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>61899</td>\n",
       "      <td>1370</td>\n",
       "      <td>411156</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id product_id order_id purchase_date     items  year  month  day\n",
       "124       61353      61364   411145    2024-04-27 -0.333333  2024      4   27\n",
       "127       61899       1370   411156    2024-04-27  3.666667  2024      4   27"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transacciones.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos a dejar igual la variable de purchase_date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254936, 8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transacciones.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reviso si hay valores nulos en las tablas con isna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Identificaci√≥n de valores nulos por columna de cada dataset\n",
      "============================== Dataset clientes ==============================\n",
      "customer_id             0\n",
      "region_id               0\n",
      "zone_id                 0\n",
      "customer_type           0\n",
      "Y                       0\n",
      "X                       1\n",
      "num_deliver_per_week    0\n",
      "num_visit_per_week      0\n",
      "dtype: int64\n",
      "============================== Dataset productos ==============================\n",
      "product_id      0\n",
      "brand           0\n",
      "category        0\n",
      "sub_category    0\n",
      "segment         0\n",
      "package         0\n",
      "size            0\n",
      "dtype: int64\n",
      "============================== Dataset transacciones ==============================\n",
      "customer_id      0\n",
      "product_id       0\n",
      "order_id         0\n",
      "purchase_date    0\n",
      "items            0\n",
      "year             0\n",
      "month            0\n",
      "day              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identificaci√≥n de valores nulos\n",
    "\n",
    "print(\" Identificaci√≥n de valores nulos por columna de cada dataset\")\n",
    "\n",
    "print(\"=\"*30 + \" Dataset clientes \"+ \"=\"*30)\n",
    "print(clientes.isna().sum())\n",
    "\n",
    "print(\"=\"*30 + \" Dataset productos \"+ \"=\"*30)\n",
    "print(productos.isna().sum())\n",
    "\n",
    "print(\"=\"*30 + \" Dataset transacciones \"+ \"=\"*30)\n",
    "print(transacciones.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset de ``clientes.parquet``, hay un registro que no cuenta con coordenada geogr√°fica X (longitud)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reviso los duplicados con duplicated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Identificaci√≥n de registros duplicados por columna de cada dataset\n",
      "============================== Dataset clientes ==============================\n",
      "0\n",
      "============================== Dataset productos ==============================\n",
      "0\n",
      "============================== Dataset transacciones ==============================\n",
      "885\n"
     ]
    }
   ],
   "source": [
    "# identificaci√≥n de valores duplicados\n",
    "\n",
    "print(\" Identificaci√≥n de registros duplicados por columna de cada dataset\")\n",
    "print(\"=\"*30 + \" Dataset clientes \"+ \"=\"*30)\n",
    "print(clientes.duplicated(subset=[\"customer_id\"]).sum())\n",
    "\n",
    "print(\"=\"*30 + \" Dataset productos \"+ \"=\"*30)\n",
    "print(productos.duplicated().sum())\n",
    "\n",
    "print(\"=\"*30 + \" Dataset transacciones \"+ \"=\"*30)\n",
    "print(transacciones.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen 885 transacciones duplicadas, las cuales tendr√°n que ser trabajadas tambi√©n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension del dataset despu√©s de eliminar duplicados:  (243338, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>items</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>61353</td>\n",
       "      <td>61364</td>\n",
       "      <td>411145</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>61899</td>\n",
       "      <td>1370</td>\n",
       "      <td>411156</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id product_id order_id purchase_date     items  year  month  day\n",
       "124       61353      61364   411145    2024-04-27 -0.333333  2024      4   27\n",
       "127       61899       1370   411156    2024-04-27  3.666667  2024      4   27"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminamos tuplas duplicadas\n",
    "\n",
    "transacciones = transacciones.drop_duplicates(subset=[\"order_id\", \"product_id\"], keep=\"first\") # Defino que revise y bote duplicados basandose en la llave de alguna forma, en el fonod cada producto se asocia a una orden y el cliente esta implicito\n",
    "print(\"Dimension del dataset despu√©s de eliminar duplicados: \", transacciones.shape) \n",
    "transacciones.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cruce de informaci√≥n.\n",
    "En este punto, es v√°lido realizar un cruce de informaci√≥n usando las llaves primarias, tales como ``Customer ID`` del dataset Clientes y ``Product ID`` del dataset Productos. En el dataset de transacciones, las llaves mencionadas ahora son llaves for√°neas y se tiene la llave primaria ``Order ID``.\n",
    "\n",
    "Como el dataset Transacciones contiene esas 3 llaves, comenzamos el merge desde ah√≠: primero con clientes y luego con productos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entonces hare los merge y despu√©s volver√© a revisar los datos m√°s o menos para saber c√≥mo quedo y asegurarme de que quedo bien**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hago merge de los dataset en un solo dataframe -> df\n",
    "\n",
    "df = transacciones.merge(clientes, on=\"customer_id\", how=\"left\") # how = left significa que usa solo las llaves del frame izquierdo, como un\n",
    "                                                                # sql left outer join: preserva el orden de la llave -> deberia aparecer customer id como \n",
    "                                                                # primera columna\n",
    "\n",
    "df = df.merge(productos, on=\"product_id\", how=\"left\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entonces ahora los 3 quedan como un gran data frame que convservan la informaci√≥n principalmente de las transacciones, esto debido a que eso es lo que \"confirma\" que hubo una compra. Puedo tener quizas algunos clientes que se eliminen en le merge o productos que se eliminen, pero deber√≠a primar el tema de las transacciones porque ah√≠ queda registrada la compra por decir. Los otros son como \"perfil\" de cliente y \"perfil\" de objeto que se vende**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del dataset:  (243338, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>items</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>region_id</th>\n",
       "      <th>zone_id</th>\n",
       "      <th>...</th>\n",
       "      <th>Y</th>\n",
       "      <th>X</th>\n",
       "      <th>num_deliver_per_week</th>\n",
       "      <th>num_visit_per_week</th>\n",
       "      <th>brand</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>segment</th>\n",
       "      <th>package</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61353</td>\n",
       "      <td>61364</td>\n",
       "      <td>411145</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>5148</td>\n",
       "      <td>...</td>\n",
       "      <td>-46.558718</td>\n",
       "      <td>-107.860564</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand 35</td>\n",
       "      <td>BEBIDAS CARBONATADAS</td>\n",
       "      <td>GASEOSAS</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>BOTELLA</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61899</td>\n",
       "      <td>1370</td>\n",
       "      <td>411156</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>5148</td>\n",
       "      <td>...</td>\n",
       "      <td>-46.557632</td>\n",
       "      <td>-107.896470</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand 34</td>\n",
       "      <td>BEBIDAS CARBONATADAS</td>\n",
       "      <td>GASEOSAS</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>BOTELLA</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id product_id order_id purchase_date     items  year  month  day  \\\n",
       "0       61353      61364   411145    2024-04-27 -0.333333  2024      4   27   \n",
       "1       61899       1370   411156    2024-04-27  3.666667  2024      4   27   \n",
       "\n",
       "  region_id zone_id  ...          Y           X  num_deliver_per_week  \\\n",
       "0        80    5148  ... -46.558718 -107.860564                     3   \n",
       "1        80    5148  ... -46.557632 -107.896470                     3   \n",
       "\n",
       "   num_visit_per_week     brand              category sub_category segment  \\\n",
       "0                   1  Brand 35  BEBIDAS CARBONATADAS     GASEOSAS  MEDIUM   \n",
       "1                   1  Brand 34  BEBIDAS CARBONATADAS     GASEOSAS  MEDIUM   \n",
       "\n",
       "   package size  \n",
       "0  BOTELLA  1.0  \n",
       "1  BOTELLA  1.0  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Dimensiones del dataset: \",df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores Nulos en dataset df\n",
      "customer_id             0\n",
      "product_id              0\n",
      "order_id                0\n",
      "purchase_date           0\n",
      "items                   0\n",
      "year                    0\n",
      "month                   0\n",
      "day                     0\n",
      "region_id               0\n",
      "zone_id                 0\n",
      "customer_type           0\n",
      "Y                       0\n",
      "X                       0\n",
      "num_deliver_per_week    0\n",
      "num_visit_per_week      0\n",
      "brand                   0\n",
      "category                0\n",
      "sub_category            0\n",
      "segment                 0\n",
      "package                 0\n",
      "size                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Valores Nulos en dataset df\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ac√° desapareci√≥ el √∫nico cliente que ten√≠a una coordenada \"X\" como NaN. Por c√≥mo se hizo el merge, capaz que el cliente no estaba en transacciones y ahora desapareci√≥ del df final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ya entonces viendo las dimensiones y si es que hay nulos, puedo presumir que todas las transacciones fueron hechas por clientes que exitian y se vendieron items que estaban registrados. Adem√°s, podr√≠a ser que en el merge se perdio info de los items o de los clientes pero apra terminos de compras esta informacion no debiera ser relevante y por ella esta bien si se perdi√≥ pues no nos aporta concretamente algo ahora**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clientes en clientes: 1569\n",
      "Clientes en transacciones: 1490\n",
      "Clientes faltantes: 79\n",
      "Productos en productos: 971\n",
      "Productos en transacciones: 114\n",
      "Productos faltantes: 857\n"
     ]
    }
   ],
   "source": [
    "# Revisar si efectivamente hubieron registros de cliente y de producto que no se mergearon con la tabla transacciones pues no compraron/no figuraban en inventario\n",
    "\n",
    "print(\"Clientes en clientes:\", clientes[\"customer_id\"].nunique())\n",
    "print(\"Clientes en transacciones:\", df[\"customer_id\"].nunique())\n",
    "print(\"Clientes faltantes:\", len(set(clientes[\"customer_id\"]) - set(df[\"customer_id\"])))\n",
    "\n",
    "print(\"Productos en productos:\", productos[\"product_id\"].nunique())\n",
    "print(\"Productos en transacciones:\", df[\"product_id\"].nunique())\n",
    "print(\"Productos faltantes:\", len(set(productos[\"product_id\"]) - set(df[\"product_id\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Efectivamente entonces no todos los clientes y productos pasan al merge, pero esto se explica en lo que ya dijimos ants, o sea, no todos los clientes han comprado ni todos los productos se han transado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sobre la columna de la fecha: ya est√° en un buen formato, pero en el momento en que se requiera un an√°lisis temporar: mes, semana, d√≠a... se pueden crear \n",
    "columnas auxiliares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valores duplicados en df nuevo mergeado\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**como se puede ver tenemos 885 transacciones duplicadas, como esto no es \"posibble\" teneoms que droppear las tuplas duplicadas pues solo nos estan duplicando, valga la redundancia, la informaci√≥n y no nos estan aportando m√°s datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Super importante no olvidar que el drop y las modificaciones se han hecho todo el tiempo considerando que una transacci√≥n equivale a 1 registro. Que la primary key es el order_id, por lo que solo puede haber 1 order_id x registro**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå EDA [0.5 puntos]\n",
    "\n",
    "<center>\n",
    "<img src=\"https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExbHZ6aGdkd21tYTI3cW8zYWhyYW5wdGlyb2s3MmRzeTV0dzQ1NWlueiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3k1hJubTtOAKPKx4k3/giphy.gif\" width=\"400\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta secci√≥n, se debe realizar un an√°lisis exploratorio de los datos para comprender su estructura, detectar posibles problemas y obtener informaci√≥n relevante para el entrenamiento de los modelos. La idea es que puedan detectar **patrones en los datos** que les permitan resolver el problema con mayor facilidad.\n",
    "\n",
    "Se deben responder preguntas a partir de lo que puedan visualizar/obtener, por ejemplo:\n",
    "\n",
    "- Clientes y productos\n",
    "\n",
    "    - ¬øCu√°ntos clientes √∫nicos hay en el dataset?\n",
    "\n",
    "    - ¬øCu√°ntos productos √∫nicos se encuentran en los datos?\n",
    "\n",
    "- Periodo y frecuencia\n",
    "\n",
    "    - ¬øDe qu√© periodo es la informaci√≥n disponible?\n",
    "\n",
    "    - ¬øCu√°l es la frecuencia de los registros (diaria, semanal, mensual, etc.)?\n",
    "\n",
    "- Calidad de los datos\n",
    "\n",
    "    - ¬øExisten valores nulos en el dataset? ¬øCu√°ntos? ¬øC√≥mo se pueden tratar?\n",
    "\n",
    "    - ¬øHay datos raros, como cantidades negativas o inconsistencias? Genere tests de validaci√≥n para identificar estos problemas.\n",
    "\n",
    "- Patrones de compra\n",
    "\n",
    "    - ¬øCu√°ntos productos compra en promedio cada cliente semana a semana?\n",
    "\n",
    "    - ¬øCu√°ntas transacciones ha realizado cada cliente?\n",
    "\n",
    "    - ¬øCu√°l es el periodo de recompra promedio de cada SKU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desarrolle aqu√≠ su c√≥digo\n",
    "\n",
    "# clientes y productos\n",
    "\n",
    "df[\"customer_id\"].value_counts().shape # hay 1490 clientes √∫nicos\n",
    "\n",
    "df[\"product_id\"].value_counts().shape # hay 114 productos √∫nicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sobre las fechas\n",
    "\n",
    "fecha_inicio = df[\"purchase_date\"].min()\n",
    "\n",
    "fecha_final = df[\"purchase_date\"].max()\n",
    "\n",
    "print(\"Fecha inicio de observaciones: \", fecha_inicio)# los registros son desde el 1 de enero del a√±o 2024?\n",
    "\n",
    "print(\"Fecha final de observaciones: \", fecha_final )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(\"purchase_date\") # esto ordena las filas del df seg√∫n la fecha\n",
    "\n",
    "frecuencia_diaria = df.resample('D').size().reset_index(name='frecuencia')\n",
    "print(frecuencia_diaria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frecuencia_semanal = df.resample('W').size().reset_index(name='frecuencia')\n",
    "print(frecuencia_semanal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frecuencia_mensual = df.resample(\"ME\").size().reset_index(name=\"frecuencia\") # M o ME para \"month\"\n",
    "print(frecuencia_mensual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De ac√°, los meses en donde se compran m√°s productos son  los menes de fin de a√±o (Noviembre-Diciembre) y principio de a√±o (Enero). El mes con ventas m√°s bajas es el mes de Mayo.\n",
    "Sobre cantidades negativas, hay items que salen con signo negativo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas del dataset mergeado\n",
    "\n",
    "cat_columns = column_type(df, printeo=\"no\")[0]\n",
    "binary_columns = column_type(df, printeo=\"no\")[1]\n",
    "num_columns = column_type(df, printeo=\"no\")[2]\n",
    "cat_nominal_columns = column_type(df, printeo=\"no\")[3]\n",
    "cat_ordinal_columns = column_type(df, printeo=\"no\")[4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentario: Ac√° me di cuenta cuenta que hay variables categ√≥ricas nominales que fueron colocadas como ordinales Como customer_type y package, que son variables categ√≥ricas nominales (Aunque customer_type es debatible).\n",
    "En cualquier caso, solo hay que modificar la funci√≥n column_type, colocando las variables categoricas nominales a mano.\n",
    "\n",
    "La distirbuci√≥n que vale la pena ser√≠a de las variables categ√≥ricas y de la variable num√©rica como el tama√±o del producto, items, n√∫mero de visitas por semana y n√∫mero de delivery. Tal vez se podr√≠a hacer una distribuci√≥n de las coordenadas geogr√°ficas, pero no estoy segura.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para las columnas categ√≥ricas: \"category\" solo tiene un valor es ques \"BEBIDA GASEOSA\", Asi que la distribuci√≥n no tiene mucho sentido.\n",
    "\n",
    "for i in cat_nominal_columns:\n",
    "    plt.figure()\n",
    "    plt.title(f\"Distribucion de {i}\")\n",
    "    sns.histplot(data=df, x=i, shrink=0.5)\n",
    "    plt.xticks(fontsize=8, rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# items\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.title(\"Distribuci√≥n de Items\")\n",
    "sns.histplot(data=df, x=\"items\", log_scale=True, bins=20)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "# size\n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "plt.title(\"Distribuci√≥n de tama√±o del producto\")\n",
    "sns.histplot(data=df, x=\"size\", log_scale=True, bins=20)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "# num_deliver_per_week\n",
    "\n",
    "plt.figure(3)\n",
    "plt.clf()\n",
    "plt.title(\"Distribuci√≥n de N√∫mero de entregas por semana\")\n",
    "sns.histplot(data=df, x=\"num_deliver_per_week\", log_scale=False, bins=20)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ac√°: transformar ciertas variables categ√≥ricas a tipo string\n",
    "\n",
    "df[\"customer_id\"] = df[\"customer_id\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo que har√© ahora ser√° obtener los top 20 clientes que tienen mayor numero de transacciones y ver que tipo de producto compran, sea por segment, size\n",
    "# u otra cosa\n",
    "# y luego ver los que top 20 clientes que tienen el menor n√∫mero de transacciones.\n",
    "# lo que viene ser√≠a los brands que s√≥n m√°s y menos vendidos.\n",
    "# ver que producto se vende m√°s o tiene m√°s delivery por regi√≥n\n",
    "\n",
    "# tal vez hacer un cluster pero ya ser√≠a mucho.\n",
    "\n",
    "### los top 20 clientes que tienen mayor n√∫mero de transacciones\n",
    "\n",
    "# para cambiar los top 20 a cualquier n√∫mero, cambiar 20 por cualquier n√∫mero\n",
    "\n",
    "temp_orden_up = df.groupby([\"customer_id\", \"num_deliver_per_week\", \"X\", \"Y\"])[\"order_id\"].nunique().sort_values(ascending=False)\n",
    "\n",
    "temp_orden_down = df.groupby(\"customer_id\")[\"order_id\"].nunique().sort_values(ascending=True)\n",
    "\n",
    "\n",
    "top_up_clientes = temp_orden_up.head(20).reset_index(name=\"num_transacciones\")\n",
    "\n",
    "top_down_clientes = temp_orden_down.head(20).reset_index(name=\"num_transacciones\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gr√°ficos: solo para el top 20\n",
    "\n",
    "plt.figure(4, figsize=(10,8))\n",
    "plt.clf()\n",
    "plt.title(\"Top clientes que registran mayor n√∫mero de √≥rdenes del producto\")\n",
    "sns.barplot(data=top_up_clientes, x=\"num_transacciones\", y=\"customer_id\", hue=\"customer_id\", palette=\"viridis\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sobre segmentos\n",
    "\n",
    "segmentos_top = df[df[\"customer_id\"].isin(top_up_clientes[\"customer_id\"])].groupby([\"customer_id\", \n",
    "            \"segment\"])[\"order_id\"].nunique().reset_index(name=\"num_transacciones\")\n",
    "\n",
    "# gr√°fico\n",
    "\n",
    "plt.figure(5, figsize=(10,8))\n",
    "plt.clf()\n",
    "plt.title(\"Segment seg√∫n los top clientes\")\n",
    "sns.barplot(data=segmentos_top, x=\"num_transacciones\", y=\"customer_id\", hue=\"segment\", palette=\"magma\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size producto\n",
    "sizes_top = df[df[\"customer_id\"].isin(top_up_clientes[\"customer_id\"])].groupby([\"customer_id\", \n",
    "            \"size\"])[\"order_id\"].nunique().reset_index(name=\"num_transacciones\")\n",
    "\n",
    "sizes_top\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sobre las brands \n",
    "\n",
    "brands_por_zona = df.groupby([\"zone_id\", \"brand\"])[\"order_id\"].nunique().reset_index(name=\"num_transacciones\")\n",
    "\n",
    "brands_top = brands_por_zona.sort_values([\"zone_id\", \"num_transacciones\"], ascending=[True, False])\n",
    "\n",
    "\n",
    "# brands menos vendidas\n",
    "\n",
    "brands_bottom = brands_por_zona.sort_values([\"zone_id\", \"num_transacciones\"], ascending=[True, True])\n",
    "\n",
    "# gr√°fico de brands\n",
    "\n",
    "plt.figure(6, figsize=(10,8))\n",
    "plt.clf()\n",
    "plt.title(\"Top brands que registran mayor n√∫mero de √≥rdenes en la zona 5148\")\n",
    "sns.barplot(data=brands_top, x=\"num_transacciones\", y=\"brand\", hue=\"brand\", palette=\"viridis\")\n",
    "plt.xscale(\"log\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sobre las coordenadas X e Y\n",
    "\n",
    "temp_orden_up = df.groupby([\"customer_id\", \"num_deliver_per_week\", \"X\", \"Y\", \"customer_type\"])[\"order_id\"].nunique().sort_values(ascending=False)\n",
    "\n",
    "temp_orden_down = df.groupby([\"customer_id\", \"num_deliver_per_week\", \"X\", \"Y\", \"customer_type\"])[\"order_id\"].nunique().sort_values(ascending=True)\n",
    "\n",
    "\n",
    "top_up_clientes = temp_orden_up.head(50).reset_index(name=\"num_transacciones\")\n",
    "\n",
    "top_down_clientes = temp_orden_down.head(50).reset_index(name=\"num_transacciones\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=top_up_clientes, x=\"X\", y=\"Y\", size=\"num_deliver_per_week\", sizes=(20, 400), alpha=0.7)\n",
    "plt.title(\"Clientes: ubicaci√≥n vs entregas y visitas\")\n",
    "plt.legend(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=top_down_clientes, x=\"X\", y=\"Y\", size=\"num_deliver_per_week\", sizes=(20, 400), alpha=0.7)\n",
    "plt.title(\"Clientes: ubicaci√≥n vs entregas y visitas\")\n",
    "plt.legend(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union de los dataframes top up y top down de clientes, a ver si resulta\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "union_top_clientes = pd.concat([top_up_clientes, top_down_clientes])\n",
    "\n",
    "fig = px.scatter(union_top_clientes, x=\"X\", y=\"Y\", color=\"customer_type\", size=\"num_deliver_per_week\")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_top_clientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Holdout [0.25 puntos]\n",
    "\n",
    "Para evaluar correctamente el modelo y garantizar su capacidad de generalizaci√≥n, se deben dividir los datos en tres conjuntos: \n",
    "- `Entrenamiento` : Para ajustar los par√°metros.\n",
    "- `Validaci√≥n`: Para optimizar hiperpar√°metros y seleccionar el mejor modelo.\n",
    "- `Prueba` : Para evaluar el rendimiento final en datos no vistos.\n",
    "\n",
    "üëÄ **Hint**: *Recuerde que los datos tienen una temporalidad que debe considerarse al momento de separarlos, para evitar fugas de informaci√≥n. Es importante justificar la estrategia de partici√≥n elegida y visualizar la distribuci√≥n temporal de los conjuntos generados*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desarrolle aqu√≠ su c√≥digo\n",
    "\n",
    "# la partici√≥n de los datos: no tenemos que usar aleatoriedad, si no que trabajamos datos desde cierto un rango temporal y la data de validaci√≥n en otro rango temporal\n",
    "# subsiguiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Feature Engineering [0.5 puntos]\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/CmXZSSC.gif\" width=\"300\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta secci√≥n, se deben construir pipelines para automatizar el preprocesamiento de los datos, lo cual garantizar√° que el flujo de trabajo sea reproducible y eficiente para esta entrega y las futuras. El objetivo es aplicar una serie de transformaciones en un orden definido para asegurar que los datos est√©n listos para los modelos a entrenar. El pipeline final debe incluir las t√©cnicas de pre-procesamiento que se deben aplicar a los distintos datos (seg√∫n lo que consideren necesario para el problema). Por ejemplo:\n",
    "\n",
    "- **Imputaci√≥n de valores nulos**: Manejo de datos faltantes mediante estrategias adecuadas (media, mediana, moda, interpolaci√≥n, etc.). \n",
    "\n",
    "- **Transformaciones personalizadas**: Uso de ColumnTransformer para aplicar diferentes transformaciones a columnas espec√≠ficas.\n",
    "\n",
    "- **Codificaci√≥n de variables categ√≥ricas**: Convertir datos categ√≥ricos a un formato num√©rico adecuado (One-Hot Encoding, Label Encoding, etc.).\n",
    "\n",
    "- **Discretizaci√≥n de variables**: Conversi√≥n de variables num√©ricas continuas en categor√≠as si son relevantes para el desempe√±o del modelo a entrenar.\n",
    "\n",
    "- **Estandarizaci√≥n o normalizaci√≥n** : Ajustar la escala de los datos para mejorar el rendimiento de los algoritmos sensibles a la magnitud de las variables.\n",
    "\n",
    "- **Eliminaci√≥n o transformaci√≥n de valores at√≠picos**: Identificar y tratar con datos outliers para mejorar la robustez del modelo.\n",
    "\n",
    "- **Nuevas caracter√≠sticas** : Creaci√≥n de variables adicionales que puedan aportar informaci√≥n relevante al modelo.\n",
    "\n",
    "Cada una de estas transformaciones debe ser justificada en funci√≥n de su relevancia para el problema y los datos, y es importante evaluar su impacto en el rendimiento del modelo. Adem√°s, el pipeline debe ser flexible y modular para poder probar diferentes configuraciones de preprocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desarrolle aqu√≠ su c√≥digo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Baseline [0.25 puntos]\n",
    "\n",
    "<center>\n",
    "<img src=\"https://media1.giphy.com/media/v1.Y2lkPTc5MGI3NjExN3lzeGFqZmU3NzJrZHllNjRmaHVzczJpZ29rdHdlMzVpZnQwNXo1diZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/qAtZM2gvjWhPjmclZE/giphy.gif\" width=\"300\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta secci√≥n se debe construir el modelo m√°s sencillo posible que pueda resolver el problema planteado, conocido como **Modelo baseline**. Su prop√≥sito es servir como referencia para comparar el rendimiento de los modelos m√°s avanzados desarrollados en etapas posteriores.  \n",
    "\n",
    "Pasos requeridos:  \n",
    "- Implemente, entrene y eval√∫e un modelo b√°sico utilizando un pipeline.  \n",
    "- Aseg√∫rese de incluir en el pipeline las transformaciones del preprocesamiento realizadas previamente junto con un clasificador b√°sico.  \n",
    "- Eval√∫e el modelo y presente el informe de m√©tricas utilizando **`classification_report`**.  \n",
    "\n",
    "Documente claramente c√≥mo se cre√≥ el modelo, las decisiones tomadas y los resultados obtenidos. Este modelo ser√° la base comparativa en las secciones posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desarrolle aqu√≠ su c√≥digo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Elecci√≥n de modelo [0.75 puntos]\n",
    "\n",
    "En esta secci√≥n deben escoger un modelo que se adapte a las necesidades del negocio. Para esto, pruebe al menos 3 modelos y desarrolle los siguientes aspectos para cada uno:\n",
    "\n",
    "- **Estructura y diferencias entre los modelos**: Explicar brevemente cada uno y sus hip√©rpar√°metros de mayor importancia.\n",
    "- **Clasificadores recomendados**:\n",
    "  - `LogisticRegression`\n",
    "  - `KNeighborsClassifier`\n",
    "  - `DecisionTreeClassifier`\n",
    "  - `SVC`\n",
    "  - `RandomForestClassifier`\n",
    "  - `LightGBMClassifier` (del paquete `lightgbm`)\n",
    "  - `XGBClassifier` (del paquete `xgboost`)\n",
    "  - Otro (seg√∫n lo que se estime adecuado)\n",
    "  \n",
    "- **Evaluaci√≥n de resultados**: Se utilizar√° el **`classification_report`** para evaluar el rendimiento de cada modelo, destacando m√©tricas clave como precisi√≥n, recall y F1-score. **Importante: No optimicen hiperpar√°metros, la idea es hacer una selecci√≥n r√°pida del modelo.**\n",
    "\n",
    "**Nota:** Pueden ocupar mas de 1 **instancia** de modelo para resolver el problema (e.g: (modelo_1, grupo_1), (modelo_2, grupo_2), ...).\n",
    "  \n",
    "A continuaci√≥n, se deben responder las siguientes preguntas para evaluar el rendimiento de los modelos entrenados:\n",
    "\n",
    "1. ¬øHay alg√∫n clasificador que supere al modelo baseline?  \n",
    "2. ¬øCu√°l es el mejor clasificador entrenado y por qu√©?  \n",
    "3. ¬øQu√© factores hacen que el mejor clasificador sea superior a los otros?  \n",
    "4. En t√©rminos de `tiempo de entrenamiento`, ¬øQu√© modelo considera m√°s adecuado para experimentar con grillas de optimizaci√≥n?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desarrolle aqu√≠ su c√≥digo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Optimizaci√≥n de Hiperpar√°metros [1.0 puntos]\n",
    "\n",
    "<center>\n",
    "<img src=\"https://media1.giphy.com/media/v1.Y2lkPTc5MGI3NjExcXJkNzdhYjlneHplaGpsbnVkdzh5dnY3Y2VyaTIzamszdGR1czJ2diZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/2rqEdFfkMzXmo/giphy.gif\" width=\"300\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de su an√°lisis anterior, se debe proceder a optimizar el rendimiento del modelo seleccionado mediante la optimizaci√≥n de sus hiperpar√°metros. Para ello, se espera que implementen `Optuna` para optimizar no solo los hiperpar√°metros del modelo, sino tambi√©n los de los preprocesadores utilizados (por ejemplo, OneHot Encoding, Scalers, etc.).\n",
    "\n",
    "Al desarrollar este proceso, deber√°n responder las siguientes preguntas clave como m√≠nimo:\n",
    "\n",
    "- ¬øQu√© m√©trica decidieron optimizar y por qu√©?\n",
    "\n",
    "- ¬øQu√© hiperpar√°metro tuvo un mayor impacto en el rendimiento de su modelo?\n",
    "\n",
    "- ¬øCu√°nto mejor√≥ el rendimiento del modelo despu√©s de la optimizaci√≥n de hiperpar√°metros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desarrolle aqu√≠ su c√≥digo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Interpretabilidad [1.0 puntos]\n",
    "\n",
    "En esta secci√≥n, deben explicar el funcionamiento de su modelo utilizando las t√©cnicas de interpretabilidad vistas en clase, como `SHAP`. Se espera que sean capaces de descomponer las predicciones y evaluar la importancia de los atributos y las interacciones entre ellos, con el fin de obtener una comprensi√≥n m√°s profunda de c√≥mo el modelo toma decisiones. \n",
    "\n",
    "Al desarrollar esta parte, deber√°n responder las siguientes preguntas clave como m√≠nimo:\n",
    "\n",
    "- ¬øPodr√≠a explicar el funcionamiento de su modelo para una predicci√≥n en particular? Si es as√≠, proporcione al menos tres ejemplos espec√≠ficos, describiendo c√≥mo el modelo lleg√≥ a sus decisiones y qu√© factores fueron m√°s relevantes en cada caso.\n",
    "\n",
    "- ¬øQu√© atributo tiene una mayor importancia en la salida de su modelo? Analice si esto tiene sentido con el problema planteado y justifique la relevancia de dicho atributo en el contexto de las predicciones que se realizan.\n",
    "\n",
    "- ¬øExiste alguna interacci√≥n entre atributos que sea relevante para el modelo? Investigue si la combinaci√≥n de ciertos atributos tiene un impacto significativo en las predicciones y expl√≠quela en **detalle**.\n",
    "\n",
    "- ¬øPodr√≠a existir sesgo hacia alg√∫n atributo en particular? Reflexione sobre la posibilidad de que el modelo est√© favoreciendo ciertos atributos. Si es as√≠, ¬øcu√°l podr√≠a ser la causa y qu√© impacto podr√≠a tener esto en la predicci√≥n?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desarrolle aqu√≠ su c√≥digo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Resultados y Conclusiones [1.0 puntos]\n",
    "\n",
    "Para finalizar, se deben explicar los desarrollos y resultados obtenidos a lo largo de todo el proceso, desde la selecci√≥n de las variables hasta la optimizaci√≥n de hiperpar√°metros e interpretaci√≥n. Se espera una reflexi√≥n cr√≠tica sobre el desempe√±o de los modelos entrenados y una comparaci√≥n entre los diferentes enfoques. Adem√°s, deber√°n abordar los siguientes puntos clave:\n",
    "\n",
    "- **An√°lisis de m√©tricas**: Comenten sobre las m√©tricas obtenidas en cada etapa del modelo, destacando las m√°s relevantes como precisi√≥n, recall, F1-score, etc. ¬øCu√°les fueron los modelos m√°s efectivos? ¬øQu√© diferencias notables encontr√≥ entre ellos?\n",
    "\n",
    "- **Impacto de las decisiones tomadas**: Reflexionen sobre c√≥mo las decisiones relacionadas con el preprocesamiento, selecci√≥n de atributos y optimizaci√≥n de hiperpar√°metros influyeron en los resultados finales. ¬øHubo alguna decisi√≥n que haya tenido un impacto notable en el rendimiento?\n",
    "\n",
    "- **Lecciones aprendidas**: Concluyan sobre las lecciones m√°s importantes que aprendieron durante el proceso y c√≥mo estas pueden influir en futuras iteraciones del modelo. ¬øQu√© se podr√≠a mejorar si se repitiera el proceso? Si tuvieran m√°s recursos y tiempo, ¬øqu√© otras t√©cnicas/herramientas habr√≠an utilizado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [Escriba aqu√≠ sus resultados]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mucho √©xito!\n",
    "\n",
    "<center>\n",
    "<img src=\"https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExaHpvOTY5Z3hpdHI3aDBpdGRueXRqamZncXp2emFrbjJ5M2s5eTR1dSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/1PMVNNKVIL8Ig/giphy.gif\" width=\"300\" height=\"200\">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
