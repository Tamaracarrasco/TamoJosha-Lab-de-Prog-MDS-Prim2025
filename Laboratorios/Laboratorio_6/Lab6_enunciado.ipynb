{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b5c0d2440b3e4995a794ded565213150",
        "deepnote_cell_type": "markdown",
        "id": "_Mql1uRoI5v5"
      },
      "source": [
        "<h1><center>Laboratorio 6: Optimizaci칩n de modelos 游빍</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos - Primavera 2025</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bfb94b9656f145ad83e81b75d218cb70",
        "deepnote_cell_type": "markdown",
        "id": "FAPGIlEAI5v8"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Diego Cortez, Gabriel Iturra\n",
        "- Auxiliares: Melanie Pe침a, Valentina Rojas\n",
        "- Ayudantes: Nicol치s Cabello, Cristopher Urbina"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b1b537fdd27c43909a49d3476ce64d91",
        "deepnote_cell_type": "markdown",
        "id": "8NozgbkZI5v9"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados\n",
        "\n",
        "- Nombre de alumno 1: Josefa Anselmo.\n",
        "- Nombre de alumno 2: Tamara Carrasco.\n",
        "\n",
        "\n",
        "Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: Entregas Martes a las 23:59.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda **fuertemente** asistir.\n",
        "- <u>Prohibidas las copias</u>. Cualquier intento de copia ser치 debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est칠n en u-cursos no ser치n revisados. Recuerden que el repositorio tambi칠n tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
        "- Pueden usar cualquier material del curso que estimen conveniente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8qWRbJkcwP9"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [TamoJosha](https://github.com/Tamaracarrasco/TamoJosha-Lab-de-Prog-MDS-Prim2025)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b7dbdd30ab544cb8a8afe00648a586ae",
        "deepnote_cell_type": "markdown",
        "id": "vHU9DI6wI5v9"
      },
      "source": [
        "### Temas a tratar\n",
        "\n",
        "- Predicci칩n de demanda usando `xgboost`\n",
        "- B칰squeda del modelo 칩ptimo de clasificaci칩n usando `optuna`\n",
        "- Uso de pipelines.\n",
        "\n",
        "\n",
        "### Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: 6 d칤as de plazo con descuento de 1 punto por d칤a. Entregas Martes a las 23:59.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda fuertemente asistir.\n",
        "- <u>Prohibidas las copias</u>. Cualquier intento de copia ser치 debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est칠n en u-cursos no ser치n revisados. Recuerden que el repositorio tambi칠n tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
        "- Pueden usar cualquier material del curso que estimen conveniente.\n",
        "\n",
        "El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f1c73babb7f74af588a4fa6ae14829e0",
        "deepnote_cell_type": "markdown",
        "id": "U_-sNOuOI5v9"
      },
      "source": [
        "# Importamos librerias 칰tiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cell_id": "51afe4d2df42442b9e5402ffece60ead",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 4957,
        "execution_start": 1699544354044,
        "id": "ekHbM85NI5v9",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "!pip install -qq xgboost optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6hJXpLCSspz"
      },
      "source": [
        "# El emprendimiento de Fiu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "44d227389a734ac59189c5e0005bc68a",
        "deepnote_cell_type": "markdown",
        "id": "b0bDalAOI5v-"
      },
      "source": [
        "Tras liderar de manera exitosa la implementaci칩n de un proyecto de ciencia de datos para caracterizar los datos generados en Santiago 2023, el misterioso corp칩reo **Fiu** se anima y decide levantar su propio negocio de consultor칤a en machine learning. Tras varias e intensas negociaciones, Fiu logra encontrar su *primera chamba*: predecir la demanda (cantidad de venta) de una famosa productora de bebidas de calibre mundial. Al ver el gran potencial y talento que usted ha demostrado en el campo de la ciencia de datos, Fiu lo contrata como data scientist para que forme parte de su nuevo emprendimiento.\n",
        "\n",
        "Para este laboratorio deben trabajar con los datos `sales.csv` subidos a u-cursos, el cual contiene una muestra de ventas de la empresa para diferentes productos en un determinado tiempo.\n",
        "\n",
        "Para comenzar, cargue el dataset se침alado y visualice a trav칠s de un `.head` los atributos que posee el dataset.\n",
        "\n",
        "<i><p align=\"center\">Fiu siendo felicitado por su excelente desempe침o en el proyecto de caracterizaci칩n de datos</p></i>\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media-front.elmostrador.cl/2023/09/A_UNO_1506411_2440e.jpg\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cell_id": "2f9c82d204b14515ad27ae07e0b77702",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 92,
        "execution_start": 1699544359006,
        "id": "QvMPOqHuI5v-",
        "source_hash": null
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>city</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>pop</th>\n",
              "      <th>shop</th>\n",
              "      <th>brand</th>\n",
              "      <th>container</th>\n",
              "      <th>capacity</th>\n",
              "      <th>price</th>\n",
              "      <th>quantity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>0.96</td>\n",
              "      <td>13280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>plastic</td>\n",
              "      <td>1.5lt</td>\n",
              "      <td>2.86</td>\n",
              "      <td>6727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>can</td>\n",
              "      <td>330ml</td>\n",
              "      <td>0.87</td>\n",
              "      <td>9848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>adult-cola</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>1.00</td>\n",
              "      <td>20050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>adult-cola</td>\n",
              "      <td>can</td>\n",
              "      <td>330ml</td>\n",
              "      <td>0.39</td>\n",
              "      <td>25696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>orange-power</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>1.00</td>\n",
              "      <td>15041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>orange-power</td>\n",
              "      <td>can</td>\n",
              "      <td>330ml</td>\n",
              "      <td>0.43</td>\n",
              "      <td>34578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>gazoza</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>0.49</td>\n",
              "      <td>44734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>lemon-boost</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>0.70</td>\n",
              "      <td>18623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>lemon-boost</td>\n",
              "      <td>plastic</td>\n",
              "      <td>1.5lt</td>\n",
              "      <td>2.21</td>\n",
              "      <td>9645</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id      date    city       lat      long     pop    shop         brand  \\\n",
              "0   0  31/01/12  Athens  37.97945  23.71622  672130  shop_1   kinder-cola   \n",
              "1   1  31/01/12  Athens  37.97945  23.71622  672130  shop_1   kinder-cola   \n",
              "2   2  31/01/12  Athens  37.97945  23.71622  672130  shop_1   kinder-cola   \n",
              "3   3  31/01/12  Athens  37.97945  23.71622  672130  shop_1    adult-cola   \n",
              "4   4  31/01/12  Athens  37.97945  23.71622  672130  shop_1    adult-cola   \n",
              "5   5  31/01/12  Athens  37.97945  23.71622  672130  shop_1  orange-power   \n",
              "6   6  31/01/12  Athens  37.97945  23.71622  672130  shop_1  orange-power   \n",
              "7   7  31/01/12  Athens  37.97945  23.71622  672130  shop_1        gazoza   \n",
              "8   8  31/01/12  Athens  37.97945  23.71622  672130  shop_1   lemon-boost   \n",
              "9   9  31/01/12  Athens  37.97945  23.71622  672130  shop_1   lemon-boost   \n",
              "\n",
              "  container capacity  price  quantity  \n",
              "0     glass    500ml   0.96     13280  \n",
              "1   plastic    1.5lt   2.86      6727  \n",
              "2       can    330ml   0.87      9848  \n",
              "3     glass    500ml   1.00     20050  \n",
              "4       can    330ml   0.39     25696  \n",
              "5     glass    500ml   1.00     15041  \n",
              "6       can    330ml   0.43     34578  \n",
              "7     glass    500ml   0.49     44734  \n",
              "8     glass    500ml   0.70     18623  \n",
              "9   plastic    1.5lt   2.21      9645  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "df = pd.read_csv(\"sales.csv\")\n",
        "\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dimensiones del dataset:\n",
            " (7456, 12)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7456 entries, 0 to 7455\n",
            "Data columns (total 12 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   id         7456 non-null   int64  \n",
            " 1   date       7456 non-null   object \n",
            " 2   city       7456 non-null   object \n",
            " 3   lat        7456 non-null   float64\n",
            " 4   long       7456 non-null   float64\n",
            " 5   pop        7456 non-null   int64  \n",
            " 6   shop       7456 non-null   object \n",
            " 7   brand      7456 non-null   object \n",
            " 8   container  7456 non-null   object \n",
            " 9   capacity   7456 non-null   object \n",
            " 10  price      7456 non-null   float64\n",
            " 11  quantity   7456 non-null   int64  \n",
            "dtypes: float64(3), int64(3), object(6)\n",
            "memory usage: 699.1+ KB\n",
            "\n",
            " Tipo de valores en las columnas: \n",
            " None\n",
            "\n",
            " Cantidad de valores nulos: \n",
            " id           0\n",
            "date         0\n",
            "city         0\n",
            "lat          0\n",
            "long         0\n",
            "pop          0\n",
            "shop         0\n",
            "brand        0\n",
            "container    0\n",
            "capacity     0\n",
            "price        0\n",
            "quantity     0\n",
            "dtype: int64\n",
            "\n",
            " Valores duplicados: \n",
            " 0\n",
            "\n",
            " describe de las variables n칰mericas: \n",
            "                 id          lat         long            pop        price  \\\n",
            "count  7456.000000  7456.000000  7456.000000    7456.000000  7456.000000   \n",
            "mean   3784.926770    38.300616    23.270170  355042.733637     1.197193   \n",
            "std    2185.822361     1.650030     1.086592  232336.703020     0.818175   \n",
            "min       0.000000    35.327870    21.734440  134219.000000     0.110000   \n",
            "25%    1889.750000    37.962450    22.417610  141732.000000     0.620000   \n",
            "50%    3783.500000    38.244440    22.930860  257501.500000     0.930000   \n",
            "75%    5682.250000    39.636890    23.716220  665102.000000     1.510000   \n",
            "max    7559.000000    40.643610    25.143410  672130.000000     4.790000   \n",
            "\n",
            "            quantity  \n",
            "count    7456.000000  \n",
            "mean    29408.428380  \n",
            "std     17652.985675  \n",
            "min      2953.000000  \n",
            "25%     16572.750000  \n",
            "50%     25294.500000  \n",
            "75%     37699.000000  \n",
            "max    145287.000000  \n",
            "\n",
            " Estad칤sticas de las variables no num칠ricas: \n",
            "             date    city    shop        brand container capacity\n",
            "count       7456    7456    7456         7456      7456     7456\n",
            "unique        84       5       6            5         3        3\n",
            "top     31/12/18  Athens  shop_4  kinder-cola     glass    330ml\n",
            "freq          90    2482    1246         1495      2486     2486\n",
            "\n",
            " ========= RANGO TEMPORAL (Aparente) =========\n",
            "Fecha inicial:  28/02/13\n",
            "칰ltima fecha:  31/12/18\n"
          ]
        }
      ],
      "source": [
        "## Exploraci칩n b치sica de los datos\n",
        "\n",
        "print(\"\\nDimensiones del dataset:\\n\", df.shape)\n",
        "print(\"\\n Tipo de valores en las columnas: \\n\", df.info())\n",
        "print(\"\\n Cantidad de valores nulos: \\n\", df.isna().sum())\n",
        "print(\"\\n Valores duplicados: \\n\", df.duplicated().sum())\n",
        "print(\"\\n describe de las variables n칰mericas: \\n\", df.select_dtypes(include=\"number\").describe())\n",
        "print(\"\\n Estad칤sticas de las variables no num칠ricas: \\n\", df.select_dtypes(include=\"object\").describe())\n",
        "\n",
        "## Rango temporal de los datos.\n",
        "\n",
        "print(\"\\n ========= RANGO TEMPORAL (Aparente) =========\")\n",
        "print(\"Fecha inicial: \", df[\"date\"].min())\n",
        "print(\"칰ltima fecha: \", df[\"date\"].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Comentario**\n",
        "\n",
        " De las estad칤sticas, se desprende lo siguiente:\n",
        "- NO hay valores nulos.\n",
        "- No hay valores duplicados.\n",
        "- Al parecer no hay valores raros como cantidades de \"quantity\" negativas.\n",
        "- dentro de las variables categ칩ricas, ``capacity`` es una variable categ칩rica ordinal. El resto de variables categ칩ricas son nominales.\n",
        "- Se tiene ``date``, serie de tiempo.\n",
        "\n",
        "\n",
        "- Se tienen 5 ciudades:  Athens, Thessaloniki, Patra, Larisa, Irakleion.\n",
        "- Hay 6 tiendas distintas: shop_1,..., shop_6.\n",
        "\t* shop_1 solo est치 en Athens.\n",
        "\t* shop_2 solo est치 en Irakleion.\n",
        "\t* shop_3 tambi칠n est치 en Athens.\n",
        "\t* shop_4 est치 en Thessaloniki.\n",
        "\t* shop_5 est치 en Larisa.\n",
        "\t* shop_6 est치 en Patra.\n",
        "\n",
        "- Se tienen 5 marcas posibles:\n",
        "\t* kinder-cola: plastic, can, glass\n",
        "\t* adult-cola: plastic, can, glass\n",
        "\t* lemon-boost: glass, can, plastic\n",
        "\t* gazoza: glass, plastic, can\n",
        "\t* orange-power: glass, can, plastic\n",
        "    \t\n",
        "- hay 3 tipos de envase (container):\n",
        "\t- glass: hay de capacidad de 500ml y 330 ml\n",
        "\t- can:  tiene solo capacidad de 330ml\n",
        "\t- plastic: tiene solo de 1.5lts\n",
        "\n",
        "**La variable target es ``quantity`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b50db6f2cb804932ae3f9e5748a6ea61",
        "deepnote_cell_type": "markdown",
        "id": "pk4ru76pI5v_"
      },
      "source": [
        "## 1 Generando un Baseline (5 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/O-lan6TkadUAAAAC/what-i-wnna-do-after-a-baseline.gif\">\n",
        "</p>\n",
        "\n",
        "Antes de entrenar un algoritmo, usted recuerda los apuntes de su mag칤ster en ciencia de datos y recuerda que debe seguir una serie de *buenas pr치cticas* para entrenar correcta y debidamente su modelo. Despu칠s de un par de vueltas, llega a las siguientes tareas:\n",
        "\n",
        "1. Separe los datos en conjuntos de train (70%), validation (20%) y test (10%). Fije una semilla para controlar la aleatoriedad. [0.5 puntos]\n",
        "2. Implemente un `FunctionTransformer` para extraer el d칤a, mes y a침o de la variable `date`. Guarde estas variables en el formato categorical de pandas. [1 punto]\n",
        "3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos num칠ricos y categ칩ricos. Use `OneHotEncoder` para las variables categ칩ricas. `Nota:` Utilice el m칠todo `.set_output(transform='pandas')` para obtener un DataFrame como salida del `ColumnTransformer` [1 punto]\n",
        "4. Guarde los pasos anteriores en un `Pipeline`, dejando como 칰ltimo paso el regresor `DummyRegressor` para generar predicciones en base a promedios. [0.5 punto]\n",
        "5. Entrene el pipeline anterior y reporte la m칠trica `mean_absolute_error` sobre los datos de validaci칩n. 쮺칩mo se interpreta esta m칠trica para el contexto del negocio? [0.5 puntos]\n",
        "6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los par치metros por default**. 쮺칩mo cambia el MAE al implementar este algoritmo? 쮼s mejor o peor que el `DummyRegressor`? [1 punto]\n",
        "7. Guarde ambos modelos en un archivo .pkl (uno cada uno) [0.5 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%!pip` not found.\n"
          ]
        }
      ],
      "source": [
        "%!pip install autopep8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cell_id": "1482c992d9494e5582b23dbd3431dbfd",
        "deepnote_cell_type": "code",
        "id": "sfnN7HubI5v_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valor MAE (DummyRegressor) para conjunto Validaci칩n:  12484.902691741254\n",
            "Valor MAE (XGBRegressor) para conjunto Validaci칩n:  2868.03515625\n"
          ]
        }
      ],
      "source": [
        "# importaci칩n de librer칤as importantes.\n",
        "\n",
        "# separacion de conjuntos\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# para el pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# m칠tricas\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error as MAE\n",
        "\n",
        "# para guardar los modelos con pickle\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "from sklearn import set_config\n",
        "set_config(transform_output=\"pandas\")\n",
        "\n",
        "# Inserte su c칩digo ac치\n",
        "\n",
        "# Definici칩n de FunctionTraformer (Punto 2)\n",
        "\n",
        "\n",
        "def extrae_fecha(dataframe_in, col=\"date\"):\n",
        "    \"\"\"\n",
        "    Esta funci칩n deber칤a estraer el d칤a, mes y a침o\n",
        "    de la variable \"date\" de un dataframe.\n",
        "    Guarda las variables en el formato categ칩rico\n",
        "    de pandas.\n",
        "\n",
        "    Par치metros:\n",
        "    -------------------\n",
        "    dataframe_in: dataframe para extraer los datos. \n",
        "    Debe contener columna \"date\".\n",
        "\n",
        "    col: columna de la fecha. Default \"date\".\n",
        "\n",
        "    \"\"\"\n",
        "    # primer transformamos esa columna a una nueva\n",
        "\n",
        "    df_copy = dataframe_in.copy()\n",
        "\n",
        "    df_copy[\"fecha\"] = pd.to_datetime(\n",
        "        df_copy[col], dayfirst=True, errors=\"coerce\", format=\"%d/%m/%y\")\n",
        "\n",
        "    # se crean las columnas de d칤a, mes y a침o.\n",
        "\n",
        "    df_copy[\"day\"] = df_copy[\"fecha\"].dt.day.astype(\"category\")\n",
        "    df_copy[\"month\"] = df_copy[\"fecha\"].dt.month.astype(\"category\")\n",
        "    df_copy[\"year\"] = df_copy[\"fecha\"].dt.year.astype(\"category\")\n",
        "\n",
        "    return df_copy\n",
        "\n",
        "\n",
        "date_transformer = FunctionTransformer(extrae_fecha)\n",
        "\n",
        "\n",
        "# SEPARACI칍N DE CONJUNTOS (Punto 1)\n",
        "\n",
        "df_x = df.drop(columns=\"quantity\").copy()\n",
        "df_y = df[\"quantity\"]\n",
        "\n",
        "\n",
        "# fijo el random state por si acaso.\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    df_x, df_y, random_state=42, shuffle=False, stratify=None, train_size=0.7)\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_val, y_val, test_size=0.33, shuffle=False, stratify=None, random_state=42)\n",
        "\n",
        "\n",
        "drop_cols = [\"id\"]\n",
        "\n",
        "num_cols = [\"lat\", \"long\", \"pop\", \"price\"]\n",
        "cat_cols = [\"city\", \"shop\", \"brand\", \"container\",\n",
        "            \"capacity\", \"day\", \"month\", \"year\"]\n",
        "\n",
        "# PIPELINES POR GRUPO (punto 3)\n",
        "\n",
        "num_std_pipeline = Pipeline(\n",
        "    [\n",
        "        # aunque no hayna nulos, coloco esto por completitud\n",
        "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"sc\", StandardScaler())\n",
        "    ]\n",
        ")\n",
        "\n",
        "cat_pipeline = Pipeline(\n",
        "    [\n",
        "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(\n",
        "            handle_unknown=\"ignore\", sparse_output=False\n",
        "        ))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# COLUMN TRANSFORMER (PARTE 3)\n",
        "\n",
        "col_transformer = ColumnTransformer(\n",
        "    [\n",
        "        (\"drop_ids\", \"drop\", drop_cols),\n",
        "        (\"numerical\", num_std_pipeline, num_cols),\n",
        "        (\"categorical\", cat_pipeline, cat_cols)\n",
        "    ], verbose_feature_names_out=False, remainder=\"drop\"\n",
        ")\n",
        "\n",
        "col_transformer.set_output(transform=\"pandas\")\n",
        "\n",
        "\n",
        "# PIPELINE DEL MODELO (PARTE 4)\n",
        "\n",
        "pipeline_dummyreg = Pipeline(\n",
        "    steps=[\n",
        "        (\"date_features\", date_transformer),\n",
        "        (\"col_transformer\", col_transformer),\n",
        "        (\"regresor_dummy\", DummyRegressor(strategy=\"mean\"))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ENTRENAMIENTO DEL MODELO DUMMYREGRESSOR\n",
        "\n",
        "pipeline_dummyreg.fit(X_train, y_train)\n",
        "\n",
        "# PREDICCIONES DUMMYREGRESSOR\n",
        "\n",
        "y_pred_val_dummyreg = pipeline_dummyreg.predict(X_val)\n",
        "\n",
        "#### REPORTE DUMMY MAE para dummyregressor (PARTE 5)\n",
        "\n",
        "print(\"Valor MAE (DummyRegressor) para conjunto Validaci칩n: \",\n",
        "      MAE(y_val, y_pred_val_dummyreg))\n",
        "\n",
        "### XGBOOST (PARTE 6)\n",
        "\n",
        "pipeline_xgb = Pipeline(\n",
        "    steps=[\n",
        "        (\"date_features\", date_transformer),\n",
        "        (\"col_transformer\", col_transformer),\n",
        "        (\"regresor_xgb\", XGBRegressor(random_state=42))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ENTRENAMIENTO DEL MODELO XGBOOST REGRESSOR\n",
        "\n",
        "pipeline_xgb.fit(X_train, y_train)\n",
        "\n",
        "# PREDICCIONES XGBOOST REGRESSOR\n",
        "\n",
        "y_pred_val_xgb = pipeline_xgb.predict(X_val)\n",
        "\n",
        "# reporte de m칠trica MAE para xgb regressor\n",
        "\n",
        "print(\"Valor MAE (XGBRegressor) para conjunto Validaci칩n: \",\n",
        "      MAE(y_val, y_pred_val_xgb))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**interpretaci칩n de la comparaci칩n de los MAE's**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PARTE 7: Guardado de modelos\n",
        "\n",
        "# Para dummy_regressor\n",
        "\n",
        "# Definir carpeta base para dummyregresor\n",
        "base_path = os.path.join(os.getcwd(), \"Laboratorios\", \"Laboratorio_6\", \"data\")\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# Guardar predicciones\n",
        "pd.DataFrame({\"predicciones\": y_pred_val_dummyreg}).to_csv(\n",
        "    os.path.join(base_path, \"predicciones_dummy_regressor.csv\"), index=False\n",
        ")\n",
        "\n",
        "# Guardar modelo\n",
        "with open(os.path.join(base_path, \"dummy_regressor_model.sav\"), \"wb\") as f:\n",
        "    pickle.dump(pipeline_dummyreg, f)\n",
        "\n",
        "# Cargar modelo\n",
        "with open(os.path.join(base_path, \"dummy_regressor_model.sav\"), \"rb\") as f:\n",
        "    modelo_loaded = pickle.load(f)\n",
        "\n",
        "# # Usar modelo cargado\n",
        "# y_pred_modelo_loaded = modelo_loaded.predict(X_val)\n",
        "\n",
        "# para xgboost regressor\n",
        "\n",
        "# Definir carpeta base para xgboost\n",
        "base_path = os.path.join(os.getcwd(), \"Laboratorios\", \"Laboratorio_6\", \"data\")\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# Guardar predicciones\n",
        "pd.DataFrame({\"predicciones\": y_pred_val_xgb}).to_csv(\n",
        "    os.path.join(base_path, \"predicciones_xgb_regressor.csv\"), index=False\n",
        ")\n",
        "\n",
        "# Guardar modelo\n",
        "with open(os.path.join(base_path, \"xgb_regressor_model.sav\"), \"wb\") as f:\n",
        "    pickle.dump(pipeline_xgb, f)\n",
        "\n",
        "# Cargar modelo\n",
        "with open(os.path.join(base_path, \"xgb_regressor_model.sav\"), \"rb\") as f:\n",
        "    modelo_loaded = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "7e17e46063774ec28226fe300d42ffe0",
        "deepnote_cell_type": "markdown",
        "id": "wnyMINdKI5v_"
      },
      "source": [
        "## 2. Forzando relaciones entre par치metros con XGBoost (10 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://64.media.tumblr.com/14cc45f9610a6ee341a45fd0d68f4dde/20d11b36022bca7b-bf/s640x960/67ab1db12ff73a530f649ac455c000945d99c0d6.gif\">\n",
        "</p>\n",
        "\n",
        "Un colega aficionado a la econom칤a le *sopla* que la demanda guarda una relaci칩n inversa con el precio del producto. Motivado para impresionar al querido corp칩reo, se propone hacer uso de esta informaci칩n para mejorar su modelo realizando las siguientes tareas:\n",
        "\n",
        "1. Vuelva a entrenar el `Pipeline` con `XGBRegressor`, pero esta vez forzando una relaci칩n mon칩tona negativa entre el precio y la cantidad. Para aplicar esta restricci칩n ap칩yese en la siguiente <a href = https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html>documentaci칩n</a>. [6 puntos]\n",
        "\n",
        ">Hint 1: Para implementar el constraint se le sugiere hacerlo especificando el nombre de la variable. De ser as칤, probablemente le sea 칰til **mantener el formato de pandas** antes del step de entrenamiento.\n",
        "\n",
        ">Hint 2: Puede obtener el nombre de las columnas en el paso anterior al modelo regresor mediante el m칠todo `.get_feature_names_out()`\n",
        "\n",
        "2. Luego, vuelva a reportar el `MAE` sobre el conjunto de validaci칩n. [1 puntos]\n",
        "\n",
        "3. 쮺칩mo cambia el error al incluir esta relaci칩n? 쯊en칤a raz칩n su amigo? [2 puntos]\n",
        "\n",
        "4. Guarde su modelo en un archivo .pkl [1 punto]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['lat' 'long' 'pop' 'price' 'city_Athens' 'city_Irakleion' 'city_Larisa'\n",
            " 'city_Patra' 'city_Thessaloniki' 'shop_shop_1' 'shop_shop_2'\n",
            " 'shop_shop_3' 'shop_shop_4' 'shop_shop_5' 'shop_shop_6'\n",
            " 'brand_adult-cola' 'brand_gazoza' 'brand_kinder-cola' 'brand_lemon-boost'\n",
            " 'brand_orange-power' 'container_can' 'container_glass'\n",
            " 'container_plastic' 'capacity_1.5lt' 'capacity_330ml' 'capacity_500ml'\n",
            " 'day_28' 'day_29' 'day_30' 'day_31' 'month_1' 'month_2' 'month_3'\n",
            " 'month_4' 'month_5' 'month_6' 'month_7' 'month_8' 'month_9' 'month_10'\n",
            " 'month_11' 'month_12' 'year_2012' 'year_2013' 'year_2014' 'year_2015'\n",
            " 'year_2016']\n"
          ]
        }
      ],
      "source": [
        "## Hint 1 y 2: obtener el nombre de las columnas en el\n",
        "## paso anterior \n",
        "## pipeline_xgb.get_feature_names_out() no funciona porque \n",
        "## date_trasnformer,  al ser un FunctionTrasnformer, no tiene ese m칠todo.\n",
        "\n",
        "X_train_trans = pipeline_xgb.named_steps[\"date_features\"].transform(X_train)\n",
        "X_train_trans = pipeline_xgb.named_steps[\"col_transformer\"].fit_transform(X_train_trans)\n",
        "\n",
        "features_names = pipeline_xgb.named_steps[\"col_transformer\"].get_feature_names_out()\n",
        "print(features_names)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'lat': 0, 'long': 0, 'pop': 0, 'price': -1, 'city_Athens': 0, 'city_Irakleion': 0, 'city_Larisa': 0, 'city_Patra': 0, 'city_Thessaloniki': 0, 'shop_shop_1': 0, 'shop_shop_2': 0, 'shop_shop_3': 0, 'shop_shop_4': 0, 'shop_shop_5': 0, 'shop_shop_6': 0, 'brand_adult-cola': 0, 'brand_gazoza': 0, 'brand_kinder-cola': 0, 'brand_lemon-boost': 0, 'brand_orange-power': 0, 'container_can': 0, 'container_glass': 0, 'container_plastic': 0, 'capacity_1.5lt': 0, 'capacity_330ml': 0, 'capacity_500ml': 0, 'day_28': 0, 'day_29': 0, 'day_30': 0, 'day_31': 0, 'month_1': 0, 'month_2': 0, 'month_3': 0, 'month_4': 0, 'month_5': 0, 'month_6': 0, 'month_7': 0, 'month_8': 0, 'month_9': 0, 'month_10': 0, 'month_11': 0, 'month_12': 0, 'year_2012': 0, 'year_2013': 0, 'year_2014': 0, 'year_2015': 0, 'year_2016': 0}\n"
          ]
        }
      ],
      "source": [
        "## ahora se tiene el orden real de las columnas\n",
        "## todas las columnas que no sean \"price\", deben llevar 0\n",
        "## para price debe ser -1\n",
        "\n",
        "monotone_constraints_mapeo = {name: 0 for name in features_names} # ac치 se genera un diccionario con 0's \n",
        "\n",
        "monotone_constraints_mapeo[\"price\"] = -1 # se pone -1 porque es una relaci칩n inversa con quantity\n",
        "                                            # decreasing constraint\n",
        "\n",
        "print(monotone_constraints_mapeo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "monotone_constraints_mapeo[\"price\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# se genera lista con los valores del diccionario de arriba\n",
        "monotone_constraints = [monotone_constraints_mapeo[name] for name in features_names] # [0, 0, 0, -1, ..., 0]\n",
        "\n",
        "# ahora se tiene que transformar a tupla\n",
        "\n",
        "monotone_constraints = tuple(monotone_constraints) # (0, 0, 0, -1, ...., 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cell_id": "f469f3b572be434191d2d5c3f11b20d2",
        "deepnote_cell_type": "code",
        "id": "B7tMnkiAI5v_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valor MAE (XGB) para conjunto Validaci칩n (wc: with constraints):  2931.6552734375\n"
          ]
        }
      ],
      "source": [
        "# Inserte su c칩digo ac치\n",
        "\n",
        "### XGBOOST \n",
        "\n",
        "pipeline_xgb_wc = Pipeline(\n",
        "    steps=[\n",
        "        (\"date_features\", date_transformer),\n",
        "        (\"col_transformer\", col_transformer),\n",
        "        (\"regresor_xgb\", XGBRegressor(random_state=42, \n",
        "        monotone_constraints = monotone_constraints))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ENTRENAMIENTO DEL MODELO XGBOOST REGRESSOR\n",
        "\n",
        "pipeline_xgb_wc.fit(X_train, y_train)\n",
        "\n",
        "# PREDICCIONES XGBOOST REGRESSOR\n",
        "\n",
        "y_pred_val_xgb_wc = pipeline_xgb_wc.predict(X_val)\n",
        "\n",
        "print(\"Valor MAE (XGB) para conjunto Validaci칩n (wc: with constraints): \",\n",
        "      MAE(y_val, y_pred_val_xgb_wc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Comentario de interpretaci칩n con parte anterior**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Guardado del modelo: _wc -> with constraints\n",
        "\n",
        "# Definir carpeta base para xgb\n",
        "base_path = os.path.join(os.getcwd(), \"Laboratorios\", \"Laboratorio_6\", \"data\")\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# Guardar predicciones\n",
        "pd.DataFrame({\"predicciones\": y_pred_val_xgb_wc}).to_csv(\n",
        "    os.path.join(base_path, \"predicciones_xgb_regressor_wc.csv\"), index=False\n",
        ")\n",
        "\n",
        "# Guardar modelo\n",
        "with open(os.path.join(base_path, \"xgb_regressor_model_wc.sav\"), \"wb\") as f:\n",
        "    pickle.dump(pipeline_xgb_wc, f)\n",
        "\n",
        "# Cargar modelo\n",
        "with open(os.path.join(base_path, \"xgb_regressor_model_wc.sav\"), \"rb\") as f:\n",
        "    modelo_loaded = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e59ef80ed20b4de8921f24da74e87374",
        "deepnote_cell_type": "markdown",
        "id": "5D5-tX4dI5v_"
      },
      "source": [
        "## 1.3 Optimizaci칩n de Hiperpar치metros con Optuna (20 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/fmNdyGN4z5kAAAAi/hacking-lucy.gif\">\n",
        "</p>\n",
        "\n",
        "Luego de presentarle sus resultados, Fiu le pregunta si es posible mejorar *aun m치s* su modelo. En particular, le comenta de la optimizaci칩n de hiperpar치metros con metodolog칤as bayesianas a trav칠s del paquete `optuna`. Como usted es un aficionado al entrenamiento de modelos de ML, se propone implementar la descabellada idea de su jefe.\n",
        "\n",
        "A partir de la mejor configuraci칩n obtenida en la secci칩n anterior, utilice `optuna` para optimizar sus hiperpar치metros. En particular, se pide que su optimizaci칩n considere lo siguiente:\n",
        "\n",
        "- Fijar una semilla en las instancias necesarias para garantizar la reproducibilidad de resultados\n",
        "- Utilice `TPESampler` como m칠todo de muestreo\n",
        "- De `XGBRegressor`, optimice los siguientes hiperpar치metros:\n",
        "    - `learning_rate` buscando valores flotantes en el rango (0.001, 0.1)\n",
        "    - `n_estimators` buscando valores enteros en el rango (50, 1000)\n",
        "    - `max_depth` buscando valores enteros en el rango (3, 10)\n",
        "    - `max_leaves` buscando valores enteros en el rango (0, 100)\n",
        "    - `min_child_weight` buscando valores enteros en el rango (1, 5)\n",
        "    - `reg_alpha` buscando valores flotantes en el rango (0, 1)\n",
        "    - `reg_lambda` buscando valores flotantes en el rango (0, 1)\n",
        "- De `OneHotEncoder`, optimice el hiperpar치metro `min_frequency` buscando el mejor valor flotante en el rango (0.0, 1.0)\n",
        "\n",
        "Para ello se pide los siguientes pasos:\n",
        "1. Implemente una funci칩n `objective()` que permita minimizar el `MAE` en el conjunto de validaci칩n. Use el m칠todo `.set_user_attr()` para almacenar el mejor pipeline entrenado. [10 puntos]\n",
        "2. Fije el tiempo de entrenamiento a 5 minutos. [1 punto]\n",
        "3. Optimizar el modelo y reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto? [3 puntos]\n",
        "4. Explique cada hiperpar치metro y su rol en el modelo. 쮿acen sentido los rangos de optimizaci칩n indicados? [5 puntos]\n",
        "5. Guardar su modelo en un archivo .pkl [1 punto]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W 2025-10-05 23:24:48,277] Trial 0 failed with parameters: {'learning_rate': 0.027762958434311664, 'n_estimators': 118, 'max_depth': 4, 'max_leaves': 83, 'min_child_weight': 5, 'reg_alpha': 0.7481463061880118, 'reg_lambda': 0.9192063554509772, 'min_frequency': 0.9174312930564078} because of the following error: ValueError('A given column is not a column of the dataframe').\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n",
            "    return self._engine.get_loc(casted_key)\n",
            "           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "KeyError: 'day'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 443, in _get_column_indices\n",
            "    col_idx = all_columns.get_loc(col)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3819, in get_loc\n",
            "    raise KeyError(key) from err\n",
            "KeyError: 'day'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\56966\\AppData\\Local\\Temp\\ipykernel_12152\\353535198.py\", line 67, in objective\n",
            "    col_transformer.fit(X_train)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 934, in fit\n",
            "    self.fit_transform(X, y=y, **params)\n",
            "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 988, in fit_transform\n",
            "    self._validate_column_callables(X)\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 541, in _validate_column_callables\n",
            "    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n",
            "                                         ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 451, in _get_column_indices\n",
            "    raise ValueError(\"A given column is not a column of the dataframe\") from e\n",
            "ValueError: A given column is not a column of the dataframe\n",
            "[W 2025-10-05 23:24:48,280] Trial 1 failed with parameters: {'learning_rate': 0.04952250605312755, 'n_estimators': 947, 'max_depth': 9, 'max_leaves': 53, 'min_child_weight': 1, 'reg_alpha': 0.2028608297257195, 'reg_lambda': 0.0522452455215735, 'min_frequency': 0.2722700310802427} because of the following error: ValueError('A given column is not a column of the dataframe').\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n",
            "    return self._engine.get_loc(casted_key)\n",
            "           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "KeyError: 'day'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 443, in _get_column_indices\n",
            "    col_idx = all_columns.get_loc(col)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3819, in get_loc\n",
            "    raise KeyError(key) from err\n",
            "KeyError: 'day'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\56966\\AppData\\Local\\Temp\\ipykernel_12152\\353535198.py\", line 67, in objective\n",
            "    col_transformer.fit(X_train)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 934, in fit\n",
            "    self.fit_transform(X, y=y, **params)\n",
            "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 988, in fit_transform\n",
            "    self._validate_column_callables(X)\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 541, in _validate_column_callables\n",
            "    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n",
            "                                         ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 451, in _get_column_indices\n",
            "    raise ValueError(\"A given column is not a column of the dataframe\") from e\n",
            "ValueError: A given column is not a column of the dataframe\n",
            "[W 2025-10-05 23:24:48,284] Trial 2 failed with parameters: {'learning_rate': 0.04426055404266729, 'n_estimators': 78, 'max_depth': 10, 'max_leaves': 13, 'min_child_weight': 2, 'reg_alpha': 0.5841148936295258, 'reg_lambda': 0.4571929049482808, 'min_frequency': 0.8923378984918766} because of the following error: ValueError('A given column is not a column of the dataframe').\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n",
            "    return self._engine.get_loc(casted_key)\n",
            "           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "KeyError: 'day'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 443, in _get_column_indices\n",
            "    col_idx = all_columns.get_loc(col)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3819, in get_loc\n",
            "    raise KeyError(key) from err\n",
            "KeyError: 'day'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\56966\\AppData\\Local\\Temp\\ipykernel_12152\\353535198.py\", line 67, in objective\n",
            "    col_transformer.fit(X_train)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 934, in fit\n",
            "    self.fit_transform(X, y=y, **params)\n",
            "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 988, in fit_transform\n",
            "    self._validate_column_callables(X)\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 541, in _validate_column_callables\n",
            "    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n",
            "                                         ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 451, in _get_column_indices\n",
            "    raise ValueError(\"A given column is not a column of the dataframe\") from e\n",
            "ValueError: A given column is not a column of the dataframe\n",
            "[W 2025-10-05 23:24:48,288] Trial 3 failed with parameters: {'learning_rate': 0.0873469625158825, 'n_estimators': 622, 'max_depth': 9, 'max_leaves': 12, 'min_child_weight': 3, 'reg_alpha': 0.8913549683604329, 'reg_lambda': 0.42032764063909966, 'min_frequency': 0.1903366761218731} because of the following error: ValueError('A given column is not a column of the dataframe').\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n",
            "    return self._engine.get_loc(casted_key)\n",
            "           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "KeyError: 'day'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 443, in _get_column_indices\n",
            "    col_idx = all_columns.get_loc(col)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3819, in get_loc\n",
            "    raise KeyError(key) from err\n",
            "KeyError: 'day'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\56966\\AppData\\Local\\Temp\\ipykernel_12152\\353535198.py\", line 67, in objective\n",
            "    col_transformer.fit(X_train)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 934, in fit\n",
            "    self.fit_transform(X, y=y, **params)\n",
            "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 988, in fit_transform\n",
            "    self._validate_column_callables(X)\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 541, in _validate_column_callables\n",
            "    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n",
            "                                         ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 451, in _get_column_indices\n",
            "    raise ValueError(\"A given column is not a column of the dataframe\") from e\n",
            "ValueError: A given column is not a column of the dataframe\n",
            "[W 2025-10-05 23:24:48,292] Trial 4 failed with parameters: {'learning_rate': 0.053433040087300744, 'n_estimators': 418, 'max_depth': 5, 'max_leaves': 62, 'min_child_weight': 4, 'reg_alpha': 0.3891691191815827, 'reg_lambda': 0.5583794144391638, 'min_frequency': 0.8784969855284978} because of the following error: ValueError('A given column is not a column of the dataframe').\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n",
            "    return self._engine.get_loc(casted_key)\n",
            "           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "KeyError: 'day'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 443, in _get_column_indices\n",
            "    col_idx = all_columns.get_loc(col)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3819, in get_loc\n",
            "    raise KeyError(key) from err\n",
            "KeyError: 'day'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\56966\\AppData\\Local\\Temp\\ipykernel_12152\\353535198.py\", line 67, in objective\n",
            "    col_transformer.fit(X_train)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 934, in fit\n",
            "    self.fit_transform(X, y=y, **params)\n",
            "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 988, in fit_transform\n",
            "    self._validate_column_callables(X)\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 541, in _validate_column_callables\n",
            "    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n",
            "                                         ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 451, in _get_column_indices\n",
            "    raise ValueError(\"A given column is not a column of the dataframe\") from e\n",
            "ValueError: A given column is not a column of the dataframe\n",
            "[W 2025-10-05 23:24:48,296] Trial 5 failed with parameters: {'learning_rate': 0.08807595478450767, 'n_estimators': 559, 'max_depth': 3, 'max_leaves': 63, 'min_child_weight': 5, 'reg_alpha': 0.7899490910736974, 'reg_lambda': 0.9746271830720158, 'min_frequency': 0.6205618434377141} because of the following error: ValueError('A given column is not a column of the dataframe').\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n",
            "    return self._engine.get_loc(casted_key)\n",
            "           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "KeyError: 'day'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 443, in _get_column_indices\n",
            "    col_idx = all_columns.get_loc(col)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3819, in get_loc\n",
            "    raise KeyError(key) from err\n",
            "KeyError: 'day'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\56966\\AppData\\Local\\Temp\\ipykernel_12152\\353535198.py\", line 67, in objective\n",
            "    col_transformer.fit(X_train)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 934, in fit\n",
            "    self.fit_transform(X, y=y, **params)\n",
            "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 988, in fit_transform\n",
            "    self._validate_column_callables(X)\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 541, in _validate_column_callables\n",
            "    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n",
            "                                         ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 451, in _get_column_indices\n",
            "    raise ValueError(\"A given column is not a column of the dataframe\") from e\n",
            "ValueError: A given column is not a column of the dataframe\n",
            "[W 2025-10-05 23:24:48,299] Trial 6 failed with parameters: {'learning_rate': 0.05109285057053825, 'n_estimators': 157, 'max_depth': 10, 'max_leaves': 58, 'min_child_weight': 5, 'reg_alpha': 0.40525822222416763, 'reg_lambda': 0.06935725674450899, 'min_frequency': 0.9149259653486456} because of the following error: ValueError('A given column is not a column of the dataframe').\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n",
            "    return self._engine.get_loc(casted_key)\n",
            "           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "KeyError: 'day'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 443, in _get_column_indices\n",
            "    col_idx = all_columns.get_loc(col)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3819, in get_loc\n",
            "    raise KeyError(key) from err\n",
            "KeyError: 'day'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\56966\\AppData\\Local\\Temp\\ipykernel_12152\\353535198.py\", line 67, in objective\n",
            "    col_transformer.fit(X_train)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 934, in fit\n",
            "    self.fit_transform(X, y=y, **params)\n",
            "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 988, in fit_transform\n",
            "    self._validate_column_callables(X)\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 541, in _validate_column_callables\n",
            "    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n",
            "                                         ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 451, in _get_column_indices\n",
            "    raise ValueError(\"A given column is not a column of the dataframe\") from e\n",
            "ValueError: A given column is not a column of the dataframe\n",
            "[W 2025-10-05 23:24:48,303] Trial 7 failed with parameters: {'learning_rate': 0.038216248245151845, 'n_estimators': 506, 'max_depth': 8, 'max_leaves': 37, 'min_child_weight': 4, 'reg_alpha': 0.20338023587966936, 'reg_lambda': 0.2070819097582529, 'min_frequency': 0.040313732853224926} because of the following error: ValueError('A given column is not a column of the dataframe').\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n",
            "    return self._engine.get_loc(casted_key)\n",
            "           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "KeyError: 'day'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 443, in _get_column_indices\n",
            "    col_idx = all_columns.get_loc(col)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3819, in get_loc\n",
            "    raise KeyError(key) from err\n",
            "KeyError: 'day'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\56966\\AppData\\Local\\Temp\\ipykernel_12152\\353535198.py\", line 67, in objective\n",
            "    col_transformer.fit(X_train)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 934, in fit\n",
            "    self.fit_transform(X, y=y, **params)\n",
            "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 988, in fit_transform\n",
            "    self._validate_column_callables(X)\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 541, in _validate_column_callables\n",
            "    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n",
            "                                         ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 451, in _get_column_indices\n",
            "    raise ValueError(\"A given column is not a column of the dataframe\") from e\n",
            "ValueError: A given column is not a column of the dataframe\n",
            "[W 2025-10-05 23:24:48,312] Trial 0 failed with value None.\n",
            "[W 2025-10-05 23:24:48,321] Trial 1 failed with value None.\n",
            "[W 2025-10-05 23:24:48,332] Trial 2 failed with value None.\n",
            "[W 2025-10-05 23:24:48,342] Trial 3 failed with value None.\n",
            "[W 2025-10-05 23:24:48,350] Trial 4 failed with value None.\n",
            "[W 2025-10-05 23:24:48,357] Trial 5 failed with value None.\n",
            "[W 2025-10-05 23:24:48,366] Trial 6 failed with value None.\n",
            "[W 2025-10-05 23:24:48,373] Trial 7 failed with value None.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "A given column is not a column of the dataframe",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._engine.get_loc(casted_key)\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyError\u001b[39m: 'day'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:443\u001b[39m, in \u001b[36m_get_column_indices\u001b[39m\u001b[34m(X, key)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     col_idx = all_columns.get_loc(col)\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col_idx, numbers.Integral):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
            "\u001b[31mKeyError\u001b[39m: 'day'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 113\u001b[39m\n\u001b[32m    105\u001b[39m study = optuna.create_study(\n\u001b[32m    106\u001b[39m     direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# para minimizar mae\u001b[39;00m\n\u001b[32m    107\u001b[39m     sampler=sampler,\n\u001b[32m    108\u001b[39m     study_name=\u001b[33m\"\u001b[39m\u001b[33moptimizacion xgb con optuna\u001b[39m\u001b[33m\"\u001b[39m                  \n\u001b[32m    109\u001b[39m )\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m## limite de tiempo 5 minutos\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m study.optimize(objective, timeout=\u001b[32m5\u001b[39m*\u001b[32m60\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m## printeos: n칰mero de trials, mae y mejores hiperpar치metros\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m N칰mero de trials: \u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(study.trials))\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     _optimize(\n\u001b[32m    491\u001b[39m         study=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    492\u001b[39m         func=func,\n\u001b[32m    493\u001b[39m         n_trials=n_trials,\n\u001b[32m    494\u001b[39m         timeout=timeout,\n\u001b[32m    495\u001b[39m         n_jobs=n_jobs,\n\u001b[32m    496\u001b[39m         catch=\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[32m    497\u001b[39m         callbacks=callbacks,\n\u001b[32m    498\u001b[39m         gc_after_trial=gc_after_trial,\n\u001b[32m    499\u001b[39m         show_progress_bar=show_progress_bar,\n\u001b[32m    500\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py:100\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     98\u001b[39m                     \u001b[38;5;66;03m# Raise if exception occurred in executing the completed futures.\u001b[39;00m\n\u001b[32m     99\u001b[39m                     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m completed:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m                         f.result()\n\u001b[32m    102\u001b[39m                 futures.add(\n\u001b[32m    103\u001b[39m                     executor.submit(\n\u001b[32m    104\u001b[39m                         _optimize_sequential,\n\u001b[32m   (...)\u001b[39m\u001b[32m    115\u001b[39m                     )\n\u001b[32m    116\u001b[39m                 )\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\concurrent\\futures\\thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.fn(*\u001b[38;5;28mself\u001b[39m.args, **\u001b[38;5;28mself\u001b[39m.kwargs)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = _run_trial(study, func, catch)\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = func(trial)\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     59\u001b[39m col_transformer = ColumnTransformer(\n\u001b[32m     60\u001b[39m [\n\u001b[32m     61\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mdrop_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdrop\u001b[39m\u001b[33m\"\u001b[39m, drop_cols),\n\u001b[32m     62\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mnumerical\u001b[39m\u001b[33m\"\u001b[39m, num_std_pipeline, num_cols),\n\u001b[32m     63\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mcategorical\u001b[39m\u001b[33m\"\u001b[39m, cat_pipeline, cat_cols)\n\u001b[32m     64\u001b[39m ], verbose_feature_names_out=\u001b[38;5;28;01mFalse\u001b[39;00m, remainder=\u001b[33m\"\u001b[39m\u001b[33mdrop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# se obtiene nombres de las cols\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m col_transformer.fit(X_train)\n\u001b[32m     68\u001b[39m feature_names = col_transformer.get_feature_names_out()\n\u001b[32m     70\u001b[39m monotone_constraints_list = []\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:934\u001b[39m, in \u001b[36mColumnTransformer.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    931\u001b[39m _raise_for_params(params, \u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    932\u001b[39m \u001b[38;5;66;03m# we use fit_transform to make sure to set sparse_output_ (for which we\u001b[39;00m\n\u001b[32m    933\u001b[39m \u001b[38;5;66;03m# need the transformed data) to have consistent output type in predict\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m934\u001b[39m \u001b[38;5;28mself\u001b[39m.fit_transform(X, y=y, **params)\n\u001b[32m    935\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = f(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs)\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:988\u001b[39m, in \u001b[36mColumnTransformer.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    985\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_transformers()\n\u001b[32m    986\u001b[39m n_samples = _num_samples(X)\n\u001b[32m--> \u001b[39m\u001b[32m988\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_column_callables(X)\n\u001b[32m    989\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_remainder(X)\n\u001b[32m    991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:541\u001b[39m, in \u001b[36mColumnTransformer._validate_column_callables\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    539\u001b[39m         columns = columns(X)\n\u001b[32m    540\u001b[39m     all_columns.append(columns)\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m     transformer_to_input_indices[name] = _get_column_indices(X, columns)\n\u001b[32m    543\u001b[39m \u001b[38;5;28mself\u001b[39m._columns = all_columns\n\u001b[32m    544\u001b[39m \u001b[38;5;28mself\u001b[39m._transformer_to_input_indices = transformer_to_input_indices\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:451\u001b[39m, in \u001b[36m_get_column_indices\u001b[39m\u001b[34m(X, key)\u001b[39m\n\u001b[32m    448\u001b[39m         column_indices.append(col_idx)\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mA given column is not a column of the dataframe\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m column_indices\n",
            "\u001b[31mValueError\u001b[39m: A given column is not a column of the dataframe"
          ]
        }
      ],
      "source": [
        "## SPOILER: Ac치 intent칠 optimizar con la restricci칩n pero me tir칩 error\n",
        "\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "# Inserte su c칩digo ac치\n",
        "\n",
        "import time\n",
        "\n",
        "seed = 42\n",
        "\n",
        "def objective(trial):\n",
        "    # Inserte su c칩digo ac치\n",
        "\n",
        "    #1: de lo que entiendo -> codificacion y escalamiento\n",
        "    #2: separaci칩n en conjuntos de train, val y test\n",
        "\n",
        "    params_xgb ={\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1),\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 1000),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "        \"max_leaves\": trial.suggest_int(\"max_leaves\", 0, 100),\n",
        "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1,5),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 1),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 1) \n",
        "    }\n",
        "\n",
        "    params_ohe = {\n",
        "        \"min_frequency\": trial.suggest_float(\"min_frequency\", 0, 1)\n",
        "    }\n",
        "\n",
        "    ### debido a que hay que optimizar ese par치metro de one hot enc\n",
        "    ### hay definir de nuevo los pipelines\n",
        "\n",
        "\n",
        "    drop_cols = [\"id\"]\n",
        "\n",
        "    num_cols = [\"lat\", \"long\", \"pop\", \"price\"]\n",
        "    cat_cols = [\"city\", \"shop\", \"brand\", \"container\",\n",
        "                \"capacity\", \"day\", \"month\", \"year\"]\n",
        "\n",
        "    # PIPELINES POR GRUPO (punto 3)\n",
        "\n",
        "    num_std_pipeline = Pipeline(\n",
        "        [\n",
        "            # aunque no hayan nulos, coloco esto por completitud\n",
        "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "            (\"sc\", StandardScaler())\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    cat_pipeline = Pipeline(\n",
        "        [\n",
        "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "            (\"onehot\", OneHotEncoder(\n",
        "                handle_unknown=\"ignore\", sparse_output=False, **params_ohe\n",
        "            ))\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    col_transformer = ColumnTransformer(\n",
        "    [\n",
        "        (\"drop_ids\", \"drop\", drop_cols),\n",
        "        (\"numerical\", num_std_pipeline, num_cols),\n",
        "        (\"categorical\", cat_pipeline, cat_cols)\n",
        "    ], verbose_feature_names_out=False, remainder=\"drop\")\n",
        "\n",
        "    # se obtiene nombres de las cols\n",
        "    col_transformer.fit(X_train)\n",
        "    feature_names = col_transformer.get_feature_names_out()\n",
        "\n",
        "    monotone_constraints_list = []\n",
        "\n",
        "    for name in feature_names:\n",
        "        clean_name = name.split(\"__\")[-1]\n",
        "        constraint = monotone_constraints_mapeo.get(clean_name, 0)  # por defecto 0\n",
        "        monotone_constraints_list.append(constraint)    \n",
        "\n",
        "\n",
        "    # pipeline xgb \n",
        "\n",
        "    pipeline_xgb_op = Pipeline(\n",
        "        steps=[\n",
        "        (\"date_features\", date_transformer),\n",
        "        (\"col_transformer\", col_transformer),\n",
        "        (\"regresor_xgb\", XGBRegressor(random_state=42, \n",
        "        monotone_constraints = monotone_constraints_list, \n",
        "        **params_xgb))\n",
        "        ]\n",
        "        )\n",
        "    \n",
        "    # entrenamiento  y evaluacion\n",
        "    pipeline_xgb_op.fit(X_train, y_train)\n",
        "    y_pred_val_xgb_op = pipeline_xgb_op.predict(X_val)\n",
        "\n",
        "    # m칠trica MAE para xgb_op\n",
        "\n",
        "    MAE_op = MAE(y_val, y_pred_val_xgb_op)\n",
        "\n",
        "    trial.set_user_attr(\"best_pipeline\", pipeline_xgb_op) # se guarda el mejor piple entrenado\n",
        "\n",
        "    return MAE_op\n",
        "\n",
        "## parte 2\n",
        "sampler = TPESampler(seed=seed)\n",
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",  # para minimizar mae\n",
        "    sampler=sampler,\n",
        "    study_name=\"optimizacion xgb con optuna\"                  \n",
        ")\n",
        "\n",
        "## limite de tiempo 5 minutos\n",
        "\n",
        "study.optimize(objective, timeout=5*60, n_jobs=-1)\n",
        "\n",
        "\n",
        "## printeos: n칰mero de trials, mae y mejores hiperpar치metros\n",
        "\n",
        "print(\"\\n N칰mero de trials: \", len(study.trials))\n",
        "print(\"\\n Mejor MAE: \", study.best_value)\n",
        "print(\"\\n Mejores hiperpar치metros: \\n\", study.best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "cell_id": "de5914621cc64cb0b1bacb9ff565a97e",
        "deepnote_cell_type": "code",
        "id": "kMXXi1ckI5v_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " N칰mero de trials:  268\n",
            "\n",
            " Mejor MAE:  2480.952392578125\n",
            "\n",
            " Mejores hiperpar치metros: \n",
            " {'learning_rate': 0.09961157740995351, 'n_estimators': 891, 'max_depth': 7, 'max_leaves': 100, 'min_child_weight': 1, 'reg_alpha': 0.17227373518474084, 'reg_lambda': 0.722944995569306, 'min_frequency': 0.07790604367998297}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "# Inserte su c칩digo ac치\n",
        "\n",
        "import time\n",
        "\n",
        "seed = 42\n",
        "\n",
        "def objective(trial):\n",
        "    # Inserte su c칩digo ac치\n",
        "\n",
        "    #1: de lo que entiendo -> codificacion y escalamiento\n",
        "    #2: separaci칩n en conjuntos de train, val y test\n",
        "\n",
        "    params_xgb ={\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1),\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 1000),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "        \"max_leaves\": trial.suggest_int(\"max_leaves\", 0, 100),\n",
        "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1,5),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 1),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 1) \n",
        "    }\n",
        "\n",
        "    params_ohe = {\n",
        "        \"min_frequency\": trial.suggest_float(\"min_frequency\", 0, 1)\n",
        "    }\n",
        "\n",
        "    ### debido a que hay que optimizar ese par치metro de one hot enc\n",
        "    ### hay definir de nuevo los pipelines\n",
        "\n",
        "\n",
        "    drop_cols = [\"id\"]\n",
        "\n",
        "    num_cols = [\"lat\", \"long\", \"pop\", \"price\"]\n",
        "    cat_cols = [\"city\", \"shop\", \"brand\", \"container\",\n",
        "                \"capacity\", \"day\", \"month\", \"year\"]\n",
        "\n",
        "    # PIPELINES POR GRUPO (punto 3)\n",
        "\n",
        "    num_std_pipeline = Pipeline(\n",
        "        [\n",
        "            # aunque no hayan nulos, coloco esto por completitud\n",
        "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "            (\"sc\", StandardScaler())\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    cat_pipeline = Pipeline(\n",
        "        [\n",
        "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "            (\"onehot\", OneHotEncoder(\n",
        "                handle_unknown=\"ignore\", sparse_output=False, **params_ohe\n",
        "            ))\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    col_transformer = ColumnTransformer(\n",
        "    [\n",
        "        (\"drop_ids\", \"drop\", drop_cols),\n",
        "        (\"numerical\", num_std_pipeline, num_cols),\n",
        "        (\"categorical\", cat_pipeline, cat_cols)\n",
        "    ], verbose_feature_names_out=False, remainder=\"drop\")\n",
        "\n",
        "\n",
        "    # pipeline xgb \n",
        "\n",
        "    pipeline_xgb_op = Pipeline(\n",
        "        steps=[\n",
        "        (\"date_features\", date_transformer),\n",
        "        (\"col_transformer\", col_transformer),\n",
        "        (\"regresor_xgb\", XGBRegressor(random_state=42, \n",
        "        #monotone_constraints = monotone_constraints, \n",
        "        **params_xgb))\n",
        "        ]\n",
        "        )\n",
        "    \n",
        "    # entrenamiento  y evaluacion\n",
        "    pipeline_xgb_op.fit(X_train, y_train)\n",
        "    y_pred_val_xgb_op = pipeline_xgb_op.predict(X_val)\n",
        "\n",
        "    # m칠trica MAE para xgb_op\n",
        "\n",
        "    MAE_op = MAE(y_val, y_pred_val_xgb_op)\n",
        "\n",
        "    trial.set_user_attr(\"best_pipeline\", pipeline_xgb_op) # se guarda el mejor piple entrenado\n",
        "\n",
        "    return MAE_op\n",
        "\n",
        "## parte 2\n",
        "sampler = TPESampler(seed=seed)\n",
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",  # para minimizar mae\n",
        "    sampler=sampler,\n",
        "    study_name=\"optimizacion xgb con optuna\"                  \n",
        ")\n",
        "\n",
        "## limite de tiempo 5 minutos\n",
        "\n",
        "study.optimize(objective, timeout=5*60, n_jobs=-1)\n",
        "\n",
        "\n",
        "## printeos: n칰mero de trials, mae y mejores hiperpar치metros\n",
        "\n",
        "print(\"\\n N칰mero de trials: \", len(study.trials))\n",
        "print(\"\\n Mejor MAE: \", study.best_value)\n",
        "print(\"\\n Mejores hiperpar치metros: \\n\", study.best_params)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valor MAE (XGB) para conjunto Validaci칩n (con mejores hiperpar치metros):  2480.952392578125\n"
          ]
        }
      ],
      "source": [
        "# HAGO ESTO PARA GUARDAR EL MODELO\n",
        "# QUIZAS HAYA UNA MANERA MAS EFICIENTE\n",
        "\n",
        "drop_cols = [\"id\"]\n",
        "\n",
        "num_cols = [\"lat\", \"long\", \"pop\", \"price\"]\n",
        "cat_cols = [\"city\", \"shop\", \"brand\", \"container\",\n",
        "            \"capacity\", \"day\", \"month\", \"year\"]\n",
        "\n",
        "# PIPELINES POR GRUPO (punto 3)\n",
        "\n",
        "num_std_pipeline = Pipeline(\n",
        "    [\n",
        "        # aunque no hayan nulos, coloco esto por completitud\n",
        "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"sc\", StandardScaler())\n",
        "    ]\n",
        ")\n",
        "\n",
        "params_ohe = {}\n",
        "\n",
        "for k, value in study.best_params.items():\n",
        "    if k == \"min_frequency\":\n",
        "        params_ohe[k] = value\n",
        "\n",
        "cat_pipeline = Pipeline(\n",
        "    [\n",
        "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(\n",
        "            handle_unknown=\"ignore\", sparse_output=False, **params_ohe\n",
        "        ))\n",
        "    ]\n",
        ")\n",
        "\n",
        "col_transformer = ColumnTransformer(\n",
        "[\n",
        "    (\"drop_ids\", \"drop\", drop_cols),\n",
        "    (\"numerical\", num_std_pipeline, num_cols),\n",
        "    (\"categorical\", cat_pipeline, cat_cols)\n",
        "], verbose_feature_names_out=False, remainder=\"drop\")\n",
        "\n",
        "\n",
        "\n",
        "params_xgb = {}\n",
        "\n",
        "for k, value in study.best_params.items():\n",
        "    if k != \"min_frequency\":\n",
        "        params_xgb[k] = value\n",
        "# XGBOOST\n",
        "\n",
        "pipeline_xgb_op = Pipeline(\n",
        "    steps=[\n",
        "        (\"date_features\", date_transformer),\n",
        "        (\"col_transformer\", col_transformer),\n",
        "        (\"regresor_xgb\", XGBRegressor(random_state=42,\n",
        "                                      #monotone_constraints=monotone_constraints, # por ahora agrego la restricci칩n\n",
        "                                      **params_xgb))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ENTRENAMIENTO DEL MODELO XGBOOST REGRESSOR\n",
        "\n",
        "pipeline_xgb_op.fit(X_train, y_train)\n",
        "\n",
        "# PREDICCIONES XGBOOST REGRESSOR\n",
        "\n",
        "y_pred_val_xgb_op = pipeline_xgb_op.predict(X_val)\n",
        "\n",
        "print(\"Valor MAE (XGB) para conjunto Validaci칩n (con mejores hiperpar치metros): \",\n",
        "      MAE(y_val, y_pred_val_xgb_op))\n",
        "\n",
        "###################################################\n",
        "# Guardado del modelo con mejores hiperpar치metros\n",
        "\n",
        "# Definir carpeta base para xgb\n",
        "base_path = os.path.join(os.getcwd(), \"Laboratorios\", \"Laboratorio_6\", \"data\")\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# Guardar predicciones\n",
        "pd.DataFrame({\"predicciones\": y_pred_val_xgb_op}).to_csv(\n",
        "    os.path.join(base_path, \"predicciones_xgb_regressor_op.csv\"), index=False\n",
        ")\n",
        "\n",
        "# Guardar modelo\n",
        "with open(os.path.join(base_path, \"xgb_regressor_model_op.sav\"), \"wb\") as f:\n",
        "    pickle.dump(pipeline_xgb_op, f)\n",
        "\n",
        "# Cargar modelo\n",
        "with open(os.path.join(base_path, \"xgb_regressor_model_op.sav\"), \"rb\") as f:\n",
        "    modelo_loaded = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5195ccfc37e044ad9453f6eb2754f631",
        "deepnote_cell_type": "markdown",
        "id": "ZglyD_QWI5wA"
      },
      "source": [
        "## 4. Optimizaci칩n de Hiperpar치metros con Optuna y Prunners (17 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.pinimg.com/originals/90/16/f9/9016f919c2259f3d0e8fe465049638a7.gif\">\n",
        "</p>\n",
        "\n",
        "Despu칠s de optimizar el rendimiento de su modelo varias veces, Fiu le pregunta si no es posible optimizar el entrenamiento del modelo en s칤 mismo. Despu칠s de leer un par de post de personas de dudosa reputaci칩n en la *deepweb*, usted llega a la conclusi칩n que puede cumplir este objetivo mediante la implementaci칩n de **Prunning**.\n",
        "\n",
        "Vuelva a optimizar los mismos hiperpar치metros que la secci칩n pasada, pero esta vez utilizando **Prunning** en la optimizaci칩n. En particular, usted debe:\n",
        "\n",
        "- Responder: 쯈u칠 es prunning? 쮻e qu칠 forma deber칤a impactar en el entrenamiento? [2 puntos]\n",
        "- Redefinir la funci칩n `objective()` utilizando `optuna.integration.XGBoostPruningCallback` como m칠todo de **Prunning** [10 puntos]\n",
        "- Fijar nuevamente el tiempo de entrenamiento a 5 minutos [1 punto]\n",
        "- Reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto? [3 puntos]\n",
        "- Guardar su modelo en un archivo .pkl [1 punto]\n",
        "\n",
        "Nota: Si quieren silenciar los prints obtenidos en el prunning, pueden hacerlo mediante el siguiente comando:\n",
        "\n",
        "```\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "```\n",
        "\n",
        "De implementar la opci칩n anterior, pueden especificar `show_progress_bar = True` en el m칠todo `optimize` para *m치s sabor*.\n",
        "\n",
        "Hint: Si quieren especificar par치metros del m칠todo .fit() del modelo a trav칠s del pipeline, pueden hacerlo por medio de la siguiente sintaxis: `pipeline.fit(stepmodelo__parametro = valor)`\n",
        "\n",
        "Hint2: Este <a href = https://stackoverflow.com/questions/40329576/sklearn-pass-fit-parameters-to-xgboost-in-pipeline>enlace</a> les puede ser de ayuda en su implementaci칩n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5IEEZnb-cwP_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna-integration[xgboost]\n",
            "  Downloading optuna_integration-4.5.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: optuna in c:\\programdata\\anaconda3\\envs\\vis_info\\lib\\site-packages (from optuna-integration[xgboost]) (4.5.0)\n",
            "Requirement already satisfied: xgboost in c:\\programdata\\anaconda3\\envs\\vis_info\\lib\\site-packages (from optuna-integration[xgboost]) (3.0.5)\n",
            "Requirement already satisfied: alembic>=1.5.0 in c:\\programdata\\anaconda3\\envs\\vis_info\\lib\\site-packages (from optuna->optuna-integration[xgboost]) (1.16.5)\n",
            "Requirement already satisfied: colorlog in c:\\programdata\\anaconda3\\envs\\vis_info\\lib\\site-packages (from optuna->optuna-integration[xgboost]) (6.9.0)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\vis_info\\lib\\site-packages (from optuna->optuna-integration[xgboost]) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\vis_info\\lib\\site-packages (from optuna->optuna-integration[xgboost]) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\programdata\\anaconda3\\envs\\vis_info\\lib\\site-packages (from optuna->optuna-integration[xgboost]) (2.0.43)\n",
            "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\envs\\vis_info\\lib\\site-packages (from optuna->optuna-integration[xgboost]) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in c:\\programdata\\anaconda3\\envs\\vis_info\\lib\\site-packages (from optuna->optuna-integration[xgboost]) (6.0.2)\n",
            "Requirement already satisfied: Mako in c:\\programdata\\anaconda3\\envs\\vis_info\\lib\\site-packages (from alembic>=1.5.0->optuna->optuna-integration[xgboost]) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in c:\\programdata\\anaconda3\\envs\\vis_info\\lib\\site-packages (from alembic>=1.5.0->optuna->optuna-integration[xgboost]) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\programdata\\anaconda3\\envs\\vis_info\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration[xgboost]) (3.2.4)\n",
            "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\vis_info\\lib\\site-packages (from colorlog->optuna->optuna-integration[xgboost]) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\programdata\\anaconda3\\envs\\vis_info\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration[xgboost]) (3.0.2)\n",
            "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\envs\\vis_info\\lib\\site-packages (from xgboost->optuna-integration[xgboost]) (1.16.0)\n",
            "Downloading optuna_integration-4.5.0-py3-none-any.whl (99 kB)\n",
            "Installing collected packages: optuna-integration\n",
            "Successfully installed optuna-integration-4.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna-integration[xgboost]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "cell_id": "eeaa967cd8f6426d8c54f276c17dce79",
        "deepnote_cell_type": "code",
        "id": "sST6Wtj5I5wA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W 2025-10-05 23:59:52,722] Trial 7 failed with parameters: {'learning_rate': 0.0763821837786234, 'n_estimators': 113, 'max_depth': 7, 'max_leaves': 80, 'min_child_weight': 3, 'reg_alpha': 0.7487616267870264, 'reg_lambda': 0.4430966953604092, 'min_frequency': 0.1300965017273984} because of the following error: TypeError(\"XGBModel.fit() got an unexpected keyword argument 'eval_metric'\").\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\56966\\AppData\\Local\\Temp\\ipykernel_12152\\3539857404.py\", line 83, in objective\n",
            "    pipeline_xgb_op.fit(X_train, y_train, **fit_params)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
            "    return func(**kwargs)\n",
            "TypeError: XGBModel.fit() got an unexpected keyword argument 'eval_metric'\n",
            "[W 2025-10-05 23:59:52,741] Trial 7 failed with value None.\n",
            "[W 2025-10-05 23:59:52,743] Trial 5 failed with parameters: {'learning_rate': 0.016964295614058957, 'n_estimators': 415, 'max_depth': 3, 'max_leaves': 16, 'min_child_weight': 2, 'reg_alpha': 0.3807098247255102, 'reg_lambda': 0.6608494449198926, 'min_frequency': 0.36495854605415545} because of the following error: TypeError(\"XGBModel.fit() got an unexpected keyword argument 'eval_metric'\").\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\56966\\AppData\\Local\\Temp\\ipykernel_12152\\3539857404.py\", line 83, in objective\n",
            "    pipeline_xgb_op.fit(X_train, y_train, **fit_params)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
            "    return func(**kwargs)\n",
            "TypeError: XGBModel.fit() got an unexpected keyword argument 'eval_metric'\n",
            "[W 2025-10-05 23:59:52,757] Trial 6 failed with parameters: {'learning_rate': 0.08856056477754085, 'n_estimators': 686, 'max_depth': 3, 'max_leaves': 19, 'min_child_weight': 4, 'reg_alpha': 0.26883523379286667, 'reg_lambda': 0.6162389383418377, 'min_frequency': 0.7442787555695224} because of the following error: TypeError(\"XGBModel.fit() got an unexpected keyword argument 'eval_metric'\").\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\56966\\AppData\\Local\\Temp\\ipykernel_12152\\3539857404.py\", line 83, in objective\n",
            "    pipeline_xgb_op.fit(X_train, y_train, **fit_params)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
            "    return func(**kwargs)\n",
            "TypeError: XGBModel.fit() got an unexpected keyword argument 'eval_metric'\n",
            "[W 2025-10-05 23:59:52,767] Trial 3 failed with parameters: {'learning_rate': 0.004895433441098991, 'n_estimators': 276, 'max_depth': 9, 'max_leaves': 1, 'min_child_weight': 2, 'reg_alpha': 0.8802306164398217, 'reg_lambda': 0.04883060311235721, 'min_frequency': 0.9586961696610629} because of the following error: TypeError(\"XGBModel.fit() got an unexpected keyword argument 'eval_metric'\").\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\56966\\AppData\\Local\\Temp\\ipykernel_12152\\3539857404.py\", line 83, in objective\n",
            "    pipeline_xgb_op.fit(X_train, y_train, **fit_params)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
            "    return func(**kwargs)\n",
            "TypeError: XGBModel.fit() got an unexpected keyword argument 'eval_metric'\n",
            "[W 2025-10-05 23:59:52,771] Trial 1 failed with parameters: {'learning_rate': 0.024429706016434006, 'n_estimators': 545, 'max_depth': 8, 'max_leaves': 35, 'min_child_weight': 3, 'reg_alpha': 0.4845558413146911, 'reg_lambda': 0.2974587360302049, 'min_frequency': 0.4099738135873867} because of the following error: TypeError(\"XGBModel.fit() got an unexpected keyword argument 'eval_metric'\").\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\56966\\AppData\\Local\\Temp\\ipykernel_12152\\3539857404.py\", line 83, in objective\n",
            "    pipeline_xgb_op.fit(X_train, y_train, **fit_params)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
            "    return func(**kwargs)\n",
            "TypeError: XGBModel.fit() got an unexpected keyword argument 'eval_metric'\n",
            "[W 2025-10-05 23:59:52,782] Trial 2 failed with parameters: {'learning_rate': 0.042819663742122836, 'n_estimators': 596, 'max_depth': 7, 'max_leaves': 17, 'min_child_weight': 3, 'reg_alpha': 0.11126247332788552, 'reg_lambda': 0.22127479715395837, 'min_frequency': 0.46308473403455963} because of the following error: TypeError(\"XGBModel.fit() got an unexpected keyword argument 'eval_metric'\").\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\56966\\AppData\\Local\\Temp\\ipykernel_12152\\3539857404.py\", line 83, in objective\n",
            "    pipeline_xgb_op.fit(X_train, y_train, **fit_params)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
            "    return func(**kwargs)\n",
            "TypeError: XGBModel.fit() got an unexpected keyword argument 'eval_metric'\n",
            "[W 2025-10-05 23:59:52,783] Trial 0 failed with parameters: {'learning_rate': 0.06799761909200686, 'n_estimators': 216, 'max_depth': 5, 'max_leaves': 54, 'min_child_weight': 2, 'reg_alpha': 0.3717041505006321, 'reg_lambda': 0.23224938727131117, 'min_frequency': 0.7834203263729504} because of the following error: TypeError(\"XGBModel.fit() got an unexpected keyword argument 'eval_metric'\").\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\56966\\AppData\\Local\\Temp\\ipykernel_12152\\3539857404.py\", line 83, in objective\n",
            "    pipeline_xgb_op.fit(X_train, y_train, **fit_params)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
            "    return func(**kwargs)\n",
            "TypeError: XGBModel.fit() got an unexpected keyword argument 'eval_metric'\n",
            "[W 2025-10-05 23:59:52,787] Trial 4 failed with parameters: {'learning_rate': 0.013585623139498789, 'n_estimators': 126, 'max_depth': 4, 'max_leaves': 74, 'min_child_weight': 5, 'reg_alpha': 0.7331544619064438, 'reg_lambda': 0.9345364793768837, 'min_frequency': 0.7020078822276432} because of the following error: TypeError(\"XGBModel.fit() got an unexpected keyword argument 'eval_metric'\").\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\56966\\AppData\\Local\\Temp\\ipykernel_12152\\3539857404.py\", line 83, in objective\n",
            "    pipeline_xgb_op.fit(X_train, y_train, **fit_params)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
            "    return func(**kwargs)\n",
            "TypeError: XGBModel.fit() got an unexpected keyword argument 'eval_metric'\n",
            "[W 2025-10-05 23:59:52,787] Trial 5 failed with value None.\n",
            "[W 2025-10-05 23:59:52,791] Trial 6 failed with value None.\n",
            "[W 2025-10-05 23:59:52,798] Trial 3 failed with value None.\n",
            "[W 2025-10-05 23:59:52,804] Trial 1 failed with value None.\n",
            "[W 2025-10-05 23:59:52,808] Trial 2 failed with value None.\n",
            "[W 2025-10-05 23:59:52,816] Trial 0 failed with value None.\n",
            "[W 2025-10-05 23:59:52,821] Trial 4 failed with value None.\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "XGBModel.fit() got an unexpected keyword argument 'eval_metric'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 108\u001b[39m\n\u001b[32m    100\u001b[39m study = optuna.create_study(\n\u001b[32m    101\u001b[39m     direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# para minimizar mae\u001b[39;00m\n\u001b[32m    102\u001b[39m     sampler=sampler,\n\u001b[32m    103\u001b[39m     study_name=\u001b[33m\"\u001b[39m\u001b[33moptimizacion xgb con optuna\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    104\u001b[39m )\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# limite de tiempo 5 minutos\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m study.optimize(objective, timeout=\u001b[32m5\u001b[39m*\u001b[32m60\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# printeos: n칰mero de trials, mae y mejores hiperpar치metros\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m N칰mero de trials: \u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(study.trials))\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     _optimize(\n\u001b[32m    491\u001b[39m         study=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    492\u001b[39m         func=func,\n\u001b[32m    493\u001b[39m         n_trials=n_trials,\n\u001b[32m    494\u001b[39m         timeout=timeout,\n\u001b[32m    495\u001b[39m         n_jobs=n_jobs,\n\u001b[32m    496\u001b[39m         catch=\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[32m    497\u001b[39m         callbacks=callbacks,\n\u001b[32m    498\u001b[39m         gc_after_trial=gc_after_trial,\n\u001b[32m    499\u001b[39m         show_progress_bar=show_progress_bar,\n\u001b[32m    500\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py:100\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     98\u001b[39m                     \u001b[38;5;66;03m# Raise if exception occurred in executing the completed futures.\u001b[39;00m\n\u001b[32m     99\u001b[39m                     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m completed:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m                         f.result()\n\u001b[32m    102\u001b[39m                 futures.add(\n\u001b[32m    103\u001b[39m                     executor.submit(\n\u001b[32m    104\u001b[39m                         _optimize_sequential,\n\u001b[32m   (...)\u001b[39m\u001b[32m    115\u001b[39m                     )\n\u001b[32m    116\u001b[39m                 )\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\concurrent\\futures\\thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.fn(*\u001b[38;5;28mself\u001b[39m.args, **\u001b[38;5;28mself\u001b[39m.kwargs)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = _run_trial(study, func, catch)\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = func(trial)\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# entrenamiento  y evaluacion\u001b[39;00m\n\u001b[32m     77\u001b[39m fit_params = {\n\u001b[32m     78\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mregresor_xgb__eval_set\u001b[39m\u001b[33m\"\u001b[39m: [(X_train, y_train), (X_val, y_val)],\n\u001b[32m     79\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mregresor_xgb__eval_metric\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmae\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     80\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mregresor_xgb__callbacks\u001b[39m\u001b[33m\"\u001b[39m: [pruning_callback]\n\u001b[32m     81\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m pipeline_xgb_op.fit(X_train, y_train, **fit_params)\n\u001b[32m     85\u001b[39m y_pred_val_xgb_op = pipeline_xgb_op.predict(X_val)\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# m칠trica MAE para xgb_op\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\sklearn\\pipeline.py:663\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    658\u001b[39m         last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    659\u001b[39m             step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    660\u001b[39m             step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    661\u001b[39m             all_params=params,\n\u001b[32m    662\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m         \u001b[38;5;28mself\u001b[39m._final_estimator.fit(Xt, y, **last_step_params[\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\vis_info\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(**kwargs)\n",
            "\u001b[31mTypeError\u001b[39m: XGBModel.fit() got an unexpected keyword argument 'eval_metric'"
          ]
        }
      ],
      "source": [
        "# Inserte su c칩digo ac치\n",
        "\n",
        "def objective(trial):\n",
        "    # Inserte su c칩digo ac치\n",
        "\n",
        "    # 1: de lo que entiendo -> codificacion y escalamiento\n",
        "    # 2: separaci칩n en conjuntos de train, val y test\n",
        "\n",
        "    params_xgb = {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1),\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 1000),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "        \"max_leaves\": trial.suggest_int(\"max_leaves\", 0, 100),\n",
        "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 5),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 1),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 1),\n",
        "    }\n",
        "\n",
        "    params_ohe = {\n",
        "        \"min_frequency\": trial.suggest_float(\"min_frequency\", 0, 1)\n",
        "    }\n",
        "\n",
        "    # debido a que hay que optimizar ese par치metro de one hot enc\n",
        "    # hay definir de nuevo los pipelines\n",
        "\n",
        "    drop_cols = [\"id\"]\n",
        "\n",
        "    num_cols = [\"lat\", \"long\", \"pop\", \"price\"]\n",
        "    cat_cols = [\"city\", \"shop\", \"brand\", \"container\",\n",
        "                \"capacity\", \"day\", \"month\", \"year\"]\n",
        "\n",
        "    # PIPELINES POR GRUPO (punto 3)\n",
        "\n",
        "    num_std_pipeline = Pipeline(\n",
        "        [\n",
        "            # aunque no hayan nulos, coloco esto por completitud\n",
        "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "            (\"sc\", StandardScaler())\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    cat_pipeline = Pipeline(\n",
        "        [\n",
        "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "            (\"onehot\", OneHotEncoder(\n",
        "                handle_unknown=\"ignore\", sparse_output=False, **params_ohe\n",
        "            ))\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    col_transformer = ColumnTransformer(\n",
        "        [\n",
        "            (\"drop_ids\", \"drop\", drop_cols),\n",
        "            (\"numerical\", num_std_pipeline, num_cols),\n",
        "            (\"categorical\", cat_pipeline, cat_cols)\n",
        "        ], verbose_feature_names_out=False, remainder=\"drop\")\n",
        "\n",
        "    # Pruning\n",
        "\n",
        "    pruning_callback = optuna.integration.XGBoostPruningCallback(\n",
        "        trial, observation_key=\"validation_1-mae\"  # un nombre?\n",
        "    )\n",
        "\n",
        "    # pipeline xgb\n",
        "\n",
        "    pipeline_xgb_op = Pipeline(\n",
        "        steps=[\n",
        "            (\"date_features\", date_transformer),\n",
        "            (\"col_transformer\", col_transformer),\n",
        "            (\"regresor_xgb\", XGBRegressor(random_state=42,\n",
        "                                          # monotone_constraints = monotone_constraints,\n",
        "                                          **params_xgb))\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # entrenamiento  y evaluacion\n",
        "    fit_params = {\n",
        "        \"regresor_xgb__eval_set\": [(X_train, y_train), (X_val, y_val)],\n",
        "        \"regresor_xgb__eval_metric\": \"mae\",\n",
        "        \"regresor_xgb__callbacks\": [pruning_callback]\n",
        "    }\n",
        "\n",
        "    pipeline_xgb_op.fit(X_train, y_train, **fit_params)\n",
        "\n",
        "    y_pred_val_xgb_op = pipeline_xgb_op.predict(X_val)\n",
        "\n",
        "    # m칠trica MAE para xgb_op\n",
        "\n",
        "    MAE_op = MAE(y_val, y_pred_val_xgb_op)\n",
        "\n",
        "    # se guarda el mejor piple entrenado\n",
        "    trial.set_user_attr(\"best_pipeline\", pipeline_xgb_op)\n",
        "\n",
        "    return MAE_op\n",
        "\n",
        "\n",
        "# parte 2\n",
        "sampler = TPESampler(seed=seed)\n",
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",  # para minimizar mae\n",
        "    sampler=sampler,\n",
        "    study_name=\"optimizacion xgb con optuna\"\n",
        ")\n",
        "\n",
        "# limite de tiempo 5 minutos\n",
        "\n",
        "study.optimize(objective, timeout=5*60, n_jobs=-1)\n",
        "\n",
        "\n",
        "# printeos: n칰mero de trials, mae y mejores hiperpar치metros\n",
        "\n",
        "print(\"\\n N칰mero de trials: \", len(study.trials))\n",
        "print(\"\\n Mejor MAE: \", study.best_value)\n",
        "print(\"\\n Mejores hiperpar치metros: \\n\", study.best_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "8a081778cc704fc6bed05393a5419327",
        "deepnote_cell_type": "markdown",
        "id": "ZMiiVaCUI5wA"
      },
      "source": [
        "## 5. Visualizaciones (5 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/F-LgB1xTebEAAAAd/look-at-this-graph-nickelback.gif\">\n",
        "</p>\n",
        "\n",
        "\n",
        "Satisfecho con su trabajo, Fiu le pregunta si es posible generar visualizaciones que permitan entender el entrenamiento de su modelo.\n",
        "\n",
        "A partir del siguiente <a href = https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#visualization>enlace</a>, genere las siguientes visualizaciones:\n",
        "\n",
        "1. Gr치fico de historial de optimizaci칩n [1 punto]\n",
        "2. Gr치fico de coordenadas paralelas [1 punto]\n",
        "3. Gr치fico de importancia de hiperpar치metros [1 punto]\n",
        "\n",
        "Comente sus resultados:\n",
        "\n",
        "4. 쮻esde qu칠 *trial* se empiezan a observar mejoras notables en sus resultados? [0.5 puntos]\n",
        "5. 쯈u칠 tendencias puede observar a partir del gr치fico de coordenadas paralelas? [1 punto]\n",
        "6. 쮺u치les son los hiperpar치metros con mayor importancia para la optimizaci칩n de su modelo? [0.5 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "cell_id": "0e706dc9a8d946eda7a9eb1f0463c6d7",
        "deepnote_cell_type": "code",
        "id": "xjxAEENAI5wA"
      },
      "outputs": [],
      "source": [
        "# Inserte su c칩digo ac치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ac8a20f445d045a3becf1a518d410a7d",
        "deepnote_cell_type": "markdown",
        "id": "EoW32TA9I5wA"
      },
      "source": [
        "## 6. S칤ntesis de resultados (3 puntos)\n",
        "\n",
        "Finalmente:\n",
        "\n",
        "1. Genere una tabla resumen del MAE en el conjunto de validaci칩n obtenido en los 5 modelos entrenados desde Baseline hasta XGBoost con Constraints, Optuna y Prunning. [1 punto]\n",
        "2. Compare los resultados de la tabla y responda, 쯤u칠 modelo obtiene el mejor rendimiento? [0.5 puntos]\n",
        "3. Cargue el mejor modelo, prediga sobre el conjunto de **test** y reporte su MAE. [0.5 puntos]\n",
        "4. 쮼xisten diferencias con respecto a las m칠tricas obtenidas en el conjunto de validaci칩n? 쯇orqu칠 puede ocurrir esto? [1 punto]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jq5C6cDnJg9h"
      },
      "outputs": [],
      "source": [
        "# Inserte su c칩digo ac치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5c4654d12037494fbd385b4dc6bd1059",
        "deepnote_cell_type": "markdown",
        "id": "E_19tgBEI5wA"
      },
      "source": [
        "# Conclusi칩n\n",
        "Exito!\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.pinimg.com/originals/55/3d/42/553d42bea9b10e0662a05aa8726fc7f4.gif\">\n",
        "</p>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "f63d38450a6b464c9bb6385cf11db4d9",
    "deepnote_persisted_session": {
      "createdAt": "2023-11-09T16:18:30.203Z"
    },
    "kernelspec": {
      "display_name": "Python 3.13.5 ('vis_info')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "27f7193e8435d5833318a8779fcc7c01e1e51279cdc9a1fc598f78d31f0d2dc3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
