{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b5c0d2440b3e4995a794ded565213150",
        "deepnote_cell_type": "markdown",
        "id": "_Mql1uRoI5v5"
      },
      "source": [
        "<h1><center>Laboratorio 6: Optimizaci√≥n de modelos üß™</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Primavera 2025</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bfb94b9656f145ad83e81b75d218cb70",
        "deepnote_cell_type": "markdown",
        "id": "FAPGIlEAI5v8"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Diego Cortez, Gabriel Iturra\n",
        "- Auxiliares: Melanie Pe√±a, Valentina Rojas\n",
        "- Ayudantes: Nicol√°s Cabello, Cristopher Urbina"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b1b537fdd27c43909a49d3476ce64d91",
        "deepnote_cell_type": "markdown",
        "id": "8NozgbkZI5v9"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Josefa Anselmo.\n",
        "- Nombre de alumno 2: Tamara Carrasco.\n",
        "\n",
        "\n",
        "Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: Entregas Martes a las 23:59.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda **fuertemente** asistir.\n",
        "- <u>Prohibidas las copias</u>. Cualquier intento de copia ser√° debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est√©n en u-cursos no ser√°n revisados. Recuerden que el repositorio tambi√©n tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Pueden usar cualquier material del curso que estimen conveniente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8qWRbJkcwP9"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [TamoJosha](https://github.com/Tamaracarrasco/TamoJosha-Lab-de-Prog-MDS-Prim2025)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b7dbdd30ab544cb8a8afe00648a586ae",
        "deepnote_cell_type": "markdown",
        "id": "vHU9DI6wI5v9"
      },
      "source": [
        "### Temas a tratar\n",
        "\n",
        "- Predicci√≥n de demanda usando `xgboost`\n",
        "- B√∫squeda del modelo √≥ptimo de clasificaci√≥n usando `optuna`\n",
        "- Uso de pipelines.\n",
        "\n",
        "\n",
        "### Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: 6 d√≠as de plazo con descuento de 1 punto por d√≠a. Entregas Martes a las 23:59.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda fuertemente asistir.\n",
        "- <u>Prohibidas las copias</u>. Cualquier intento de copia ser√° debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est√©n en u-cursos no ser√°n revisados. Recuerden que el repositorio tambi√©n tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Pueden usar cualquier material del curso que estimen conveniente.\n",
        "\n",
        "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f1c73babb7f74af588a4fa6ae14829e0",
        "deepnote_cell_type": "markdown",
        "id": "U_-sNOuOI5v9"
      },
      "source": [
        "# Importamos librerias √∫tiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cell_id": "51afe4d2df42442b9e5402ffece60ead",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 4957,
        "execution_start": 1699544354044,
        "id": "ekHbM85NI5v9",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "!pip install -qq xgboost optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6hJXpLCSspz"
      },
      "source": [
        "# El emprendimiento de Fiu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "44d227389a734ac59189c5e0005bc68a",
        "deepnote_cell_type": "markdown",
        "id": "b0bDalAOI5v-"
      },
      "source": [
        "Tras liderar de manera exitosa la implementaci√≥n de un proyecto de ciencia de datos para caracterizar los datos generados en Santiago 2023, el misterioso corp√≥reo **Fiu** se anima y decide levantar su propio negocio de consultor√≠a en machine learning. Tras varias e intensas negociaciones, Fiu logra encontrar su *primera chamba*: predecir la demanda (cantidad de venta) de una famosa productora de bebidas de calibre mundial. Al ver el gran potencial y talento que usted ha demostrado en el campo de la ciencia de datos, Fiu lo contrata como data scientist para que forme parte de su nuevo emprendimiento.\n",
        "\n",
        "Para este laboratorio deben trabajar con los datos `sales.csv` subidos a u-cursos, el cual contiene una muestra de ventas de la empresa para diferentes productos en un determinado tiempo.\n",
        "\n",
        "Para comenzar, cargue el dataset se√±alado y visualice a trav√©s de un `.head` los atributos que posee el dataset.\n",
        "\n",
        "<i><p align=\"center\">Fiu siendo felicitado por su excelente desempe√±o en el proyecto de caracterizaci√≥n de datos</p></i>\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media-front.elmostrador.cl/2023/09/A_UNO_1506411_2440e.jpg\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cell_id": "2f9c82d204b14515ad27ae07e0b77702",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 92,
        "execution_start": 1699544359006,
        "id": "QvMPOqHuI5v-",
        "source_hash": null
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>city</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>pop</th>\n",
              "      <th>shop</th>\n",
              "      <th>brand</th>\n",
              "      <th>container</th>\n",
              "      <th>capacity</th>\n",
              "      <th>price</th>\n",
              "      <th>quantity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>0.96</td>\n",
              "      <td>13280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>plastic</td>\n",
              "      <td>1.5lt</td>\n",
              "      <td>2.86</td>\n",
              "      <td>6727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>kinder-cola</td>\n",
              "      <td>can</td>\n",
              "      <td>330ml</td>\n",
              "      <td>0.87</td>\n",
              "      <td>9848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>adult-cola</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>1.00</td>\n",
              "      <td>20050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>adult-cola</td>\n",
              "      <td>can</td>\n",
              "      <td>330ml</td>\n",
              "      <td>0.39</td>\n",
              "      <td>25696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>orange-power</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>1.00</td>\n",
              "      <td>15041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>orange-power</td>\n",
              "      <td>can</td>\n",
              "      <td>330ml</td>\n",
              "      <td>0.43</td>\n",
              "      <td>34578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>gazoza</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>0.49</td>\n",
              "      <td>44734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>lemon-boost</td>\n",
              "      <td>glass</td>\n",
              "      <td>500ml</td>\n",
              "      <td>0.70</td>\n",
              "      <td>18623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>31/01/12</td>\n",
              "      <td>Athens</td>\n",
              "      <td>37.97945</td>\n",
              "      <td>23.71622</td>\n",
              "      <td>672130</td>\n",
              "      <td>shop_1</td>\n",
              "      <td>lemon-boost</td>\n",
              "      <td>plastic</td>\n",
              "      <td>1.5lt</td>\n",
              "      <td>2.21</td>\n",
              "      <td>9645</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id      date    city       lat      long     pop    shop         brand  \\\n",
              "0   0  31/01/12  Athens  37.97945  23.71622  672130  shop_1   kinder-cola   \n",
              "1   1  31/01/12  Athens  37.97945  23.71622  672130  shop_1   kinder-cola   \n",
              "2   2  31/01/12  Athens  37.97945  23.71622  672130  shop_1   kinder-cola   \n",
              "3   3  31/01/12  Athens  37.97945  23.71622  672130  shop_1    adult-cola   \n",
              "4   4  31/01/12  Athens  37.97945  23.71622  672130  shop_1    adult-cola   \n",
              "5   5  31/01/12  Athens  37.97945  23.71622  672130  shop_1  orange-power   \n",
              "6   6  31/01/12  Athens  37.97945  23.71622  672130  shop_1  orange-power   \n",
              "7   7  31/01/12  Athens  37.97945  23.71622  672130  shop_1        gazoza   \n",
              "8   8  31/01/12  Athens  37.97945  23.71622  672130  shop_1   lemon-boost   \n",
              "9   9  31/01/12  Athens  37.97945  23.71622  672130  shop_1   lemon-boost   \n",
              "\n",
              "  container capacity  price  quantity  \n",
              "0     glass    500ml   0.96     13280  \n",
              "1   plastic    1.5lt   2.86      6727  \n",
              "2       can    330ml   0.87      9848  \n",
              "3     glass    500ml   1.00     20050  \n",
              "4       can    330ml   0.39     25696  \n",
              "5     glass    500ml   1.00     15041  \n",
              "6       can    330ml   0.43     34578  \n",
              "7     glass    500ml   0.49     44734  \n",
              "8     glass    500ml   0.70     18623  \n",
              "9   plastic    1.5lt   2.21      9645  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "df = pd.read_csv(\"sales.csv\")\n",
        "\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dimensiones del dataset:\n",
            " (7456, 12)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7456 entries, 0 to 7455\n",
            "Data columns (total 12 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   id         7456 non-null   int64  \n",
            " 1   date       7456 non-null   object \n",
            " 2   city       7456 non-null   object \n",
            " 3   lat        7456 non-null   float64\n",
            " 4   long       7456 non-null   float64\n",
            " 5   pop        7456 non-null   int64  \n",
            " 6   shop       7456 non-null   object \n",
            " 7   brand      7456 non-null   object \n",
            " 8   container  7456 non-null   object \n",
            " 9   capacity   7456 non-null   object \n",
            " 10  price      7456 non-null   float64\n",
            " 11  quantity   7456 non-null   int64  \n",
            "dtypes: float64(3), int64(3), object(6)\n",
            "memory usage: 699.1+ KB\n",
            "\n",
            " Tipo de valores en las columnas: \n",
            " None\n",
            "\n",
            " Cantidad de valores nulos: \n",
            " id           0\n",
            "date         0\n",
            "city         0\n",
            "lat          0\n",
            "long         0\n",
            "pop          0\n",
            "shop         0\n",
            "brand        0\n",
            "container    0\n",
            "capacity     0\n",
            "price        0\n",
            "quantity     0\n",
            "dtype: int64\n",
            "\n",
            " Valores duplicados: \n",
            " 0\n",
            "\n",
            " describe de las variables n√∫mericas: \n",
            "                 id          lat         long            pop        price  \\\n",
            "count  7456.000000  7456.000000  7456.000000    7456.000000  7456.000000   \n",
            "mean   3784.926770    38.300616    23.270170  355042.733637     1.197193   \n",
            "std    2185.822361     1.650030     1.086592  232336.703020     0.818175   \n",
            "min       0.000000    35.327870    21.734440  134219.000000     0.110000   \n",
            "25%    1889.750000    37.962450    22.417610  141732.000000     0.620000   \n",
            "50%    3783.500000    38.244440    22.930860  257501.500000     0.930000   \n",
            "75%    5682.250000    39.636890    23.716220  665102.000000     1.510000   \n",
            "max    7559.000000    40.643610    25.143410  672130.000000     4.790000   \n",
            "\n",
            "            quantity  \n",
            "count    7456.000000  \n",
            "mean    29408.428380  \n",
            "std     17652.985675  \n",
            "min      2953.000000  \n",
            "25%     16572.750000  \n",
            "50%     25294.500000  \n",
            "75%     37699.000000  \n",
            "max    145287.000000  \n",
            "\n",
            " Estad√≠sticas de las variables no num√©ricas: \n",
            "             date    city    shop        brand container capacity\n",
            "count       7456    7456    7456         7456      7456     7456\n",
            "unique        84       5       6            5         3        3\n",
            "top     31/12/18  Athens  shop_4  kinder-cola     glass    330ml\n",
            "freq          90    2482    1246         1495      2486     2486\n",
            "\n",
            " ========= RANGO TEMPORAL (Aparente) =========\n",
            "Fecha inicial:  28/02/13\n",
            "√∫ltima fecha:  31/12/18\n"
          ]
        }
      ],
      "source": [
        "## Exploraci√≥n b√°sica de los datos\n",
        "\n",
        "print(\"\\nDimensiones del dataset:\\n\", df.shape)\n",
        "print(\"\\n Tipo de valores en las columnas: \\n\", df.info())\n",
        "print(\"\\n Cantidad de valores nulos: \\n\", df.isna().sum())\n",
        "print(\"\\n Valores duplicados: \\n\", df.duplicated().sum())\n",
        "print(\"\\n describe de las variables n√∫mericas: \\n\", df.select_dtypes(include=\"number\").describe())\n",
        "print(\"\\n Estad√≠sticas de las variables no num√©ricas: \\n\", df.select_dtypes(include=\"object\").describe())\n",
        "\n",
        "## Rango temporal de los datos.\n",
        "\n",
        "print(\"\\n ========= RANGO TEMPORAL (Aparente) =========\")\n",
        "print(\"Fecha inicial: \", df[\"date\"].min())\n",
        "print(\"√∫ltima fecha: \", df[\"date\"].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Comentario**\n",
        "\n",
        " De las estad√≠sticas, se desprende lo siguiente:\n",
        "- NO hay valores nulos.\n",
        "- No hay valores duplicados.\n",
        "- Al parecer no hay valores raros como cantidades de \"quantity\" negativas.\n",
        "- dentro de las variables categ√≥ricas, ``capacity`` es una variable categ√≥rica ordinal. El resto de variables categ√≥ricas son nominales.\n",
        "- Se tiene ``date``, serie de tiempo.\n",
        "\n",
        "\n",
        "- Se tienen 5 ciudades:  Athens, Thessaloniki, Patra, Larisa, Irakleion.\n",
        "- Hay 6 tiendas distintas: shop_1,..., shop_6.\n",
        "\t* shop_1 solo est√° en Athens.\n",
        "\t* shop_2 solo est√° en Irakleion.\n",
        "\t* shop_3 tambi√©n est√° en Athens.\n",
        "\t* shop_4 est√° en Thessaloniki.\n",
        "\t* shop_5 est√° en Larisa.\n",
        "\t* shop_6 est√° en Patra.\n",
        "\n",
        "- Se tienen 5 marcas posibles:\n",
        "\t* kinder-cola: plastic, can, glass\n",
        "\t* adult-cola: plastic, can, glass\n",
        "\t* lemon-boost: glass, can, plastic\n",
        "\t* gazoza: glass, plastic, can\n",
        "\t* orange-power: glass, can, plastic\n",
        "    \t\n",
        "- hay 3 tipos de envase (container):\n",
        "\t- glass: hay de capacidad de 500ml y 330 ml\n",
        "\t- can:  tiene solo capacidad de 330ml\n",
        "\t- plastic: tiene solo de 1.5lts\n",
        "\n",
        "**La variable target es ``quantity`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b50db6f2cb804932ae3f9e5748a6ea61",
        "deepnote_cell_type": "markdown",
        "id": "pk4ru76pI5v_"
      },
      "source": [
        "## 1 Generando un Baseline (5 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/O-lan6TkadUAAAAC/what-i-wnna-do-after-a-baseline.gif\">\n",
        "</p>\n",
        "\n",
        "Antes de entrenar un algoritmo, usted recuerda los apuntes de su mag√≠ster en ciencia de datos y recuerda que debe seguir una serie de *buenas pr√°cticas* para entrenar correcta y debidamente su modelo. Despu√©s de un par de vueltas, llega a las siguientes tareas:\n",
        "\n",
        "1. Separe los datos en conjuntos de train (70%), validation (20%) y test (10%). Fije una semilla para controlar la aleatoriedad. [0.5 puntos]\n",
        "2. Implemente un `FunctionTransformer` para extraer el d√≠a, mes y a√±o de la variable `date`. Guarde estas variables en el formato categorical de pandas. [1 punto]\n",
        "3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos num√©ricos y categ√≥ricos. Use `OneHotEncoder` para las variables categ√≥ricas. `Nota:` Utilice el m√©todo `.set_output(transform='pandas')` para obtener un DataFrame como salida del `ColumnTransformer` [1 punto]\n",
        "4. Guarde los pasos anteriores en un `Pipeline`, dejando como √∫ltimo paso el regresor `DummyRegressor` para generar predicciones en base a promedios. [0.5 punto]\n",
        "5. Entrene el pipeline anterior y reporte la m√©trica `mean_absolute_error` sobre los datos de validaci√≥n. ¬øC√≥mo se interpreta esta m√©trica para el contexto del negocio? [0.5 puntos]\n",
        "6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los par√°metros por default**. ¬øC√≥mo cambia el MAE al implementar este algoritmo? ¬øEs mejor o peor que el `DummyRegressor`? [1 punto]\n",
        "7. Guarde ambos modelos en un archivo .pkl (uno cada uno) [0.5 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%!pip` not found.\n"
          ]
        }
      ],
      "source": [
        "%!pip install autopep8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cell_id": "1482c992d9494e5582b23dbd3431dbfd",
        "deepnote_cell_type": "code",
        "id": "sfnN7HubI5v_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valor MAE (DummyRegressor) para conjunto Validaci√≥n:  12484.902691741254\n",
            "Valor MAE (XGBRegressor) para conjunto Validaci√≥n:  2868.03515625\n"
          ]
        }
      ],
      "source": [
        "# importaci√≥n de librer√≠as importantes.\n",
        "\n",
        "# separacion de conjuntos\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# para el pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# m√©tricas\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error as MAE\n",
        "\n",
        "# para guardar los modelos con pickle\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "from sklearn import set_config\n",
        "set_config(transform_output=\"pandas\")\n",
        "\n",
        "# Inserte su c√≥digo ac√°\n",
        "\n",
        "# Definici√≥n de FunctionTraformer (Punto 2)\n",
        "\n",
        "\n",
        "def extrae_fecha(dataframe_in, col=\"date\"):\n",
        "    \"\"\"\n",
        "    Esta funci√≥n deber√≠a estraer el d√≠a, mes y a√±o\n",
        "    de la variable \"date\" de un dataframe.\n",
        "    Guarda las variables en el formato categ√≥rico\n",
        "    de pandas.\n",
        "\n",
        "    Par√°metros:\n",
        "    -------------------\n",
        "    dataframe_in: dataframe para extraer los datos. \n",
        "    Debe contener columna \"date\".\n",
        "\n",
        "    col: columna de la fecha. Default \"date\".\n",
        "\n",
        "    \"\"\"\n",
        "    # primer transformamos esa columna a una nueva\n",
        "\n",
        "    df_copy = dataframe_in.copy()\n",
        "\n",
        "    df_copy[\"fecha\"] = pd.to_datetime(\n",
        "        df_copy[col], dayfirst=True, errors=\"coerce\", format=\"%d/%m/%y\")\n",
        "\n",
        "    # se crean las columnas de d√≠a, mes y a√±o.\n",
        "\n",
        "    df_copy[\"day\"] = df_copy[\"fecha\"].dt.day.astype(\"category\")\n",
        "    df_copy[\"month\"] = df_copy[\"fecha\"].dt.month.astype(\"category\")\n",
        "    df_copy[\"year\"] = df_copy[\"fecha\"].dt.year.astype(\"category\")\n",
        "\n",
        "    return df_copy\n",
        "\n",
        "\n",
        "date_transformer = FunctionTransformer(extrae_fecha)\n",
        "\n",
        "\n",
        "# SEPARACI√ìN DE CONJUNTOS (Punto 1)\n",
        "\n",
        "df_x = df.drop(columns=\"quantity\").copy()\n",
        "df_y = df[\"quantity\"]\n",
        "\n",
        "\n",
        "# fijo el random state por si acaso.\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    df_x, df_y, random_state=42, shuffle=False, stratify=None, train_size=0.7)\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_val, y_val, test_size=0.33, shuffle=False, stratify=None, random_state=42)\n",
        "\n",
        "\n",
        "drop_cols = [\"id\"]\n",
        "\n",
        "num_cols = [\"lat\", \"long\", \"pop\", \"price\"]\n",
        "cat_cols = [\"city\", \"shop\", \"brand\", \"container\",\n",
        "            \"capacity\", \"day\", \"month\", \"year\"]\n",
        "\n",
        "# PIPELINES POR GRUPO (punto 3)\n",
        "\n",
        "num_std_pipeline = Pipeline(\n",
        "    [\n",
        "        # aunque no hayna nulos, coloco esto por completitud\n",
        "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"sc\", StandardScaler())\n",
        "    ]\n",
        ")\n",
        "\n",
        "cat_pipeline = Pipeline(\n",
        "    [\n",
        "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(\n",
        "            handle_unknown=\"ignore\", sparse_output=False\n",
        "        ))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# COLUMN TRANSFORMER (PARTE 3)\n",
        "\n",
        "col_transformer = ColumnTransformer(\n",
        "    [\n",
        "        (\"drop_ids\", \"drop\", drop_cols),\n",
        "        (\"numerical\", num_std_pipeline, num_cols),\n",
        "        (\"categorical\", cat_pipeline, cat_cols)\n",
        "    ], verbose_feature_names_out=False, remainder=\"drop\"\n",
        ")\n",
        "\n",
        "col_transformer.set_output(transform=\"pandas\")\n",
        "\n",
        "\n",
        "# PIPELINE DEL MODELO (PARTE 4)\n",
        "\n",
        "pipeline_dummyreg = Pipeline(\n",
        "    steps=[\n",
        "        (\"date_features\", date_transformer),\n",
        "        (\"col_transformer\", col_transformer),\n",
        "        (\"regresor_dummy\", DummyRegressor(strategy=\"mean\"))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ENTRENAMIENTO DEL MODELO DUMMYREGRESSOR\n",
        "\n",
        "pipeline_dummyreg.fit(X_train, y_train)\n",
        "\n",
        "# PREDICCIONES DUMMYREGRESSOR\n",
        "\n",
        "y_pred_val_dummyreg = pipeline_dummyreg.predict(X_val)\n",
        "\n",
        "#### REPORTE DUMMY MAE para dummyregressor (PARTE 5)\n",
        "\n",
        "print(\"Valor MAE (DummyRegressor) para conjunto Validaci√≥n: \",\n",
        "      MAE(y_val, y_pred_val_dummyreg))\n",
        "\n",
        "### XGBOOST (PARTE 6)\n",
        "\n",
        "pipeline_xgb = Pipeline(\n",
        "    steps=[\n",
        "        (\"date_features\", date_transformer),\n",
        "        (\"col_transformer\", col_transformer),\n",
        "        (\"regresor_xgb\", XGBRegressor(random_state=42))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ENTRENAMIENTO DEL MODELO XGBOOST REGRESSOR\n",
        "\n",
        "pipeline_xgb.fit(X_train, y_train)\n",
        "\n",
        "# PREDICCIONES XGBOOST REGRESSOR\n",
        "\n",
        "y_pred_val_xgb = pipeline_xgb.predict(X_val)\n",
        "\n",
        "# reporte de m√©trica MAE para xgb regressor\n",
        "\n",
        "print(\"Valor MAE (XGBRegressor) para conjunto Validaci√≥n: \",\n",
        "      MAE(y_val, y_pred_val_xgb))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**interpretaci√≥n de la comparaci√≥n de los MAE's**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PARTE 7: Guardado de modelos\n",
        "\n",
        "# Para dummy_regressor\n",
        "\n",
        "# Definir carpeta base para dummyregresor\n",
        "base_path = os.path.join(os.getcwd(), \"Laboratorios\", \"Laboratorio_6\", \"data\")\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# Guardar predicciones\n",
        "pd.DataFrame({\"predicciones\": y_pred_val_dummyreg}).to_csv(\n",
        "    os.path.join(base_path, \"predicciones_dummy_regressor.csv\"), index=False\n",
        ")\n",
        "\n",
        "# Guardar modelo\n",
        "with open(os.path.join(base_path, \"dummy_regressor_model.sav\"), \"wb\") as f:\n",
        "    pickle.dump(pipeline_dummyreg, f)\n",
        "\n",
        "# Cargar modelo\n",
        "with open(os.path.join(base_path, \"dummy_regressor_model.sav\"), \"rb\") as f:\n",
        "    modelo_loaded = pickle.load(f)\n",
        "\n",
        "# # Usar modelo cargado\n",
        "# y_pred_modelo_loaded = modelo_loaded.predict(X_val)\n",
        "\n",
        "# para xgboost regressor\n",
        "\n",
        "# Definir carpeta base para xgboost\n",
        "base_path = os.path.join(os.getcwd(), \"Laboratorios\", \"Laboratorio_6\", \"data\")\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# Guardar predicciones\n",
        "pd.DataFrame({\"predicciones\": y_pred_val_xgb}).to_csv(\n",
        "    os.path.join(base_path, \"predicciones_xgb_regressor.csv\"), index=False\n",
        ")\n",
        "\n",
        "# Guardar modelo\n",
        "with open(os.path.join(base_path, \"xgb_regressor_model.sav\"), \"wb\") as f:\n",
        "    pickle.dump(pipeline_xgb, f)\n",
        "\n",
        "# Cargar modelo\n",
        "with open(os.path.join(base_path, \"xgb_regressor_model.sav\"), \"rb\") as f:\n",
        "    modelo_loaded = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "7e17e46063774ec28226fe300d42ffe0",
        "deepnote_cell_type": "markdown",
        "id": "wnyMINdKI5v_"
      },
      "source": [
        "## 2. Forzando relaciones entre par√°metros con XGBoost (10 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://64.media.tumblr.com/14cc45f9610a6ee341a45fd0d68f4dde/20d11b36022bca7b-bf/s640x960/67ab1db12ff73a530f649ac455c000945d99c0d6.gif\">\n",
        "</p>\n",
        "\n",
        "Un colega aficionado a la econom√≠a le *sopla* que la demanda guarda una relaci√≥n inversa con el precio del producto. Motivado para impresionar al querido corp√≥reo, se propone hacer uso de esta informaci√≥n para mejorar su modelo realizando las siguientes tareas:\n",
        "\n",
        "1. Vuelva a entrenar el `Pipeline` con `XGBRegressor`, pero esta vez forzando una relaci√≥n mon√≥tona negativa entre el precio y la cantidad. Para aplicar esta restricci√≥n ap√≥yese en la siguiente <a href = https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html>documentaci√≥n</a>. [6 puntos]\n",
        "\n",
        ">Hint 1: Para implementar el constraint se le sugiere hacerlo especificando el nombre de la variable. De ser as√≠, probablemente le sea √∫til **mantener el formato de pandas** antes del step de entrenamiento.\n",
        "\n",
        ">Hint 2: Puede obtener el nombre de las columnas en el paso anterior al modelo regresor mediante el m√©todo `.get_feature_names_out()`\n",
        "\n",
        "2. Luego, vuelva a reportar el `MAE` sobre el conjunto de validaci√≥n. [1 puntos]\n",
        "\n",
        "3. ¬øC√≥mo cambia el error al incluir esta relaci√≥n? ¬øTen√≠a raz√≥n su amigo? [2 puntos]\n",
        "\n",
        "4. Guarde su modelo en un archivo .pkl [1 punto]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['lat' 'long' 'pop' 'price' 'city_Athens' 'city_Irakleion' 'city_Larisa'\n",
            " 'city_Patra' 'city_Thessaloniki' 'shop_shop_1' 'shop_shop_2'\n",
            " 'shop_shop_3' 'shop_shop_4' 'shop_shop_5' 'shop_shop_6'\n",
            " 'brand_adult-cola' 'brand_gazoza' 'brand_kinder-cola' 'brand_lemon-boost'\n",
            " 'brand_orange-power' 'container_can' 'container_glass'\n",
            " 'container_plastic' 'capacity_1.5lt' 'capacity_330ml' 'capacity_500ml'\n",
            " 'day_28' 'day_29' 'day_30' 'day_31' 'month_1' 'month_2' 'month_3'\n",
            " 'month_4' 'month_5' 'month_6' 'month_7' 'month_8' 'month_9' 'month_10'\n",
            " 'month_11' 'month_12' 'year_2012' 'year_2013' 'year_2014' 'year_2015'\n",
            " 'year_2016']\n"
          ]
        }
      ],
      "source": [
        "## Hint 1 y 2: obtener el nombre de las columnas en el\n",
        "## paso anterior \n",
        "## pipeline_xgb.get_feature_names_out() no funciona porque \n",
        "## date_trasnformer,  al ser un FunctionTrasnformer, no tiene ese m√©todo.\n",
        "\n",
        "X_train_trans = pipeline_xgb.named_steps[\"date_features\"].transform(X_train)\n",
        "X_train_trans = pipeline_xgb.named_steps[\"col_transformer\"].fit_transform(X_train_trans)\n",
        "\n",
        "features_names = pipeline_xgb.named_steps[\"col_transformer\"].get_feature_names_out()\n",
        "print(features_names)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'lat': 0, 'long': 0, 'pop': 0, 'price': -1, 'city_Athens': 0, 'city_Irakleion': 0, 'city_Larisa': 0, 'city_Patra': 0, 'city_Thessaloniki': 0, 'shop_shop_1': 0, 'shop_shop_2': 0, 'shop_shop_3': 0, 'shop_shop_4': 0, 'shop_shop_5': 0, 'shop_shop_6': 0, 'brand_adult-cola': 0, 'brand_gazoza': 0, 'brand_kinder-cola': 0, 'brand_lemon-boost': 0, 'brand_orange-power': 0, 'container_can': 0, 'container_glass': 0, 'container_plastic': 0, 'capacity_1.5lt': 0, 'capacity_330ml': 0, 'capacity_500ml': 0, 'day_28': 0, 'day_29': 0, 'day_30': 0, 'day_31': 0, 'month_1': 0, 'month_2': 0, 'month_3': 0, 'month_4': 0, 'month_5': 0, 'month_6': 0, 'month_7': 0, 'month_8': 0, 'month_9': 0, 'month_10': 0, 'month_11': 0, 'month_12': 0, 'year_2012': 0, 'year_2013': 0, 'year_2014': 0, 'year_2015': 0, 'year_2016': 0}\n"
          ]
        }
      ],
      "source": [
        "## ahora se tiene el orden real de las columnas\n",
        "## todas las columnas que no sean \"price\", deben llevar 0\n",
        "## para price debe ser -1\n",
        "\n",
        "monotone_constraints_mapeo = {name: 0 for name in features_names} # ac√° se genera un diccionario con 0's \n",
        "\n",
        "monotone_constraints_mapeo[\"price\"] = -1 # se pone -1 porque es una relaci√≥n inversa con quantity\n",
        "                                            # decreasing constraint\n",
        "\n",
        "print(monotone_constraints_mapeo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "monotone_constraints_mapeo[\"price\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# se genera lista con los valores del diccionario de arriba\n",
        "monotone_constraints = [monotone_constraints_mapeo[name] for name in features_names] # [0, 0, 0, -1, ..., 0]\n",
        "\n",
        "# ahora se tiene que transformar a tupla\n",
        "\n",
        "monotone_constraints = tuple(monotone_constraints) # (0, 0, 0, -1, ...., 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cell_id": "f469f3b572be434191d2d5c3f11b20d2",
        "deepnote_cell_type": "code",
        "id": "B7tMnkiAI5v_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valor MAE (XGB) para conjunto Validaci√≥n (wc: with constraints):  2931.6552734375\n"
          ]
        }
      ],
      "source": [
        "# Inserte su c√≥digo ac√°\n",
        "\n",
        "### XGBOOST \n",
        "\n",
        "pipeline_xgb_wc = Pipeline(\n",
        "    steps=[\n",
        "        (\"date_features\", date_transformer),\n",
        "        (\"col_transformer\", col_transformer),\n",
        "        (\"regresor_xgb\", XGBRegressor(random_state=42, \n",
        "        monotone_constraints = monotone_constraints))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ENTRENAMIENTO DEL MODELO XGBOOST REGRESSOR\n",
        "\n",
        "pipeline_xgb_wc.fit(X_train, y_train)\n",
        "\n",
        "# PREDICCIONES XGBOOST REGRESSOR\n",
        "\n",
        "y_pred_val_xgb_wc = pipeline_xgb_wc.predict(X_val)\n",
        "\n",
        "print(\"Valor MAE (XGB) para conjunto Validaci√≥n (wc: with constraints): \",\n",
        "      MAE(y_val, y_pred_val_xgb_wc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Guardado del modelo: _wc -> with constraints\n",
        "\n",
        "# Definir carpeta base para dummyregresor\n",
        "base_path = os.path.join(os.getcwd(), \"Laboratorios\", \"Laboratorio_6\", \"data\")\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# Guardar predicciones\n",
        "pd.DataFrame({\"predicciones\": y_pred_val_xgb_wc}).to_csv(\n",
        "    os.path.join(base_path, \"predicciones_xgb_regressor_wc.csv\"), index=False\n",
        ")\n",
        "\n",
        "# Guardar modelo\n",
        "with open(os.path.join(base_path, \"xgb_regressor_model_wc.sav\"), \"wb\") as f:\n",
        "    pickle.dump(pipeline_xgb_wc, f)\n",
        "\n",
        "# Cargar modelo\n",
        "with open(os.path.join(base_path, \"xgb_regressor_model_wc.sav\"), \"rb\") as f:\n",
        "    modelo_loaded = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e59ef80ed20b4de8921f24da74e87374",
        "deepnote_cell_type": "markdown",
        "id": "5D5-tX4dI5v_"
      },
      "source": [
        "## 1.3 Optimizaci√≥n de Hiperpar√°metros con Optuna (20 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/fmNdyGN4z5kAAAAi/hacking-lucy.gif\">\n",
        "</p>\n",
        "\n",
        "Luego de presentarle sus resultados, Fiu le pregunta si es posible mejorar *aun m√°s* su modelo. En particular, le comenta de la optimizaci√≥n de hiperpar√°metros con metodolog√≠as bayesianas a trav√©s del paquete `optuna`. Como usted es un aficionado al entrenamiento de modelos de ML, se propone implementar la descabellada idea de su jefe.\n",
        "\n",
        "A partir de la mejor configuraci√≥n obtenida en la secci√≥n anterior, utilice `optuna` para optimizar sus hiperpar√°metros. En particular, se pide que su optimizaci√≥n considere lo siguiente:\n",
        "\n",
        "- Fijar una semilla en las instancias necesarias para garantizar la reproducibilidad de resultados\n",
        "- Utilice `TPESampler` como m√©todo de muestreo\n",
        "- De `XGBRegressor`, optimice los siguientes hiperpar√°metros:\n",
        "    - `learning_rate` buscando valores flotantes en el rango (0.001, 0.1)\n",
        "    - `n_estimators` buscando valores enteros en el rango (50, 1000)\n",
        "    - `max_depth` buscando valores enteros en el rango (3, 10)\n",
        "    - `max_leaves` buscando valores enteros en el rango (0, 100)\n",
        "    - `min_child_weight` buscando valores enteros en el rango (1, 5)\n",
        "    - `reg_alpha` buscando valores flotantes en el rango (0, 1)\n",
        "    - `reg_lambda` buscando valores flotantes en el rango (0, 1)\n",
        "- De `OneHotEncoder`, optimice el hiperpar√°metro `min_frequency` buscando el mejor valor flotante en el rango (0.0, 1.0)\n",
        "\n",
        "Para ello se pide los siguientes pasos:\n",
        "1. Implemente una funci√≥n `objective()` que permita minimizar el `MAE` en el conjunto de validaci√≥n. Use el m√©todo `.set_user_attr()` para almacenar el mejor pipeline entrenado. [10 puntos]\n",
        "2. Fije el tiempo de entrenamiento a 5 minutos. [1 punto]\n",
        "3. Optimizar el modelo y reportar el n√∫mero de *trials*, el `MAE` y los mejores hiperpar√°metros encontrados. ¬øC√≥mo cambian sus resultados con respecto a la secci√≥n anterior? ¬øA qu√© se puede deber esto? [3 puntos]\n",
        "4. Explique cada hiperpar√°metro y su rol en el modelo. ¬øHacen sentido los rangos de optimizaci√≥n indicados? [5 puntos]\n",
        "5. Guardar su modelo en un archivo .pkl [1 punto]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "de5914621cc64cb0b1bacb9ff565a97e",
        "deepnote_cell_type": "code",
        "id": "kMXXi1ckI5v_"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "# Inserte su c√≥digo ac√°\n",
        "\n",
        "def objective(trial):\n",
        "    # Inserte su c√≥digo ac√°\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5195ccfc37e044ad9453f6eb2754f631",
        "deepnote_cell_type": "markdown",
        "id": "ZglyD_QWI5wA"
      },
      "source": [
        "## 4. Optimizaci√≥n de Hiperpar√°metros con Optuna y Prunners (17 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.pinimg.com/originals/90/16/f9/9016f919c2259f3d0e8fe465049638a7.gif\">\n",
        "</p>\n",
        "\n",
        "Despu√©s de optimizar el rendimiento de su modelo varias veces, Fiu le pregunta si no es posible optimizar el entrenamiento del modelo en s√≠ mismo. Despu√©s de leer un par de post de personas de dudosa reputaci√≥n en la *deepweb*, usted llega a la conclusi√≥n que puede cumplir este objetivo mediante la implementaci√≥n de **Prunning**.\n",
        "\n",
        "Vuelva a optimizar los mismos hiperpar√°metros que la secci√≥n pasada, pero esta vez utilizando **Prunning** en la optimizaci√≥n. En particular, usted debe:\n",
        "\n",
        "- Responder: ¬øQu√© es prunning? ¬øDe qu√© forma deber√≠a impactar en el entrenamiento? [2 puntos]\n",
        "- Redefinir la funci√≥n `objective()` utilizando `optuna.integration.XGBoostPruningCallback` como m√©todo de **Prunning** [10 puntos]\n",
        "- Fijar nuevamente el tiempo de entrenamiento a 5 minutos [1 punto]\n",
        "- Reportar el n√∫mero de *trials*, el `MAE` y los mejores hiperpar√°metros encontrados. ¬øC√≥mo cambian sus resultados con respecto a la secci√≥n anterior? ¬øA qu√© se puede deber esto? [3 puntos]\n",
        "- Guardar su modelo en un archivo .pkl [1 punto]\n",
        "\n",
        "Nota: Si quieren silenciar los prints obtenidos en el prunning, pueden hacerlo mediante el siguiente comando:\n",
        "\n",
        "```\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "```\n",
        "\n",
        "De implementar la opci√≥n anterior, pueden especificar `show_progress_bar = True` en el m√©todo `optimize` para *m√°s sabor*.\n",
        "\n",
        "Hint: Si quieren especificar par√°metros del m√©todo .fit() del modelo a trav√©s del pipeline, pueden hacerlo por medio de la siguiente sintaxis: `pipeline.fit(stepmodelo__parametro = valor)`\n",
        "\n",
        "Hint2: Este <a href = https://stackoverflow.com/questions/40329576/sklearn-pass-fit-parameters-to-xgboost-in-pipeline>enlace</a> les puede ser de ayuda en su implementaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IEEZnb-cwP_"
      },
      "outputs": [],
      "source": [
        "#!pip install optuna-integration[xgboost]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "eeaa967cd8f6426d8c54f276c17dce79",
        "deepnote_cell_type": "code",
        "id": "sST6Wtj5I5wA"
      },
      "outputs": [],
      "source": [
        "# Inserte su c√≥digo ac√°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "8a081778cc704fc6bed05393a5419327",
        "deepnote_cell_type": "markdown",
        "id": "ZMiiVaCUI5wA"
      },
      "source": [
        "## 5. Visualizaciones (5 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/F-LgB1xTebEAAAAd/look-at-this-graph-nickelback.gif\">\n",
        "</p>\n",
        "\n",
        "\n",
        "Satisfecho con su trabajo, Fiu le pregunta si es posible generar visualizaciones que permitan entender el entrenamiento de su modelo.\n",
        "\n",
        "A partir del siguiente <a href = https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#visualization>enlace</a>, genere las siguientes visualizaciones:\n",
        "\n",
        "1. Gr√°fico de historial de optimizaci√≥n [1 punto]\n",
        "2. Gr√°fico de coordenadas paralelas [1 punto]\n",
        "3. Gr√°fico de importancia de hiperpar√°metros [1 punto]\n",
        "\n",
        "Comente sus resultados:\n",
        "\n",
        "4. ¬øDesde qu√© *trial* se empiezan a observar mejoras notables en sus resultados? [0.5 puntos]\n",
        "5. ¬øQu√© tendencias puede observar a partir del gr√°fico de coordenadas paralelas? [1 punto]\n",
        "6. ¬øCu√°les son los hiperpar√°metros con mayor importancia para la optimizaci√≥n de su modelo? [0.5 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "0e706dc9a8d946eda7a9eb1f0463c6d7",
        "deepnote_cell_type": "code",
        "id": "xjxAEENAI5wA"
      },
      "outputs": [],
      "source": [
        "# Inserte su c√≥digo ac√°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ac8a20f445d045a3becf1a518d410a7d",
        "deepnote_cell_type": "markdown",
        "id": "EoW32TA9I5wA"
      },
      "source": [
        "## 6. S√≠ntesis de resultados (3 puntos)\n",
        "\n",
        "Finalmente:\n",
        "\n",
        "1. Genere una tabla resumen del MAE en el conjunto de validaci√≥n obtenido en los 5 modelos entrenados desde Baseline hasta XGBoost con Constraints, Optuna y Prunning. [1 punto]\n",
        "2. Compare los resultados de la tabla y responda, ¬øqu√© modelo obtiene el mejor rendimiento? [0.5 puntos]\n",
        "3. Cargue el mejor modelo, prediga sobre el conjunto de **test** y reporte su MAE. [0.5 puntos]\n",
        "4. ¬øExisten diferencias con respecto a las m√©tricas obtenidas en el conjunto de validaci√≥n? ¬øPorqu√© puede ocurrir esto? [1 punto]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jq5C6cDnJg9h"
      },
      "outputs": [],
      "source": [
        "# Inserte su c√≥digo ac√°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5c4654d12037494fbd385b4dc6bd1059",
        "deepnote_cell_type": "markdown",
        "id": "E_19tgBEI5wA"
      },
      "source": [
        "# Conclusi√≥n\n",
        "Exito!\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.pinimg.com/originals/55/3d/42/553d42bea9b10e0662a05aa8726fc7f4.gif\">\n",
        "</p>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "f63d38450a6b464c9bb6385cf11db4d9",
    "deepnote_persisted_session": {
      "createdAt": "2023-11-09T16:18:30.203Z"
    },
    "kernelspec": {
      "display_name": "Python 3.13.5 ('vis_info')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "27f7193e8435d5833318a8779fcc7c01e1e51279cdc9a1fc598f78d31f0d2dc3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
