{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tgm8mCA9Dp3"
      },
      "source": [
        "# Laboratorio 5: Clasificaci√≥n ü§ó\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Primavera 2025</strong></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Kc_ibM9GXH"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Diego Cortez, Gabriel Iturra\n",
        "- Auxiliares: Melanie Pe√±a, Valentina Rojas\n",
        "- Ayudantes: Nicol√°s Cabello, Cristopher Urbina"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9dUSltr9JrN"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Josefa Anselmo.\n",
        "- Nombre de alumno 2: Tamara Carrasco."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC1IloytrsAx"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [TamoJosha](https://github.com/Tamaracarrasco/TamoJosha-Lab-de-Prog-MDS-Prim2025)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBa48PDF9OHw"
      },
      "source": [
        "### Temas a tratar\n",
        "- Clasificaci√≥n en problemas desbalanceados\n",
        "- Lightgbm y xgboost\n",
        "- Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkhnnMx49Qrh"
      },
      "source": [
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: Entregas Martes a las 23:59.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda **fuertemente** asistir.\n",
        "- <u>Prohibidas las copias</u>. Cualquier intento de copia ser√° debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est√©n en u-cursos no ser√°n revisados. Recuerden que el repositorio tambi√©n tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Pueden usar cualquier material del curso que estimen conveniente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxzJ48Vv8quO"
      },
      "source": [
        "\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender c√≥mo trabajar con problemas de clasificaci√≥n con clases desbalanceadas.\n",
        "- Aplicar los modelos lightgbm y xgboost.\n",
        "- Practicar Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-ao0mOU64Ru"
      },
      "source": [
        "# Parte Te√≥rica [12 puntos]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApXKwPDmxcEV"
      },
      "source": [
        "1. Explique cu√°l es la diferencia entre los datos de entrenamiento y validaci√≥n. [1 punto]\n",
        "\n",
        "2. Explique cu√°l es el principal desaf√≠o al trabajar problemas de clasificaci√≥n con data no supervisada. [1 punto]\n",
        "\n",
        "3. Explique en **sus palabras** qu√© es la matriz de confusi√≥n y para qu√© se utiliza. [1 puntos]\n",
        "\n",
        "4. Escriba la f√≥rmula de las siguientes m√©tricas y explique con **sus palabras** c√≥mo se interpretan. [1 punto cada uno]\n",
        "\n",
        "  * Accuracy\n",
        "  * Precision\n",
        "  * Recall\n",
        "  * F1 score\n",
        "\n",
        "5. Explique qu√© m√©trica recomendar√≠a para los siguientes contextos de clasificaci√≥n. [1 punto cada uno]\n",
        "\n",
        "  * Mantenimiento predictivo de fallas de maquinaria pesada en la industria minera.  \n",
        "  * Detecci√≥n de enfermedades altamente contagiosas.\n",
        "  * Aprobaci√≥n de cr√©ditos de alto riesgo.\n",
        "  * Detecci√≥n de cr√≠menes.\n",
        "\n",
        "6. Explique qu√© es la calibraci√≥n de modelos y para qu√© se usa. [1 punto]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy4QMWD8-FPk"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYFdD1aK-ICa"
      },
      "source": [
        "*Escriba su respuesta aqu√≠*\n",
        "\n",
        "# Esta parte la podemos responder despu√©s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg_9jBqtgRDO"
      },
      "source": [
        "# Parte pr√°ctica [48 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slm6yRfdfZwS"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1BnO4tyh3vM2P199Ec9s3JjngQ4qQ9seP\"\n",
        "\" width=\"300\">\n",
        "</p>\n",
        "\n",
        "\n",
        "Tras el tr√°gico despido de la m√≠tica mascota de Maip√∫, Renac√≠n decide adentrarse como consultor en el mercado futbolero, el cu√°l (para variar...) est√° cargado en especulaciones.\n",
        "\n",
        "Como su principal tarea ser√° asesorar a los directivos de los clubes sobre cu√°l jugador comprar y cu√°l no, Renac√≠n desea generar modelos predictivos que evalu√©n distintas caracter√≠sticas de los jugadores; todo con el fin de tomar decisiones concretas basadas en los datos.\n",
        "\n",
        "Sin embargo, su condici√≥n de corporeo le impidi√≥ tomar la versi√≥n anterior de MDS7202, por lo que este motivo Renac√≠n contrata a su equipo para lograr su objetivo final. Dado que a√∫n tiene fuertes v√≠nculos con la direcci√≥n de deportes de la municipalidad, el corporeo le entrega base de datos con las estad√≠sticas de cada jugador para que su equipo empieze a trabajar ya con un dataset listo para ser usado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnbx7RwHfkue"
      },
      "source": [
        "**Los Datos**\n",
        "\n",
        "Para este laboratorio deber√°n trabajar con el csv `statsplayers.csv`, donde deber√°n aplicar algoritmos de aprendizaje supervisado de clasificaci√≥n en base a caracter√≠sticas que describen de jugadores de f√∫tbol.\n",
        "\n",
        "Para comenzar cargue el dataset se√±alado y a continuaci√≥n vea el reporte **`Player_Stats_Report.html`** (adjunto en la carpeta del enunciado) que describe las caracter√≠sticas principales del `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAMk7Ca3alvV",
        "outputId": "c3224233-468e-45a1-84cf-0ec2e845bce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Entorno listo. Ahora ve a: Entorno de ejecuci√≥n ‚Üí Reiniciar entorno de ejecuci√≥n, y luego ejecuta el Bloque 2.\n"
          ]
        }
      ],
      "source": [
        "# 1) Quita versiones que chocan\n",
        "!pip -q uninstall -y scikit-learn imbalanced-learn pandas numpy scipy matplotlib umap-learn xarray plotnine || true\n",
        "\n",
        "# 2) Instala versiones compatibles con PyCaret 3.3.2 (CPU)\n",
        "!pip -q install --no-deps scikit-learn==1.3.2 imbalanced-learn==0.11.0 numpy==1.26.4 pandas==2.1.4 scipy==1.11.4 matplotlib==3.7.5\n",
        "!pip -q install pycaret==3.3.2 lightgbm==4.0.0 xgboost==1.7.6 catboost==1.2.5 umap-learn==0.5.5\n",
        "\n",
        "# 3) Reinicia el runtime (necesario porque sklearn cambia binarios)\n",
        "import IPython\n",
        "IPython.display.clear_output()\n",
        "print(\"‚úÖ Entorno listo. Ahora ve a: Entorno de ejecuci√≥n ‚Üí Reiniciar entorno de ejecuci√≥n, y luego ejecuta el Bloque 2.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "lk87P-MoamVP",
        "outputId": "5c2cfe35-9ed5-446c-e065-61e1c66fcdff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sklearn: 1.4.2 | imblearn: 0.14.0 | numpy: 1.26.4 | pandas: 2.1.4 | matplotlib: 3.7.5\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "('Pycaret only supports python 3.9, 3.10, 3.11. Your actual Python version: ', sys.version_info(major=3, minor=12, micro=11, releaselevel='final', serial=0), 'Please DOWNGRADE your Python version.')",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-337587666.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Import m√≠nimo de PyCaret clasificaci√≥n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpull\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PyCaret OK\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pycaret/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     raise RuntimeError(\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;34m\"Pycaret only supports python 3.9, 3.10, 3.11. Your actual Python version: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: ('Pycaret only supports python 3.9, 3.10, 3.11. Your actual Python version: ', sys.version_info(major=3, minor=12, micro=11, releaselevel='final', serial=0), 'Please DOWNGRADE your Python version.')"
          ]
        }
      ],
      "source": [
        "# Verifica versiones clave\n",
        "import sklearn, imblearn, numpy, pandas, matplotlib\n",
        "print(\"sklearn:\", sklearn.__version__,\n",
        "      \"| imblearn:\", imblearn.__version__,\n",
        "      \"| numpy:\", numpy.__version__,\n",
        "      \"| pandas:\", pandas.__version__,\n",
        "      \"| matplotlib:\", matplotlib.__version__)\n",
        "\n",
        "# Import m√≠nimo de PyCaret clasificaci√≥n\n",
        "from pycaret.classification import setup, compare_models, pull, get_config\n",
        "print(\"PyCaret OK\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX6iwOWUfrp_",
        "outputId": "eb58546c-1bd8-4a94-b64b-ac2a0d5ff594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Ac√° tendr√≠amos que subir los datos a una carpeta en drive y compartirla\n",
        "# si es que en alg√∫n momento utilizaremos colab.\n",
        "\n",
        "# Si usted est√° utilizando Colabolatory le puede ser √∫til este c√≥digo para cargar los archivos.\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    path = '/content/drive/MyDrive/data/stats_players.csv'\n",
        "except:\n",
        "    print('Ignorando conexi√≥n drive-colab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdcucZhp-M_0"
      },
      "source": [
        "## 1. Predicci√≥n de Seleccionados Nacionales [14 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXrewqxjjzvA"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://www.futuro.cl/wp-content/uploads/2016/06/chile-argentina-meme-12.jpg\" width=\"300\">\n",
        "</p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfre1YsSDqla"
      },
      "source": [
        "### 1.1 Preprocesamiento [5 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR00u4HTDtxv"
      },
      "source": [
        "Tareas:\n",
        "\n",
        "1. Genere los labels para la clasificaci√≥n binaria en una variable llamada `label`. Para esto, trabaje sobre el atributo `National_Position` suponiendo que los valores nulos son jugadores no seleccionados para representar a su pa√≠s. [Sin puntaje]\n",
        "\n",
        "2. Hecho esto, ¬øcu√°ntos se tienen ejemplos por cada clase? Comente lo que observa. [1 punto]\n",
        "\n",
        "3. Genere un `ColumnTransformer` en donde especifique las transformaciones que hay que realizar para cada columna (por ejemplo StandarScaler, MinMaxScaler, OneHotEncoder, etc...) para que puedan ser utilizadas correctamente por el modelo predictivo y gu√°rdelo una variable llamada `col_transformer`. [2 puntos]\n",
        "\n",
        "4. Comente y justifique las transformaciones elegidas sobre cada una de las variables (para esto utilice el material `Player_Stats_Report.html` que viene en el zip del lab), al igual que las transformaciones aplicadas. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgAk0kbPjEsx"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhC2sZj9dSI1",
        "outputId": "fbde555f-5ba6-4589-a580-058db90b9b05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones del dataset de los stats (17588, 39)\n",
            "\n",
            " ==== Columnas del dataset de stats ==== \n",
            " ['Name', 'Nationality', 'National_Position', 'Club_Position', 'Height', 'Weight', 'Preffered_Foot', 'Age', 'Work_Rate', 'Weak_foot', 'Skill_Moves', 'Ball_Control', 'Dribbling', 'Marking', 'Sliding_Tackle', 'Standing_Tackle', 'Aggression', 'Reactions', 'Interceptions', 'Vision', 'Composure', 'Crossing', 'Short_Pass', 'Long_Pass', 'Acceleration', 'Speed', 'Stamina', 'Strength', 'Balance', 'Agility', 'Jumping', 'Heading', 'Shot_Power', 'Finishing', 'Long_Shots', 'Curve', 'Freekick_Accuracy', 'Penalties', 'Volleys']\n",
            "\n",
            " ==== Informaci√≥n de los valores de las columnas ==== \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17588 entries, 0 to 17587\n",
            "Data columns (total 39 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   Name               17588 non-null  object\n",
            " 1   Nationality        17588 non-null  object\n",
            " 2   National_Position  1075 non-null   object\n",
            " 3   Club_Position      17587 non-null  object\n",
            " 4   Height             17588 non-null  int64 \n",
            " 5   Weight             17588 non-null  int64 \n",
            " 6   Preffered_Foot     17588 non-null  object\n",
            " 7   Age                17588 non-null  int64 \n",
            " 8   Work_Rate          17588 non-null  object\n",
            " 9   Weak_foot          17588 non-null  int64 \n",
            " 10  Skill_Moves        17588 non-null  int64 \n",
            " 11  Ball_Control       17588 non-null  int64 \n",
            " 12  Dribbling          17588 non-null  int64 \n",
            " 13  Marking            17588 non-null  int64 \n",
            " 14  Sliding_Tackle     17588 non-null  int64 \n",
            " 15  Standing_Tackle    17588 non-null  int64 \n",
            " 16  Aggression         17588 non-null  int64 \n",
            " 17  Reactions          17588 non-null  int64 \n",
            " 18  Interceptions      17588 non-null  int64 \n",
            " 19  Vision             17588 non-null  int64 \n",
            " 20  Composure          17588 non-null  int64 \n",
            " 21  Crossing           17588 non-null  int64 \n",
            " 22  Short_Pass         17588 non-null  int64 \n",
            " 23  Long_Pass          17588 non-null  int64 \n",
            " 24  Acceleration       17588 non-null  int64 \n",
            " 25  Speed              17588 non-null  int64 \n",
            " 26  Stamina            17588 non-null  int64 \n",
            " 27  Strength           17588 non-null  int64 \n",
            " 28  Balance            17588 non-null  int64 \n",
            " 29  Agility            17588 non-null  int64 \n",
            " 30  Jumping            17588 non-null  int64 \n",
            " 31  Heading            17588 non-null  int64 \n",
            " 32  Shot_Power         17588 non-null  int64 \n",
            " 33  Finishing          17588 non-null  int64 \n",
            " 34  Long_Shots         17588 non-null  int64 \n",
            " 35  Curve              17588 non-null  int64 \n",
            " 36  Freekick_Accuracy  17588 non-null  int64 \n",
            " 37  Penalties          17588 non-null  int64 \n",
            " 38  Volleys            17588 non-null  int64 \n",
            "dtypes: int64(33), object(6)\n",
            "memory usage: 5.2+ MB\n"
          ]
        }
      ],
      "source": [
        "# Importaci√≥n de librer√≠as importantes\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder\n",
        "\n",
        "data = pd.read_csv(\"stats_players.csv\", sep=\",\")\n",
        "\n",
        "print(\"Dimensiones del dataset de los stats\", data.shape)\n",
        "\n",
        "print(\"\\n ==== Columnas del dataset de stats ==== \\n\", data.columns.tolist())\n",
        "\n",
        "print(\"\\n ==== Informaci√≥n de los valores de las columnas ==== \\n\")\n",
        "data.info()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "dyVIko1dAYyC",
        "outputId": "5272d2d2-55cb-46eb-ea76-cdb1129a0d84"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b4259173-a80e-4466-87ca-98f6c132a554\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Nationality</th>\n",
              "      <th>National_Position</th>\n",
              "      <th>Club_Position</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Preffered_Foot</th>\n",
              "      <th>Age</th>\n",
              "      <th>Work_Rate</th>\n",
              "      <th>Weak_foot</th>\n",
              "      <th>...</th>\n",
              "      <th>Agility</th>\n",
              "      <th>Jumping</th>\n",
              "      <th>Heading</th>\n",
              "      <th>Shot_Power</th>\n",
              "      <th>Finishing</th>\n",
              "      <th>Long_Shots</th>\n",
              "      <th>Curve</th>\n",
              "      <th>Freekick_Accuracy</th>\n",
              "      <th>Penalties</th>\n",
              "      <th>Volleys</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cristiano Ronaldo</td>\n",
              "      <td>Portugal</td>\n",
              "      <td>LS</td>\n",
              "      <td>LW</td>\n",
              "      <td>185</td>\n",
              "      <td>80</td>\n",
              "      <td>Right</td>\n",
              "      <td>32</td>\n",
              "      <td>High / Low</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>90</td>\n",
              "      <td>95</td>\n",
              "      <td>85</td>\n",
              "      <td>92</td>\n",
              "      <td>93</td>\n",
              "      <td>90</td>\n",
              "      <td>81</td>\n",
              "      <td>76</td>\n",
              "      <td>85</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lionel Messi</td>\n",
              "      <td>Argentina</td>\n",
              "      <td>RW</td>\n",
              "      <td>RW</td>\n",
              "      <td>170</td>\n",
              "      <td>72</td>\n",
              "      <td>Left</td>\n",
              "      <td>29</td>\n",
              "      <td>Medium / Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>90</td>\n",
              "      <td>68</td>\n",
              "      <td>71</td>\n",
              "      <td>85</td>\n",
              "      <td>95</td>\n",
              "      <td>88</td>\n",
              "      <td>89</td>\n",
              "      <td>90</td>\n",
              "      <td>74</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Neymar</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>LW</td>\n",
              "      <td>LW</td>\n",
              "      <td>174</td>\n",
              "      <td>68</td>\n",
              "      <td>Right</td>\n",
              "      <td>25</td>\n",
              "      <td>High / Medium</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>96</td>\n",
              "      <td>61</td>\n",
              "      <td>62</td>\n",
              "      <td>78</td>\n",
              "      <td>89</td>\n",
              "      <td>77</td>\n",
              "      <td>79</td>\n",
              "      <td>84</td>\n",
              "      <td>81</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Luis Su√°rez</td>\n",
              "      <td>Uruguay</td>\n",
              "      <td>LS</td>\n",
              "      <td>ST</td>\n",
              "      <td>182</td>\n",
              "      <td>85</td>\n",
              "      <td>Right</td>\n",
              "      <td>30</td>\n",
              "      <td>High / Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>86</td>\n",
              "      <td>69</td>\n",
              "      <td>77</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>86</td>\n",
              "      <td>86</td>\n",
              "      <td>84</td>\n",
              "      <td>85</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Manuel Neuer</td>\n",
              "      <td>Germany</td>\n",
              "      <td>GK</td>\n",
              "      <td>GK</td>\n",
              "      <td>193</td>\n",
              "      <td>92</td>\n",
              "      <td>Right</td>\n",
              "      <td>31</td>\n",
              "      <td>Medium / Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>52</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "      <td>47</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 39 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4259173-a80e-4466-87ca-98f6c132a554')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b4259173-a80e-4466-87ca-98f6c132a554 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b4259173-a80e-4466-87ca-98f6c132a554');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f21fd9e5-3ffa-4abb-8767-df93cac6ffa3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f21fd9e5-3ffa-4abb-8767-df93cac6ffa3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f21fd9e5-3ffa-4abb-8767-df93cac6ffa3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                Name Nationality National_Position Club_Position  Height  \\\n",
              "0  Cristiano Ronaldo    Portugal                LS            LW     185   \n",
              "1       Lionel Messi   Argentina                RW            RW     170   \n",
              "2             Neymar      Brazil                LW            LW     174   \n",
              "3        Luis Su√°rez     Uruguay                LS            ST     182   \n",
              "4       Manuel Neuer     Germany                GK            GK     193   \n",
              "\n",
              "   Weight Preffered_Foot  Age        Work_Rate  Weak_foot  ...  Agility  \\\n",
              "0      80          Right   32       High / Low          4  ...       90   \n",
              "1      72           Left   29  Medium / Medium          4  ...       90   \n",
              "2      68          Right   25    High / Medium          5  ...       96   \n",
              "3      85          Right   30    High / Medium          4  ...       86   \n",
              "4      92          Right   31  Medium / Medium          4  ...       52   \n",
              "\n",
              "   Jumping  Heading  Shot_Power  Finishing  Long_Shots  Curve  \\\n",
              "0       95       85          92         93          90     81   \n",
              "1       68       71          85         95          88     89   \n",
              "2       61       62          78         89          77     79   \n",
              "3       69       77          87         94          86     86   \n",
              "4       78       25          25         13          16     14   \n",
              "\n",
              "   Freekick_Accuracy  Penalties  Volleys  \n",
              "0                 76         85       88  \n",
              "1                 90         74       85  \n",
              "2                 84         81       83  \n",
              "3                 84         85       88  \n",
              "4                 11         47       11  \n",
              "\n",
              "[5 rows x 39 columns]"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzyGnGXoAYyC",
        "outputId": "095989f2-80a5-425e-c7b7-cb2d818494d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conteo de valores de National_Position \n",
            " National_Position\n",
            "NaN    16513\n",
            "Sub      556\n",
            "LCB       48\n",
            "GK        47\n",
            "RCB       46\n",
            "LB        39\n",
            "RB        38\n",
            "RM        34\n",
            "LM        32\n",
            "ST        30\n",
            "LCM       25\n",
            "RCM       25\n",
            "LDM       19\n",
            "CAM       19\n",
            "LS        18\n",
            "RS        18\n",
            "RDM       18\n",
            "CB         9\n",
            "CM         9\n",
            "CDM        9\n",
            "RW         7\n",
            "LW         7\n",
            "LWB        4\n",
            "LAM        4\n",
            "RWB        4\n",
            "RAM        4\n",
            "LF         3\n",
            "RF         3\n",
            "Name: count, dtype: int64\n",
            "\n",
            " Cantidad de valores √∫nicos de National_Position:  27\n"
          ]
        }
      ],
      "source": [
        "## La columna de National_Position presenta muchos valores nulos.\n",
        "print(\"Conteo de valores de National_Position \\n\", data[\"National_Position\"].value_counts(dropna=False))\n",
        "\n",
        "print(\"\\n Cantidad de valores √∫nicos de National_Position: \", data[\"National_Position\"].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "DKDUBd1gAYyC",
        "outputId": "0a11cc42-1da4-47f6-b5a3-4fc29ce04aca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>16513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>1075</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label\n",
              "0.0    16513\n",
              "1.0     1075\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#### ITEM 1 ####\n",
        "\n",
        "# Ac√°, se crea una nueva columna ``label``\n",
        "# donde toma valor 1 si el jugador es seleccionado de su pa√≠s\n",
        "# 0 si no lo es, bas√°ndonos en la columna National_position.\n",
        "\n",
        "# 1) Una opci√≥n: rellenar con 0's los espacios que hayan con Nan\n",
        "\n",
        "data[\"National_Position\"] = data[\"National_Position\"].fillna(\"Vac√≠o\")\n",
        "\n",
        "# 2) Ac√° se accede a los datos de la columna National_position\n",
        "# y se crea la nueva columna label con los valores pedidos.\n",
        "\n",
        "data.loc[data[\"National_Position\"] == \"Vac√≠o\", \"label\"] = 0\n",
        "data.loc[data[\"National_Position\"] != \"Vac√≠o\", \"label\"] = 1\n",
        "\n",
        "data[\"label\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAo8ii6sAYyD"
      },
      "source": [
        "**Pregunta 2:** Hecho esto, ¬øcu√°ntos se tienen ejemplos por cada clase? Comente lo que observa.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Luego de crear la variable \"label\", se observa que la clase 0 (jugadores no seleccionados) cuenta con 16.513 ejemplos (‚âà94 %), mientras que la clase 1 (jugadores seleccionados) tiene 1.075 ejemplos (‚âà6 %). Esto evidencia un desbalance de clases marcado, donde la clase positiva es claramente minoritaria. Este desbalance podr√≠a influir en el entrenamiento de futuros modelos, ya que un clasificador ingenuo que prediga siempre la clase mayoritaria obtendr√≠a alta exactitud, pero sin capacidad real de identificar jugadores seleccionados.\n",
        "\n",
        "**Pregunta 3:** Genere un `ColumnTransformer` en donde especifique las transformaciones que hay que realizar para cada columna (por ejemplo StandarScaler, MinMaxScaler, OneHotEncoder, etc...) para que puedan ser utilizadas correctamente por el modelo predictivo y gu√°rdelo una variable llamada `col_transformer`.\n",
        "\n",
        "1. **Variables categ√≥ricas**:  ``Name``, ``Nationality``,  ``National_Position``, ``Club_Position``, ``Preffered_Foot`` y ``Work_Rate``.\n",
        "\n",
        "2. **Variables categ√≥ricas discretas**: \"Weak_foot\", \"Skill_Moves\". Presentan valores discretos num√©ricos.\n",
        "\n",
        "El resto de columnas son num√©ricas (n√∫meros no discretos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEd-aReJAYyD",
        "outputId": "f4a52cd3-5e1e-4f90-b678-6a3a9816b383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Name =====\n",
            "count      17588\n",
            "unique     17341\n",
            "top       Felipe\n",
            "freq           6\n",
            "Name: Name, dtype: object\n",
            "\n",
            "\n",
            "===== Nationality =====\n",
            "count       17588\n",
            "unique        160\n",
            "top       England\n",
            "freq         1618\n",
            "Name: Nationality, dtype: object\n",
            "\n",
            "\n",
            "===== National_Position =====\n",
            "count     17588\n",
            "unique       28\n",
            "top       Vac√≠o\n",
            "freq      16513\n",
            "Name: National_Position, dtype: object\n",
            "\n",
            "\n",
            "===== Club_Position =====\n",
            "count     17587\n",
            "unique       29\n",
            "top         Sub\n",
            "freq       7492\n",
            "Name: Club_Position, dtype: object\n",
            "\n",
            "\n",
            "===== Preffered_Foot =====\n",
            "count     17588\n",
            "unique        2\n",
            "top       Right\n",
            "freq      13494\n",
            "Name: Preffered_Foot, dtype: object\n",
            "\n",
            "\n",
            "===== Work_Rate =====\n",
            "count               17588\n",
            "unique                  9\n",
            "top       Medium / Medium\n",
            "freq                 9897\n",
            "Name: Work_Rate, dtype: object\n",
            "\n",
            "\n",
            "Work_Rate\n",
            "Medium / Medium    9897\n",
            "High / Medium      2918\n",
            "Medium / High      1534\n",
            "Medium / Low        845\n",
            "High / High         747\n",
            "High / Low          730\n",
            "Low / Medium        449\n",
            "Low / High          438\n",
            "Low / Low            30\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "## Columnas categ√≥ricas\n",
        "## ¬øOrdinales o nominales?\n",
        "\n",
        "cat_cols = [ \"Name\", \"Nationality\",  \"National_Position\", \"Club_Position\", \"Preffered_Foot\" , \"Work_Rate\"]\n",
        "\n",
        "for col in cat_cols:\n",
        "    print(f\"===== {col} =====\")\n",
        "    print(data[col].describe())\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Al parecer \"Work_Rate\" es categ√≥rica ordinal?\n",
        "\n",
        "print(data[\"Work_Rate\"].value_counts())\n",
        "\n",
        "# Aunque bien podr√≠a ser nominal\n",
        "\n",
        "# Luego, no hay que usar OrdinalEncoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "014unqOnAYyD"
      },
      "source": [
        "Observando las distribuciones disponibles en el html adjunto, Se tiene lo siguiente sobre las variables y sus posibles transformaciones.\n",
        "\n",
        "1. Variables que necesiten un escalamiento: Todas las num√©ricas porque presentan diferentes escalas.\n",
        "\n",
        "2. Todas las variables categ√≥ricas son nominales: En particular, se deber√≠an codificar las columnas de \"National_Position\", \"Club_Position\", \"Preffered_Foot\" y \"Work_Rate\" con OneHotEncoder. No tiene sentido codificar las columnas de los nombres y de los pa√≠ses.\n",
        "\n",
        "3. Hay variables categ√≥ricas (\"Weak_foot\" y \"Skill_Moves\") que ya est√°n codificadas (son variables categ√≥ricas ordinales)\n",
        "\n",
        "4. Sobre las columnas de \"Name\" y \"Nacionality\": no deber√≠an considerarse la de los nombres. ya que funcionan como una especie de ID. Para la de nacionalidad, se podrian agrupar los pa√≠ses por continente y de ah√≠ codifificar. Pero esto ser√≠a muy extra.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIl-bO1mAYyD"
      },
      "outputs": [],
      "source": [
        "# Listar columnas\n",
        "drop_cols = [\n",
        "    \"Name\",\n",
        "    \"National_Position\"\n",
        "]\n",
        "\n",
        "# 2. OHE (cardinalidad moderada)\n",
        "ohe_nationality = [\"Nationality\"]\n",
        "\n",
        "# 4. Club_Position: OHE + imputaci√≥n (1 missing) -> NO se dropean filas\n",
        "ohe_clubpos = [\"Club_Position\"]\n",
        "\n",
        "# 7. Preferred_Foot: Dejamos expl√≠citamente el orden ['Left','Right'] y drop='if_binary'\n",
        "#    => la √∫nica columna resultante ser√° el indicador de 'Right' (1 = Right).\n",
        "ohe_binary_foot = [\"Preffered_Foot\"]\n",
        "\n",
        "# 9. Work_Rate: OHE\n",
        "ohe_workrate = [\"Work_Rate\"]\n",
        "\n",
        "# 10‚Äì11. Ordinal (1..5)\n",
        "\n",
        "ord_1to5 = [\"Weak_foot\", \"Skill_Moves\"]\n",
        "cats_1to5 = [[1, 2, 3, 4, 5]] * len(ord_1to5)\n",
        "\n",
        "# 5‚Äì6, 8, 12‚Äì39. Num√©ricas (StandardScaler)\n",
        "num_std = [\n",
        "    \"Height\", \"Weight\", \"Age\",\n",
        "    \"Ball_Control\", \"Dribbling\", \"Marking\", \"Sliding_Tackle\", \"Standing_Tackle\",\n",
        "    \"Aggression\", \"Reactions\", \"Interceptions\", \"Vision\",\n",
        "    \"Composure\", \"Crossing\", \"Short_Pass\", \"Long_Pass\",\n",
        "    \"Acceleration\", \"Speed\", \"Stamina\", \"Strength\", \"Balance\", \"Agility\",\n",
        "    \"Jumping\", \"Heading\",\n",
        "    \"Shot_Power\", \"Finishing\", \"Long_Shots\", \"Curve\",\n",
        "    \"Freekick_Accuracy\", \"Penalties\", \"Volleys\"\n",
        "]\n",
        "\n",
        "# PIPELINES POR GRUPO\n",
        "num_std_pipe = Pipeline([\n",
        "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"sc\",  StandardScaler())\n",
        "])\n",
        "\n",
        "cat_ohe_pipe = Pipeline([\n",
        "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
        "])\n",
        "\n",
        "# Mapeo binario fijo: columna √∫nica = indicador de 'Right'\n",
        "binary_foot_pipe = Pipeline([\n",
        "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"ohe\", OneHotEncoder(\n",
        "        categories=[[\"Left\",\"Right\"]],\n",
        "        drop=\"if_binary\",\n",
        "        handle_unknown=\"ignore\",\n",
        "        sparse_output=True\n",
        "    ))\n",
        "])\n",
        "\n",
        "ordinal_1to5_pipe = Pipeline([\n",
        "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"ord\", OrdinalEncoder(\n",
        "        categories=cats_1to5,\n",
        "        handle_unknown=\"use_encoded_value\",  # por si aparece algo fuera de 1..5\n",
        "        unknown_value=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "# COLUMNTRANSFORMER FINAL\n",
        "col_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"drop_ids\",     \"drop\",           drop_cols),\n",
        "        (\"num_std\",      num_std_pipe,     num_std),\n",
        "        (\"ohe_nat\",      cat_ohe_pipe,     ohe_nationality),\n",
        "        (\"ohe_clubpos\",  cat_ohe_pipe,     ohe_clubpos),\n",
        "        (\"ohe_workrate\", cat_ohe_pipe,     ohe_workrate),\n",
        "        (\"ohe_foot\",     binary_foot_pipe, ohe_binary_foot),\n",
        "        (\"ord_1to5\",     ordinal_1to5_pipe, ord_1to5),\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "\n",
        "# col_transformer.set_output(transform='pandas')\n",
        "\n",
        "# df2 = col_transformer.fit_transform(data) # ac√° se est√° obteniendo un dataframe con 17588 filas y 100 columnas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BzNNnKnAYyD"
      },
      "outputs": [],
      "source": [
        "### Ojo, no apliqu√© ninguna transformacion sobre los paises y los nombres.\n",
        "### la columna de los nombres deber√≠a quitarse\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqdawBEyYXmA"
      },
      "source": [
        "**Pregunta 4:** Comente y justifique las transformaciones elegidas sobre cada una de las variables (para esto utilice el material `Player_Stats_Report.html` que viene en el zip del lab), al igual que las transformaciones aplicadas.\n",
        "\n",
        "\n",
        "En primer lugar, se descartaron aquellas variables que no aportan informaci√≥n √∫til para el modelado o que pueden inducir overfitting o data leakage.\n",
        "\n",
        "Name se elimin√≥ porque es un identificador √∫nico sin valor predictivo y que podr√≠a inducir al modelo a memorizar.\n",
        "\n",
        "National_Position tambi√©n fue descartada, ya que a partir de esta se gener√≥ directamente la variable objetivo (label), por lo cual mantenerla representar√≠a una fuga de informaci√≥n. Adem√°s ten√≠a m√°s de un 90% de missing values.\n",
        "\n",
        "En el caso de variables categ√≥ricas con alta cardinalidad, como Nationality, se aplic√≥ OneHotEncoder con handle_unknown=\"ignore\". Esta elecci√≥n permite representar cada pa√≠s como una variable binaria, evitando asignar un orden artificial inexistente y controlando el problema de pa√≠ses poco frecuentes que podr√≠an aparecer en datos futuros.\n",
        "\n",
        "Para Club_Position, categ√≥rica con baja cardinalidad, tambi√©n se aplic√≥ OneHotEncoder. El √∫nico valor faltante fue imputado con la moda, evitando descartar el registro completo. Esto se justifica dado que la p√©rdida de un jugador reducir√≠a innecesariamente la base de entrenamiento.\n",
        "\n",
        "En Preferred_Foot, categ√≥rica binaria (‚ÄúLeft‚Äù/‚ÄúRight‚Äù), se utiliz√≥ OneHotEncoder con categor√≠as definidas expl√≠citamente. Esto asegura que la codificaci√≥n refleje correctamente la l√≥gica de la variable, resultando en un √∫nico indicador binario donde el valor 1 representa ‚ÄúRight‚Äù.\n",
        "\n",
        "La variable Work_Rate, de naturaleza categ√≥rica ordinal compuesta (p.ej., ‚ÄúHigh/Low‚Äù), se transform√≥ mediante OneHotEncoder. Aunque posee una componente ordinal impl√≠cita (High > Medium > Low), el hecho de que combine ataque y defensa hace m√°s coherente tratarla como categor√≠as independientes sin imponer un orden lineal.\n",
        "\n",
        "Las variables ordinales de 1 a 5, como Weak_Foot y Skill_Moves, fueron codificadas con OrdinalEncoder. En estos casos, el orden s√≠ es fundamental pues un jugador con 5 estrellas domina mejor que uno con 2, y esa informaci√≥n ordinal debe preservarse en la codificaci√≥n.\n",
        "\n",
        "En cuanto a las variables num√©ricas de atributos t√©cnicos, f√≠sicos y psicol√≥gicos, tales como Height, Weight, Age, Ball_Control, Dribbling, Aggression, Reactions, Acceleration, Strength, Finishing, Stamina, Vision, entre otras (todas reportadas en el informe), se aplic√≥ StandardScaler. La justificaci√≥n radica en que se encuentran todas en una escala similar (0‚Äì100 en la mayor√≠a de los casos, presentan distribuciones aproximadamente normales, con asimetr√≠as leves y sin outliers extremos seg√∫n los histogramas y estad√≠sticas de dispersi√≥n y modelos sensibles a la escala de los predictores, como m√°quinas de soporte vectorial o regresi√≥n log√≠stica regularizada, se benefician de que estas variables tengan media 0 y desviaci√≥n est√°ndar 1.\n",
        "\n",
        "Finalmente, el uso de SimpleImputer con mediana o moda en el pipeline asegura robustez frente a valores faltantes, los cuales, aunque escasos, no deben inducir p√©rdidas de observaciones en el entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv1HOfcNEPF4"
      },
      "source": [
        "### 1.2 Entrenamiento [3 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPkuXTUBvB0"
      },
      "source": [
        "Ahora, vamos a entrenar los pipelines generados en los pasos anteriores. Para esto, debe realizar las siguientes tareas:\n",
        "\n",
        "1. Separe los datos de entrenamiento en un conjunto de entrenamiento y de prueba  (la proporci√≥n queda a su juicio). En este paso, seleccione los ejemplos de forma aleatoria e intente mantener la distribuci√≥n original de labels de cada clase en los conjuntos de prueba/entrenamiento. (vea la documentaci√≥n de `train_test_split`). [1 puntos]\n",
        "\n",
        "\n",
        "2. Defina un pipeline llamado `pipeline_xgboost` y otro llamado `pipeline_lightgbm`. Estos pipelines deben tener el mismo ColumnTransformer definido en la secci√≥n de preprocesamiento, pero deben variar los clasificadores de acuerdo al nombre de cada pipeline. [1 puntos]\n",
        "\n",
        "3. Entrene los pipelines. [1 punto]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zmJBcHaAYyE",
        "outputId": "cc54e9d8-81c9-4c16-b08e-de2d9efac62f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install lightgbm\n",
        "%pip install xgboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbadONFtjGnE"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G720DKxdAYyE"
      },
      "source": [
        "<https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLtlXGTPdWAV",
        "outputId": "a8d2c229-e5f5-45e6-fa83-f66443015c4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 752, number of negative: 11559\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 2531\n",
            "[LightGBM] [Info] Number of data points in the train set: 12311, number of used features: 78\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 35 dense feature groups (0.42 MB) transferred to GPU in 0.004236 secs. 1 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061084 -> initscore=-2.732483\n",
            "[LightGBM] [Info] Start training from score -2.732483\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Separaci√≥n de los conjuntos de entrenamiento y de testing.\n",
        "# La proporci√≥n a utilizar ser√° 70% y 30%\n",
        "\n",
        "# df2[\"label\"] = data[\"label\"] # se agrega variable target al dataframe\n",
        "\n",
        "## ITEM 1:  separamos la variable target del dataframe\n",
        "\n",
        "df2_x = data.drop(columns=\"label\").copy()\n",
        "df2_y = data[\"label\"]\n",
        "\n",
        "# importaci√≥n de las librer√≠as para este item\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "pipeline_xgboost = Pipeline(\n",
        "    steps=[\n",
        "        (\"col_transformer\", col_transformer),\n",
        "        (\"classifier\", XGBClassifier(n_estimators=100, random_state=42,\n",
        "                                     learning_rate=0.01, objective=\"binary:logistic\",\n",
        "                                     device=\"cuda\", tree_method=\"gpu_hist\", verbosity=0))# por ahora pongo ese n√∫mero de iteraciones para que no explote\n",
        "    ]                                                                                             # ac√° se podr√≠an colocar otros hiperpar√°metros como la tasa de aprendizaje, n_estimatos\n",
        ")                                                                                        # objective=\"binary:logistic\" porque la clasificaci√≥n es binaria\n",
        "                                                                                        # device=\"cuda\" y tree_method=\"gpu_hist\" son par√°metros que google dec√≠a que deb√≠a poner al trabajar ac√° en colab\n",
        "                                                                                        # verbosity=0 para que no salgan mensajes del entrenamiento.\n",
        "\n",
        "\n",
        "\n",
        "pipeline_lightgbm = Pipeline(\n",
        "    steps=[\n",
        "        (\"col_transformer\", col_transformer),\n",
        "        (\"classifier\", LGBMClassifier(random_state=42, boosting_type=\"gbdt\",\n",
        "                                      learning_rate=0.01, n_estimators=100, objective=\"binary\", device=\"gpu\"))\n",
        "                                                                          # gbdt: gradient boosting tradicional\n",
        "    ]                                                                           # otros hiperpar√°metros: objective=\"binary\" porque es clasificaci√≥n binaria\n",
        ")\n",
        "\n",
        "##########\n",
        "\n",
        "## entrenamiento de xgb\n",
        "\n",
        "pipeline_xgboost.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "## entrenamiento de lgbm\n",
        "pipeline_lightgbm.fit(X_train, y_train)\n",
        "\n",
        "## predicciones\n",
        "\n",
        "y_pred_xgb = pipeline_xgboost.predict(X_test)\n",
        "y_pred_lgbm = pipeline_lightgbm.predict(X_test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXKAhldCAYyF",
        "outputId": "7b067736-a2e0-438d-b131-0075772cdfb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/data/lightgbm_model.pkl']"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Guardar pipleines ya entrenados\n",
        "\n",
        "import os, joblib\n",
        "os.makedirs(\"/content/drive/MyDrive/data\", exist_ok=True)\n",
        "\n",
        "joblib.dump(pipeline_xgboost,  \"/content/drive/MyDrive/data/xgboost_model.pkl\")\n",
        "joblib.dump(pipeline_lightgbm, \"/content/drive/MyDrive/data/lightgbm_model.pkl\")\n",
        "\n",
        "# Guardar predicciones\n",
        "\n",
        "pred_df = pd.DataFrame({\n",
        "    \"y_true\": y_test,\n",
        "    \"y_pred_xgb\": y_pred_xgb,\n",
        "    \"y_pred_lgbm\": y_pred_lgbm\n",
        "})\n",
        "pred_df.to_csv(\"/content/drive/MyDrive/data/predicciones_modelos.csv\", index=False)\n",
        "\n",
        "# Guardar probabilidades para AUC/PR:\n",
        "\n",
        "y_proba_xgb  = pipeline_xgboost.predict_proba(X_test)[:, 1]\n",
        "y_proba_lgbm = pipeline_lightgbm.predict_proba(X_test)[:, 1]\n",
        "pd.DataFrame({\n",
        "    \"y_true\": y_test,\n",
        "    \"proba_xgb\": y_proba_xgb,\n",
        "    \"proba_lgbm\": y_proba_lgbm\n",
        "}).to_csv(\"/content/drive/MyDrive/data/probas_modelos.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5Qt8cCWhVJJ"
      },
      "outputs": [],
      "source": [
        "# Guardo modelos con pickle\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Redirecciono a drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/data\", exist_ok=True)\n",
        "\n",
        "# Guardo predicciones xgb\n",
        "pd.DataFrame({\"predicciones\": y_pred_xgb}).to_csv(\n",
        "    \"/content/drive/MyDrive/data/predicciones_xgb.csv\", index=False\n",
        ")\n",
        "\n",
        "# Guardo modelo con pickle\n",
        "with open(\"/content/drive/MyDrive/data/xgboost_model.sav\", \"wb\") as f:\n",
        "    pickle.dump(pipeline_xgboost, f)\n",
        "\n",
        "# Cargo el modelo desde drive\n",
        "with open(\"/content/drive/MyDrive/data/xgboost_model.sav\", \"rb\") as f:\n",
        "    modelo_loaded = pickle.load(f)\n",
        "\n",
        "# Predicciones con modelo cargado\n",
        "y_pred_modelo_loaded = modelo_loaded.predict(X_test)\n",
        "\n",
        "\n",
        "pred_df.to_csv(\"/content/drive/MyDrive/data/predicciones_modelos.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV9HSdM9Y1qN"
      },
      "outputs": [],
      "source": [
        "# Guardo predicciones lgbm\n",
        "pd.DataFrame({\"predicciones\": y_pred_lgbm}).to_csv(\n",
        "    \"/content/drive/MyDrive/data/predicciones_lgbm.csv\", index=False\n",
        ")\n",
        "\n",
        "# Guardo modelo con pickle\n",
        "with open(\"/content/drive/MyDrive/data/lightgbm_model.sav\", \"wb\") as f:\n",
        "    pickle.dump(pipeline_lightgbm, f)\n",
        "\n",
        "# Cargo el modelo desde drive\n",
        "with open(\"/content/drive/MyDrive/data/lightgbm_model.sav\", \"rb\") as f:\n",
        "    modelo_lgbm_loaded = pickle.load(f)\n",
        "\n",
        "# Predicciones con modelo cargado\n",
        "y_pred_lgbm_loaded = modelo_lgbm_loaded.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poc9HSNBFeKO"
      },
      "source": [
        "### 1.3 Resultados [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGGCj8YtFil1"
      },
      "source": [
        "1. Calcule las m√©tricas accuracy, precisi√≥n y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) para evaluar el rendimiento de los distintos modelos. Verifique sus resultados usando `classification_report`. [2 puntos]\n",
        "\n",
        "2. Explique qu√© implican los valores de accuracy, precisi√≥n y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) y c√≥mo influye la cantidad de ejemplos por clase en los resultados obtenidos. [2 puntos]\n",
        "\n",
        "3. Explique qu√© m√©trica le parece m√°s adecuada y concluya qu√© modelo tiene un mejor desempe√±o. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1hkVFdujJTi"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNmI_tbbdQte",
        "outputId": "d98c6699-0293-4970-89be-76c62fec2363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======== Reporte M√©tricas XGBoost ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      4954\n",
            "         1.0       1.00      1.00      1.00       323\n",
            "\n",
            "    accuracy                           1.00      5277\n",
            "   macro avg       1.00      1.00      1.00      5277\n",
            "weighted avg       1.00      1.00      1.00      5277\n",
            "\n",
            "\n",
            "\n",
            "======== Reporte M√©tricas LGBM ========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      4954\n",
            "         1.0       1.00      1.00      1.00       323\n",
            "\n",
            "    accuracy                           1.00      5277\n",
            "   macro avg       1.00      1.00      1.00      5277\n",
            "weighted avg       1.00      1.00      1.00      5277\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# importaci√≥n del reporte de clasificacion\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "print(\"======== Reporte M√©tricas XGBoost ========\")\n",
        "print(classification_report(y_test, y_pred_xgb))\n",
        "print(\"\\n\")\n",
        "print(\"======== Reporte M√©tricas LGBM ========\")\n",
        "print(classification_report(y_test, y_pred_xgb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy5VMU6ae_g6"
      },
      "source": [
        "## 2. Predicci√≥n de posiciones de jugadores [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0PGg_hLgr4H"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://pbs.twimg.com/media/E1rfA1aWEAYU6Ny.jpg\" width=\"300\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6rSnAesfOm3"
      },
      "source": [
        "En una nueva jornada de desmesuradas transacciones deportivas, Renac√≠n escuch√≥ a sus colegas discutir acerca de que el precio de cada jugador depende en gran medida de la posici√≥n en la cancha en la que juega. Y adem√°s, que hay bastantes jugadores nuevos que no tienen muy claro en que posici√≥n verdaderamente brillar√≠an, por lo que actualmente puede que actualmente est√©n jugando en posiciones sub-optimas.\n",
        "\n",
        "Viendo que los resultados del primer an√°lisis no son tan esperanzadores, el corporeo los comanda a cambiar su tarea: ahora, les solicita que construyan un clasificador enfocado en predecir la mejor posici√≥n de los jugadores en la cancha seg√∫n sus caracter√≠sticas.\n",
        "\n",
        "Para lograr esto, primero, les pide que etiqueten de la siguiente manera los valores que aparecen en el atributo `Club_Position`, pidiendo que agrupen los valores en los siguientes grupos:\n",
        "\n",
        "**Nota**:  Renac√≠n les recalca que **no deben utilizar los valores ```Sub``` y ```Res``` de esta columna**.\n",
        "\n",
        "```python\n",
        "ataque = ['ST', 'CF']\n",
        "central_ataque = ['RW', 'CAM', 'LW']\n",
        "central = ['RM', 'CM', 'LM']\n",
        "central_defensa = ['RWB', 'CDM', 'LWB']\n",
        "defensa = ['RB', 'CB', 'LB']\n",
        "arquero = ['GK']\n",
        "```\n",
        "\n",
        "La elecci√≥n del clasificador se justificar en base a la siguiente [gu√≠a](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) y se deben comentar los resultados obtenidos en la clasificaci√≥n.\n",
        "\n",
        "**Tareas:** [1 punto por tarea]\n",
        "\n",
        "1. En un nuevo dataframe, aplique las etiquetas descritas anteriormente en cada uno de los valores se√±alados en esta secci√≥n y gu√°rdelos en la variable `label`.\n",
        "2. Cuente cu√°ntos por clase quedan.\n",
        "3. Entrene el nuevo pipeline y ejecute una evaluaci√≥n de este.  \n",
        "4. Comente los resultados obtenidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBmSaWh8i2MI"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "Ir_7zMh2i1vg",
        "outputId": "2fd6893f-38d0-4fca-80e1-366325df4fbe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>defensa</th>\n",
              "      <td>1180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>central</th>\n",
              "      <td>907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>arquero</th>\n",
              "      <td>632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>central_ataque</th>\n",
              "      <td>581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ataque</th>\n",
              "      <td>430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>central_defensa</th>\n",
              "      <td>209</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label\n",
              "defensa            1180\n",
              "central             907\n",
              "arquero             632\n",
              "central_ataque      581\n",
              "ataque              430\n",
              "central_defensa     209\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Copio el data frame\n",
        "data_copy = data.drop(columns=[c for c in data.columns if c.lower() == \"label\"], errors=\"ignore\").copy()\n",
        "\n",
        "# Excluyo Sub/Res\n",
        "data_copy = data_copy[~data_copy[\"Club_Position\"].isin([\"Sub\", \"Res\"])]\n",
        "\n",
        "# Mapeo Club_Position\n",
        "codigo_categorias = {\n",
        "    \"ST\": \"ataque\", \"CF\": \"ataque\",\n",
        "    \"RW\": \"central_ataque\", \"CAM\": \"central_ataque\", \"LW\": \"central_ataque\",\n",
        "    \"RM\": \"central\", \"CM\": \"central\", \"LM\": \"central\",\n",
        "    \"RWB\": \"central_defensa\", \"CDM\": \"central_defensa\", \"LWB\": \"central_defensa\",\n",
        "    \"RB\": \"defensa\", \"CB\": \"defensa\", \"LB\": \"defensa\",\n",
        "    \"GK\": \"arquero\"\n",
        "}\n",
        "data_copy[\"label\"] = data_copy[\"Club_Position\"].map(codigo_categorias)\n",
        "\n",
        "# Mantengo solo filas con label v√°lido\n",
        "data_copy = data_copy.dropna(subset=[\"label\"]).reset_index(drop=True)\n",
        "\n",
        "# Reviso\n",
        "data_copy[[\"Club_Position\", \"label\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yodfkwrZApn"
      },
      "outputs": [],
      "source": [
        "# pregunta 2\n",
        "# Conteo\n",
        "conteos = data_copy[\"label\"].value_counts()\n",
        "porcentajes = data_copy[\"label\"].value_counts(normalize=True).mul(100).round(2)\n",
        "\n",
        "print(\"Conteo por clase:\\n\", conteos, \"\\n\")\n",
        "print(\"Porcentajes (%):\\n\", porcentajes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqFj3u6PZFrw"
      },
      "outputs": [],
      "source": [
        "# pregunta 3:\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Features y target\n",
        "X = data_copy.drop(columns=[\"Club_Position\", \"label\"]).copy()\n",
        "y = data_copy[\"label\"].copy()\n",
        "\n",
        "# Columnas\n",
        "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = [\"National_Position\", \"Preffered_Foot\", \"Work_Rate\"]\n",
        "\n",
        "# Pipelines\n",
        "num_transformation = Pipeline([\n",
        "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"sc\", StandardScaler())\n",
        "])\n",
        "\n",
        "categoric_transformation = Pipeline([\n",
        "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "])\n",
        "\n",
        "col_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", num_transformation, num_cols),\n",
        "        (\"cat\", categoric_transformation, cat_cols),\n",
        "    ],\n",
        "    verbose_feature_names_out=False\n",
        ")\n",
        "\n",
        "# Split estratificado\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, train_size=0.7, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Clasificador lineal\n",
        "pipeline_svc = Pipeline([\n",
        "    (\"col_transformer\", col_transformer),\n",
        "    (\"classifier\", LinearSVC(random_state=42, max_iter=3000))\n",
        "])\n",
        "\n",
        "pipeline_svc.fit(X_train, y_train)\n",
        "y_pred = pipeline_svc.predict(X_test)\n",
        "\n",
        "print(\"Classification report\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=sorted(y.unique()))\n",
        "cm_df = pd.DataFrame(cm, index=[f\"true_{c}\" for c in sorted(y.unique())],\n",
        "                        columns=[f\"pred_{c}\" for c in sorted(y.unique())])\n",
        "print(\"Matriz de confusi√≥n\")\n",
        "print(cm_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3FrNSH1ZKQf"
      },
      "outputs": [],
      "source": [
        "# pregunta 4\n",
        "# Guardar modelo\n",
        "\n",
        "SAVE_DIR = \"/content/drive/MyDrive/data\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Guardar modelo\n",
        "joblib.dump(pipeline_svc, f\"{SAVE_DIR}/linear_svc_positions.pkl\")\n",
        "\n",
        "# Guardar predicciones\n",
        "pred_out = pd.DataFrame({\n",
        "    \"y_true\": y_test.values,\n",
        "    \"y_pred\": y_pred\n",
        "})\n",
        "pred_out.to_csv(f\"{SAVE_DIR}/predicciones_positions.csv\", index=False)\n",
        "\n",
        "print(f\"\\nModelo guardado en: {SAVE_DIR}/linear_svc_positions.pkl\")\n",
        "print(f\"Predicciones guardadas en: {SAVE_DIR}/predicciones_positions.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bL2m8nNojXM"
      },
      "source": [
        "## 3. Predicciones de Seleccionados Nacionales para el Jere Klein [30 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2XmRsJdsEh_"
      },
      "source": [
        "<center>\n",
        "<img src='https://www.radioactiva.cl/wp-content/uploads/2024/04/Jere-Klein-1-768x432.webp' width=500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgmUoVDsqUPu"
      },
      "source": [
        "Despu√©s de alcanzar la fama como cantante urbano, Jere Klein decide explorar una nueva faceta. Con su amor por el f√∫tbol y convencido de que los artistas urbanos poseen un talento y versatilidad excepcionales, Jere se embarca en un proyecto innovador: desarrollar un sistema de inteligencia artificial capaz de identificar a jugadores que tienen potencial para convertirse en futbolistas profesionales. Su teor√≠a es que muchos artistas del g√©nero urbano chileno, con sus habilidades √∫nicas y su disciplina, podr√≠an destacarse tambi√©n en el deporte. Con este sistema, Jere espera no solo abrir nuevas oportunidades para sus colegas artistas, sino tambi√©n demostrar la amplia gama de talentos que pueden ofrecer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD8pQ5Zfq8dE"
      },
      "source": [
        "### 2.1 ¬øQu√© modelo de √°rbol es m√°s de \"pana\"? [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-KUA4g99eo"
      },
      "source": [
        "<center>\n",
        "<img src='https://64.media.tumblr.com/39189215a7d3d96823cb359f35b44e05/tumblr_psmrhrR3Xw1qf5hjqo4_540.gif' width=300 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL-moVhB9vPH"
      },
      "source": [
        "\n",
        "**Tareas**\n",
        "\n",
        "\n",
        "1. Considerando el la variable llamada `label` creada en la secci√≥n 1.1. Para determinar cu√°l modelo de √°rbol ser√≠a m√°s adecuado para la tarea en cuesti√≥n, utilice PyCaret. Este deber√° centrarse exclusivamente en modelos de tipo √°rbol. Jere ha especificado que busca un modelo que tome decisiones r√°pidamente y que tenga una baja tasa de falsos positivos, ya que planea invertir en estos jugadores. [3 puntos]\n",
        "\n",
        "Para la comparaci√≥n, utilice los siguientes modelos:\n",
        "\n",
        "```python\n",
        "['et', 'rf', 'dt', 'xgboost', 'lightgbm', 'catboost']\n",
        "```\n",
        "\n",
        "2. Explique en brevemente que son los modelos de la siguiente lista `['et', 'rf', 'dt']` y como funcionan. [3 punto]\n",
        "\n",
        "3. Tras realizar la comparaci√≥n de modelos, seleccione aquel que muestre el mejor rendimiento en t√©rminos de velocidad y precisi√≥n, especialmente en la reducci√≥n de falsos positivos. Utilice la funci√≥n `evaluate_model` de PyCaret para revisar y analizar los resultados obtenidos en los siguientes aspectos:\n",
        "\n",
        "  - **Confusi√≥n Matrix**: ¬øC√≥mo se encuentran la tasa de verdaderos positivos y verdaderos negativos?\n",
        "  - **Threshold**: ¬øEs acaso el umbral por defecto del modelo el mejor para las predicciones?\n",
        "  - **Feature Importance**: ¬øCu√°les son las variables con mejor desempe√±o? ¬øA qu√© podr√≠a deberse esto?\n",
        "  - **Learning Curve**: ¬øEl modelo presenta alg√∫n problema?\n",
        "\n",
        "  [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY85nrViYROF"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "kUCjOjsEYUXL",
        "outputId": "a36fcf4d-d659-49f1-d2e5-f998bd04770d"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pycaret'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1767138499.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PYCARET_CUSTOM_LOGGING_LEVEL\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"CRITICAL\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycaret'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from pycaret.classification import setup, compare_models, pull, get_config\n",
        "\n",
        "df_tree = data_copy.copy()\n",
        "ignore_cols = [c for c in [\"Club_Position\", \"Name\"] if c in df_tree.columns]\n",
        "\n",
        "clf_setup = setup(\n",
        "    data=df_tree,\n",
        "    target=\"label\",\n",
        "    session_id=42,\n",
        "    fold=3,\n",
        "    use_gpu=False,\n",
        "    verbose=False,\n",
        "    ignore_features=ignore_cols\n",
        ")\n",
        "\n",
        "tree_models = ['et', 'rf', 'dt', 'xgboost', 'lightgbm', 'catboost']\n",
        "best_tree = compare_models(include=tree_models, sort='Precision', turbo=True)\n",
        "\n",
        "results_compare = pull()\n",
        "display(results_compare)\n",
        "print(\"\\nMejor modelo seg√∫n 'Precision':\", best_tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ElPfMy_ZsDo"
      },
      "source": [
        "### pregunta 2\n",
        "\n",
        "['dt'] Decision Tree (√°rbol de decisi√≥n):\n",
        "- Modelo no lineal que particiona el espacio de features mediante reglas if-else.\n",
        "- Construye nodos que maximizan ganancia de informaci√≥n (p. ej., Gini/Entrop√≠a) hasta cierto criterio de parada.\n",
        "- Pros: interpretables, entrenan r√°pido, manejan mixtura de tipos, poca preparaci√≥n de datos.\n",
        "- Contras: tienden a sobreajustar si no se podan o regularizan (profundidad m√°xima, min_samples_leaf, etc.).\n",
        "\n",
        "['rf'] Random Forest (bosque aleatorio):\n",
        "- Ensamble de muchos √°rboles entrenados sobre bootstraps de los datos y subconjuntos aleatorios de features.\n",
        "- Promedia las predicciones (votaci√≥n) para reducir varianza del √°rbol individual.\n",
        "- Pros: robusto al overfitting, buen desempe√±o out-of-the-box, maneja no linealidades.\n",
        "- Contras: menos interpretable que un √°rbol √∫nico; tama√±o de modelo y tiempo de predicci√≥n mayores que DT.\n",
        "\n",
        "['et'] Extra Trees (Extremely Randomized Trees):\n",
        "- Similar a Random Forest, pero introduce m√°s aleatoriedad en los splits (umbrales elegidos al azar).\n",
        "- Suele reducir la varianza a√∫n m√°s y acelerar entrenamiento.\n",
        "- Pros: muy r√°pido en entrenamiento, buen rendimiento, menos varianza.\n",
        "- Contras: puede perder algo de precisi√≥n vs RF en algunos casos; interpretabilidad similar a RF.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRI4uxkPZkZh"
      },
      "outputs": [],
      "source": [
        "from pycaret.classification import evaluate_model, plot_model, predict_model, get_config, save_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# 1) Evaluaci√≥n interactiva\n",
        "evaluate_model(best_tree)\n",
        "\n",
        "# 2) Plots seguros (tambi√©n en multiclase)\n",
        "plot_model(best_tree, plot='confusion_matrix')\n",
        "plot_model(best_tree, plot='feature')\n",
        "plot_model(best_tree, plot='learning')\n",
        "\n",
        "# 2b) Plot de threshold SOLO si es binario\n",
        "y_train_pc = get_config('y_train')\n",
        "n_classes_train = y_train_pc.nunique() if hasattr(y_train_pc, \"nunique\") else len(np.unique(y_train_pc))\n",
        "if n_classes_train == 2:\n",
        "    plot_model(best_tree, plot='threshold')\n",
        "\n",
        "# 3) Predicci√≥n en holdout y reporte cl√°sico\n",
        "X_test_pc = get_config('X_test')\n",
        "y_test_pc = get_config('y_test')\n",
        "\n",
        "pred_test = predict_model(best_tree, data=X_test_pc)  # respeta el preprocesamiento interno\n",
        "# Compatibilidad PyCaret v3 (prediction_label) / v2 (Label)\n",
        "label_col = 'prediction_label' if 'prediction_label' in pred_test.columns else (\n",
        "    'Label' if 'Label' in pred_test.columns else None\n",
        ")\n",
        "if label_col is None:\n",
        "    raise ValueError(f\"No encontr√© la columna de predicci√≥n en predict_model(). \"\n",
        "                     f\"Columnas: {list(pred_test.columns)[:25]}\")\n",
        "\n",
        "y_true = np.asarray(y_test_pc)\n",
        "y_pred = pred_test[label_col].to_numpy()\n",
        "\n",
        "print(\"=== Classification report (holdout) ===\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "print(\"\\n=== Confusion Matrix (holdout) ===\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# 4) Ajuste de umbral para reducir falsos positivos (SOLO binario)\n",
        "classes = np.sort(np.unique(y_true))\n",
        "if len(classes) == 2:\n",
        "    pos_label = classes[-1]        # ajusta si tu clase positiva es la otra\n",
        "    neg_label = classes[0]\n",
        "\n",
        "    # Probabilidades por clase\n",
        "    proba_df = predict_model(best_tree, data=X_test_pc, raw_score=True)\n",
        "\n",
        "    # Columnas de probas = nuevas columnas que no son features ni columnas de predicci√≥n\n",
        "    exclude = set(X_test_pc.columns) | {label_col, 'prediction_score'}\n",
        "    proba_cols = [c for c in proba_df.columns if c not in exclude]\n",
        "\n",
        "    # Intenta identificar la columna de probas de la clase positiva\n",
        "    cand = [c for c in proba_cols\n",
        "            if str(c).lower() == str(pos_label).lower()\n",
        "            or str(c).lower().endswith(f\"_{str(pos_label).lower()}\")]\n",
        "\n",
        "    if cand:\n",
        "        scores = proba_df[cand[0]].to_numpy()\n",
        "        thr = 0.60  # umbral a tu criterio\n",
        "        y_pred_thr = np.where(scores >= thr, pos_label, neg_label)\n",
        "\n",
        "        print(f\"\\n=== M√©tricas con umbral {thr:.2f} (binario) ===\")\n",
        "        print(classification_report(y_true, y_pred_thr))\n",
        "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred_thr))\n",
        "    else:\n",
        "        print(\"\\n[Aviso] No se encontr√≥ columna de probabilidad para la clase positiva.\")\n",
        "        print(\"Revisa las columnas de proba detectadas:\", proba_cols[:10])\n",
        "\n",
        "# 5) Guardar el mejor modelo (incluye todo el pipeline de PyCaret)\n",
        "SAVE_DIR = \"/content/drive/MyDrive/data\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "save_path = save_model(best_tree, f\"{SAVE_DIR}/best_tree_pycaret\")  # generar√° un .pkl\n",
        "print(f\"\\nModelo guardado en: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8DSS3u1xMpB"
      },
      "source": [
        "### 2.2 Reducci√≥n de dimensionalidad [14 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLu0543p876P"
      },
      "source": [
        "<center>\n",
        "<img src='https://i.kym-cdn.com/photos/images/original/002/258/560/668.gif' width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT-bxJ0txwNF"
      },
      "source": [
        "A pesar de los resultados obtenidos previamente, el manager de Jere ha solicitado el entrenamiento de un modelo de XGBoost utilizando los datos disponibles. Adem√°s, se debe proceder a realizar una reducci√≥n de dimensionalidad basada en la importancia de las caracter√≠sticas.\n",
        "\n",
        "Para llevar a cabo esta tarea:\n",
        "\n",
        "1. Inicie entrenando un modelo XGBoost con todas las caracter√≠sticas disponibles. [2 puntos]\n",
        "\n",
        "2. Una vez el modelo est√© entrenado, eval√∫e y clasifique las caracter√≠sticas seg√∫n su importancia de forma descendente. [2 puntos]\n",
        "\n",
        "3. Utilice esta clasificaci√≥n para ejecutar una b√∫squeda recursiva de eliminaci√≥n de caracter√≠sticas, eliminando progresivamente las menos importantes y evaluando el impacto en el desempe√±o del modelo hasta identificar las N caracter√≠sticas m√°s cr√≠ticas. [2 puntos]\n",
        "\n",
        "4. Con este conjunto reducido de caracter√≠sticas, entrene un nuevo modelo y eval√∫e su rendimiento. [2 puntos]\n",
        "\n",
        "5. Posteriormente, responda a las siguientes preguntas para una comprensi√≥n m√°s profunda de los cambios y beneficios:\n",
        "\n",
        "  - ¬øEl rendimiento del modelo con las caracter√≠sticas seleccionadas es similar al del modelo original? ¬øC√≥mo se comparan en t√©rminos de precisi√≥n y robustez? [2 puntos]\n",
        "  - ¬øCu√°les son los beneficios potenciales de eliminar variables del modelo? Considere factores como la simplificaci√≥n del modelo, reducci√≥n del tiempo de entrenamiento, y mejora en la capacidad de generalizaci√≥n. [2 puntos]\n",
        "  - Comente si el modelo con menor dimensionalidad es m√°s sencillo de explicar. Explique brevemente por qu√© la eliminaci√≥n de ciertas caracter√≠sticas puede facilitar la comprensi√≥n y la explicaci√≥n del comportamiento del modelo. [2 puntos]\n",
        "\n",
        "Notar que con esta metodologia buscamos encontrar un punto entermedio entre n√∫mero de festures y desempe√±o. por esto, si observa que al aumentar festires el aumento es despreciable, puede no considerar agregar m√°s features a su modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHfmK63TuDOS"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQwUd_nsuDOe"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Datos\n",
        "df = data_copy.copy()\n",
        "X = df.drop(columns=[\"Club_Position\", \"label\"])\n",
        "y = df[\"label\"].copy()\n",
        "\n",
        "# Columnas por tipo\n",
        "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = [c for c in [\"National_Position\", \"Preffered_Foot\", \"Work_Rate\"] if c in X.columns]\n",
        "\n",
        "# Preprocesamiento\n",
        "num_pipe = Pipeline([\n",
        "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"sc\", StandardScaler())\n",
        "])\n",
        "cat_pipe = Pipeline([\n",
        "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
        "])\n",
        "\n",
        "col_transformer_full = ColumnTransformer(\n",
        "    [(\"num\", num_pipe, num_cols),\n",
        "     (\"cat\", cat_pipe, cat_cols)],\n",
        "    verbose_feature_names_out=True\n",
        ")\n",
        "\n",
        "# Split estratificado\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, train_size=0.7, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# === CORRECCI√ìN: encodear y para XGBoost ===\n",
        "le_y = LabelEncoder()\n",
        "y_train_enc = le_y.fit_transform(y_train)   # entero 0..K-1\n",
        "y_test_enc  = le_y.transform(y_test)\n",
        "n_classes = len(le_y.classes_)\n",
        "is_binary  = (n_classes == 2)\n",
        "\n",
        "# XGBoost seg√∫n #clases\n",
        "xgb = XGBClassifier(\n",
        "    objective=\"binary:logistic\" if is_binary else \"multi:softprob\",\n",
        "    num_class=None if is_binary else n_classes,\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    tree_method=\"hist\",\n",
        "    eval_metric=\"logloss\" if is_binary else \"mlogloss\"\n",
        ")\n",
        "\n",
        "pipeline_xgb_full = Pipeline([\n",
        "    (\"col_transformer\", col_transformer_full),\n",
        "    (\"xgb\", xgb)\n",
        "])\n",
        "\n",
        "# Entrenar (con y encodeado)\n",
        "pipeline_xgb_full.fit(X_train, y_train_enc)\n",
        "\n",
        "# Evaluar (pred en enteros y luego volver a texto para el reporte)\n",
        "y_pred_enc  = pipeline_xgb_full.predict(X_test)\n",
        "y_pred_txt  = le_y.inverse_transform(y_pred_enc)\n",
        "\n",
        "print(\"=== XGBoost (todas las features) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_txt))\n",
        "print(classification_report(y_test, y_pred_txt))\n",
        "\n",
        "# Guardar para siguientes pasos\n",
        "X_train_full, X_test_full, y_train_full, y_test_full = X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh-_boATZ_Zv"
      },
      "source": [
        "**Pregunta 2:** Una vez el modelo est√© entrenado, eval√∫e y clasifique las caracter√≠sticas seg√∫n su importancia de forma descendente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjLvBGQxZ8T4"
      },
      "outputs": [],
      "source": [
        "# Obtener nombres de columnas transformadas\n",
        "feature_names = pipeline_xgb_full.named_steps[\"col_transformer\"].get_feature_names_out()\n",
        "\n",
        "# Importancia por features transformadas\n",
        "importances = pipeline_xgb_full.named_steps[\"xgb\"].feature_importances_\n",
        "imp_df = pd.DataFrame({\"feature\": feature_names, \"importance\": importances}).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "# Agregar importancias por columna original\n",
        "cat_cols_set = set(cat_cols)\n",
        "def base_col(name):\n",
        "    clean = name.split(\"__\", 1)[-1]\n",
        "    for c in cat_cols_set:\n",
        "        if clean.startswith(c + \"_\") or clean == c:\n",
        "            return c\n",
        "    return clean\n",
        "\n",
        "imp_df[\"base\"] = imp_df[\"feature\"].map(base_col)\n",
        "agg_imp = (imp_df.groupby(\"base\", as_index=False)\n",
        "                  .agg(total_importance=(\"importance\", \"sum\"))\n",
        "                  .sort_values(\"total_importance\", ascending=False)\n",
        "          )\n",
        "\n",
        "print(\"Top 20 features transformadas:\\n\", imp_df.head(20), \"\\n\")\n",
        "print(\"Top 20 columnas base (agregadas):\\n\", agg_imp.head(20))\n",
        "\n",
        "# Guardar para el paso 3\n",
        "imp_df_full = imp_df.copy()\n",
        "agg_imp_full = agg_imp.copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWp9IfkbaCBf"
      },
      "source": [
        "**Pregunta 3:** Utilice esta clasificaci√≥n para ejecutar una b√∫squeda recursiva de eliminaci√≥n de caracter√≠sticas, eliminando progresivamente las menos importantes y evaluando el impacto en el desempe√±o del modelo hasta identificar las N caracter√≠sticas m√°s cr√≠ticas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcuGpLslaHJV"
      },
      "outputs": [],
      "source": [
        "# Eliminaci√≥n progresiva (RFE manual por ranking)\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# --- Prepara/recupera el encoding del target (NUM√âRICO) ---\n",
        "try:\n",
        "    le_y_global\n",
        "    y_train_full_enc\n",
        "    y_test_full_enc\n",
        "    n_classes\n",
        "except NameError:\n",
        "    le_y_global = LabelEncoder()\n",
        "    y_train_full_enc = le_y_global.fit_transform(y_train_full)  # usa y_train_full (texto) ya definido\n",
        "    y_test_full_enc  = le_y_global.transform(y_test_full)\n",
        "    n_classes = len(le_y_global.classes_)\n",
        "is_binary = (n_classes == 2)\n",
        "pos_label_enc = (le_y_global.transform([le_y_global.classes_[-1]])[0] if is_binary else None)\n",
        "\n",
        "# --- Orden base de features por importancia (asumido existente) ---\n",
        "ordered_base = agg_imp_full[\"base\"].tolist()\n",
        "\n",
        "# Rango de K a evaluar\n",
        "K_list = list(range(min(5, len(ordered_base)), min(len(ordered_base), 40)+1, 5))\n",
        "results = []\n",
        "\n",
        "for K in K_list:\n",
        "    keep_base = set(ordered_base[:K])\n",
        "\n",
        "    # Filtrar columnas num/cat a conservar\n",
        "    keep_num = [c for c in num_cols if c in keep_base]\n",
        "    keep_cat = [c for c in cat_cols if c in keep_base]\n",
        "\n",
        "    # ColumnTransformer reducido\n",
        "    num_pipe_k = Pipeline([\n",
        "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"sc\", StandardScaler())\n",
        "    ])\n",
        "    cat_pipe_k = Pipeline([\n",
        "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
        "    ])\n",
        "\n",
        "    col_transformer_k = ColumnTransformer(\n",
        "        [(\"num\", num_pipe_k, keep_num),\n",
        "         (\"cat\", cat_pipe_k, keep_cat)],\n",
        "        verbose_feature_names_out=True\n",
        "    )\n",
        "\n",
        "    # Modelo XGB coherente con #clases (usa SIEMPRE y codificado)\n",
        "    if is_binary:\n",
        "        xgb_k = XGBClassifier(\n",
        "            objective=\"binary:logistic\",\n",
        "            n_estimators=300, learning_rate=0.05, max_depth=6,\n",
        "            subsample=0.8, colsample_bytree=0.8,\n",
        "            random_state=42, n_jobs=-1, tree_method=\"hist\", eval_metric=\"logloss\"\n",
        "        )\n",
        "        avg_prec = dict(average=\"binary\", pos_label=pos_label_enc)\n",
        "    else:\n",
        "        xgb_k = XGBClassifier(\n",
        "            objective=\"multi:softprob\", num_class=n_classes,\n",
        "            n_estimators=300, learning_rate=0.05, max_depth=6,\n",
        "            subsample=0.8, colsample_bytree=0.8,\n",
        "            random_state=42, n_jobs=-1, tree_method=\"hist\", eval_metric=\"mlogloss\"\n",
        "        )\n",
        "        avg_prec = dict(average=\"macro\")\n",
        "\n",
        "    pipe_k = Pipeline([\n",
        "        (\"col_transformer\", col_transformer_k),\n",
        "        (\"xgb\", xgb_k)\n",
        "    ])\n",
        "\n",
        "    # Entrenar (con y codificado)\n",
        "    t0 = time.perf_counter()\n",
        "    pipe_k.fit(X_train_full, y_train_full_enc)\n",
        "    t1 = time.perf_counter()\n",
        "\n",
        "    # Predecir (codificado) y m√©tricas\n",
        "    y_pred_enc = pipe_k.predict(X_test_full)\n",
        "\n",
        "    acc = accuracy_score(y_test_full_enc, y_pred_enc)\n",
        "    prec = precision_score(y_test_full_enc, y_pred_enc, **avg_prec, zero_division=0)\n",
        "    f1   = f1_score(y_test_full_enc, y_pred_enc, average=\"macro\", zero_division=0)\n",
        "    dur  = t1 - t0\n",
        "\n",
        "    results.append({\n",
        "        \"K\": K,\n",
        "        \"features_kept\": K,\n",
        "        \"train_time_s\": round(dur, 3),\n",
        "        \"accuracy\": round(acc, 4),\n",
        "        \"precision\": round(prec, 4),\n",
        "        \"f1_macro\": round(f1, 4),\n",
        "        \"keep_num\": keep_num,\n",
        "        \"keep_cat\": keep_cat\n",
        "    })\n",
        "\n",
        "# Tabla de resultados\n",
        "res_df = pd.DataFrame(results).sort_values(\n",
        "    [\"precision\", \"accuracy\", \"train_time_s\"],\n",
        "    ascending=[False, False, True]\n",
        ").reset_index(drop=True)\n",
        "\n",
        "print(\"=== Resultados por K (ordenado por precisi√≥n, luego accuracy y tiempo) ===\")\n",
        "display(res_df.head(10))\n",
        "\n",
        "# Mejor K seg√∫n criterio\n",
        "best_row = res_df.iloc[0]\n",
        "K_best = int(best_row[\"K\"])\n",
        "keep_num_best = best_row[\"keep_num\"]\n",
        "keep_cat_best = best_row[\"keep_cat\"]\n",
        "print(f\"\\nK* elegido = {K_best}\\nNum: {keep_num_best}\\nCat: {keep_cat_best}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6joPhJoaJmO"
      },
      "source": [
        "**Pregunta 4:** Con este conjunto reducido de caracter√≠sticas, entrene un nuevo modelo y eval√∫e su rendimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPLQ6k8IaOzU"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from xgboost import XGBClassifier\n",
        "import numpy as np\n",
        "\n",
        "# ========= Asegurar encoding del target =========\n",
        "try:\n",
        "    le_y_global\n",
        "    y_train_full_enc\n",
        "    y_test_full_enc\n",
        "    n_classes\n",
        "except NameError:\n",
        "    le_y_global = LabelEncoder()\n",
        "    y_train_full_enc = le_y_global.fit_transform(y_train_full)  # y_train_full en TEXTO -> enteros\n",
        "    y_test_full_enc  = le_y_global.transform(y_test_full)\n",
        "    n_classes = len(le_y_global.classes_)\n",
        "\n",
        "is_binary = (n_classes == 2)\n",
        "pos_label_text = le_y_global.classes_[-1]         # cambia si tu clase positiva es otra\n",
        "pos_label_enc  = le_y_global.transform([pos_label_text])[0]\n",
        "\n",
        "# ========= ColumnTransformer (con las mejores features) =========\n",
        "num_pipe_best = Pipeline([\n",
        "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"sc\", StandardScaler())\n",
        "])\n",
        "cat_pipe_best = Pipeline([\n",
        "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
        "])\n",
        "\n",
        "col_transformer_best = ColumnTransformer(\n",
        "    [(\"num\", num_pipe_best, keep_num_best),\n",
        "     (\"cat\", cat_pipe_best, keep_cat_best)],\n",
        "    verbose_feature_names_out=True\n",
        ")\n",
        "\n",
        "# ========= Modelo XGBoost seg√∫n #clases =========\n",
        "xgb_best = XGBClassifier(\n",
        "    objective=\"binary:logistic\" if is_binary else \"multi:softprob\",\n",
        "    num_class=None if is_binary else n_classes,\n",
        "    n_estimators=300, learning_rate=0.05, max_depth=6,\n",
        "    subsample=0.8, colsample_bytree=0.8,\n",
        "    random_state=42, n_jobs=-1, tree_method=\"hist\",\n",
        "    eval_metric=\"logloss\" if is_binary else \"mlogloss\"\n",
        ")\n",
        "\n",
        "pipeline_xgb_reduced = Pipeline([\n",
        "    (\"col_transformer\", col_transformer_best),\n",
        "    (\"xgb\", xgb_best)\n",
        "])\n",
        "\n",
        "# ========= ENTRENAR SIEMPRE CON y ENCODEADO =========\n",
        "pipeline_xgb_reduced.fit(X_train_full, y_train_full_enc)\n",
        "\n",
        "# ========= Predicci√≥n y reporte (volver a TEXTO para legibilidad) =========\n",
        "y_pred_red_enc = pipeline_xgb_reduced.predict(X_test_full)\n",
        "y_pred_red_txt = le_y_global.inverse_transform(y_pred_red_enc)\n",
        "\n",
        "print(\"=== XGBoost (conjunto reducido) ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_full, y_pred_red_txt))\n",
        "print(classification_report(y_test_full, y_pred_red_txt))\n",
        "print(\"\\n=== Matriz de confusi√≥n (reducido) ===\")\n",
        "print(confusion_matrix(y_test_full, y_pred_red_txt))\n",
        "\n",
        "# ========= Comparaci√≥n r√°pida con el modelo completo =========\n",
        "# Intentamos usar y_pred_full si ya existe; si no, lo recomputamos si existe pipeline_xgb_full\n",
        "def _ensure_text_preds(y_pred_any):\n",
        "    \"\"\"Convierte predicciones a texto si vienen en enteros; si ya son texto, las deja igual.\"\"\"\n",
        "    y_pred_any = np.asarray(y_pred_any)\n",
        "    if y_pred_any.dtype.kind in \"iu\":  # ints -> a texto con el mismo encoder\n",
        "        return le_y_global.inverse_transform(y_pred_any)\n",
        "    return y_pred_any  # ya es texto\n",
        "\n",
        "y_pred_full_text = None\n",
        "\n",
        "if \"y_pred_full\" in globals() or \"y_pred_full\" in locals():\n",
        "    try:\n",
        "        y_pred_full_text = _ensure_text_preds(y_pred_full)\n",
        "    except Exception:\n",
        "        y_pred_full_text = None\n",
        "\n",
        "if y_pred_full_text is None and (\"pipeline_xgb_full\" in globals() or \"pipeline_xgb_full\" in locals()):\n",
        "    try:\n",
        "        y_pred_full_enc2 = pipeline_xgb_full.predict(X_test_full)\n",
        "        y_pred_full_text = _ensure_text_preds(y_pred_full_enc2)\n",
        "    except Exception:\n",
        "        y_pred_full_text = None\n",
        "\n",
        "# C√°lculo de precisi√≥n (macro para multiclase; en binario usa tu positiva expl√≠cita)\n",
        "if y_pred_full_text is not None:\n",
        "    avg_full = dict(average=\"macro\") if n_classes > 2 else dict(average=\"binary\", pos_label=pos_label_text)\n",
        "    avg_red  = avg_full\n",
        "\n",
        "    prec_full = precision_score(y_test_full, y_pred_full_text, **avg_full, zero_division=0)\n",
        "    prec_red  = precision_score(y_test_full, y_pred_red_txt,  **avg_red,  zero_division=0)\n",
        "\n",
        "    modo = \"macro\" if n_classes > 2 else f\"binary (pos='{pos_label_text}')\"\n",
        "    print(f\"\\nPrecisi√≥n [{modo}] - Full: {prec_full:.4f} | Reducido: {prec_red:.4f}\")\n",
        "else:\n",
        "    print(\"\\n[Aviso] No encontr√© 'y_pred_full' ni 'pipeline_xgb_full' para comparar precisi√≥n con el modelo full.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc1KhDdmaQKH"
      },
      "source": [
        "**Pregunta 5:** Posteriormente, responda a las siguientes preguntas para una comprensi√≥n m√°s profunda de los cambios y beneficios:\n",
        "\n",
        "  - ¬øEl rendimiento del modelo con las caracter√≠sticas seleccionadas es similar al del modelo original? ¬øC√≥mo se comparan en t√©rminos de precisi√≥n y robustez?\n",
        "  - ¬øCu√°les son los beneficios potenciales de eliminar variables del modelo? Considere factores como la simplificaci√≥n del modelo, reducci√≥n del tiempo de entrenamiento, y mejora en la capacidad de generalizaci√≥n.\n",
        "  - Comente si el modelo con menor dimensionalidad es m√°s sencillo de explicar. Explique brevemente por qu√© la eliminaci√≥n de ciertas caracter√≠sticas puede facilitar la comprensi√≥n y la explicaci√≥n del comportamiento del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ8C7Tu4aSf4"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTG5cH9r3M9g"
      },
      "source": [
        "### 2.3 Calibraci√≥n Probabilistica [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDL0VqjR7yvb"
      },
      "source": [
        "<center>\n",
        "<img src='https://media2.giphy.com/media/l2Je4Ku0Cx292KWv6/200w.gif?cid=6c09b952y0sihtq9tb6sz8j2023x3zxxp3qx1ocgonkpkblj&ep=v1_gifs_search&rid=200w.gif&ct=g' width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmOKxhAw3sic"
      },
      "source": [
        "Para lograr modelos m√°s modulares, se recomienda realizar una calibraci√≥n del modelo entrenado anteriormente, con el objetivo de obtener salidas que reflejen mayor modularidad.\n",
        "\n",
        "1. Se solicita que utilice un m√©todo de calibraci√≥n que asegure que las probabilidades generadas incrementen de manera mon√≥tona. Una m√©trica ampliamente utilizada para evaluar la precisi√≥n de la calibraci√≥n de un modelo es el Brier Score. Calcule el Brier Score para el modelo tanto antes como despu√©s de la calibraci√≥n. Esto le permitir√° realizar una comparaci√≥n cuantitativa y determinar si la calibraci√≥n ha mejorado el rendimiento del modelo. Para m√°s informaci√≥n sobre el Brier Score, puede consultar el siguiente enlace: [Scikit-Learn - Brier Score Loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html). [3 puntos]\n",
        "\n",
        "2. Tras la calibraci√≥n, examine y comente los resultados obtenidos. A su an√°lisis a√±ada una comparaci√≥n visual de las ideales versus las salidas del modelo original (sin calibrar) y del modelo calibrado. [3 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIiYz_qLuD19"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co7C-I3Rae7V"
      },
      "source": [
        "### pregunta 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0bfSuiFuD2I"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "from sklearn.metrics import brier_score_loss\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "## me tira error porque en la varaible dependiente hay categoricas, no numeros discretos.\n",
        "\n",
        "# Probabilidades del modelo original\n",
        "proba_orig = pipeline_xgb_full.predict_proba(X_test_full)\n",
        "\n",
        "classes = np.array(sorted(pd.Series(y_train_full).unique()))\n",
        "n_classes = len(classes)\n",
        "\n",
        "def brier_multiclass(y_true, proba, classes):\n",
        "    \"\"\"Promedia Brier one-vs-rest por clase (m√°s com√∫n en pr√°ctica).\"\"\"\n",
        "    Y = label_binarize(y_true, classes=classes)\n",
        "    if Y.shape[1] == 1 and proba.ndim == 1:\n",
        "        return brier_score_loss(Y.ravel(), proba.ravel())\n",
        "    if proba.ndim == 1:\n",
        "        proba = np.c_[1 - proba, proba]\n",
        "    scores = []\n",
        "    for k in range(len(classes)):\n",
        "        scores.append(brier_score_loss(Y[:, k], proba[:, k]))\n",
        "    return float(np.mean(scores))\n",
        "\n",
        "# Brier antes\n",
        "if n_classes == 2:\n",
        "    pos_idx = int(np.where(classes == classes.max())[0])\n",
        "    brier_before = brier_score_loss((y_test_full == classes[pos_idx]).astype(int), proba_orig[:, pos_idx])\n",
        "else:\n",
        "    brier_before = brier_multiclass(y_test_full, proba_orig, classes)\n",
        "\n",
        "print(f\"Brier score (ANTES, modelo original): {brier_before:.6f}\")\n",
        "\n",
        "# Construir pipeline calibrado\n",
        "base_xgb_params = pipeline_xgb_full.named_steps[\"xgb\"].get_params()\n",
        "base_xgb = XGBClassifier(**base_xgb_params)\n",
        "\n",
        "pipeline_xgb_calibrated = Pipeline([\n",
        "    (\"col_transformer\", deepcopy(col_transformer_full)),\n",
        "    (\"cal\", CalibratedClassifierCV(\n",
        "        estimator=base_xgb,\n",
        "        method=\"isotonic\",\n",
        "        cv=5\n",
        "    ))\n",
        "])\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train_full)\n",
        "y_test_enc = le.transform(y_test_full)\n",
        "\n",
        "# Entrenar calibrado en el conjunto de entrenamiento\n",
        "pipeline_xgb_calibrated.fit(X_train_full, y_train_enc) # ac√° cambio y_train_full por y_test_enc\n",
        "\n",
        "# Probabilidades calibradas y Brier despu√©s\n",
        "proba_cal = pipeline_xgb_calibrated.predict_proba(X_test_full)\n",
        "\n",
        "if n_classes == 2:\n",
        "    pos_idx = int(np.where(classes == classes.max())[0])\n",
        "    brier_after = brier_score_loss((y_test_full == classes[pos_idx]).astype(int), proba_cal[:, pos_idx])\n",
        "else:\n",
        "    brier_after = brier_multiclass(y_test_full, proba_cal, classes)\n",
        "\n",
        "print(f\"Brier score (DESPU√âS, calibrado isotonic): {brier_after:.6f}\")\n",
        "\n",
        "# tabla resumen\n",
        "res_brier = pd.DataFrame({\n",
        "    \"modelo\": [\"original\", \"calibrado_isotonic\"],\n",
        "    \"brier_score\": [brier_before, brier_after]\n",
        "})\n",
        "print(\"\\nResumen Brier:\\n\", res_brier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z3lx879acu5"
      },
      "source": [
        "### pregunta 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOm_Z-VdaaK_"
      },
      "outputs": [],
      "source": [
        "from sklearn.calibration import CalibrationDisplay\n",
        "\n",
        "\n",
        "classes = np.array(sorted(pd.Series(y_train_full).unique()))\n",
        "n_classes = len(classes)\n",
        "\n",
        "def plot_binary_calibration(y_true, proba_orig, proba_cal, pos_label):\n",
        "    y_bin = (y_true == pos_label).astype(int)\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    ax.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Ideal\")\n",
        "    CalibrationDisplay.from_predictions(y_bin, proba_orig, n_bins=10, name=\"Original\", ax=ax)\n",
        "    CalibrationDisplay.from_predictions(y_bin, proba_cal,  n_bins=10, name=\"Calibrado (Isotonic)\", ax=ax)\n",
        "    ax.set_title(f\"Calibration curve (pos_label={pos_label})\")\n",
        "    ax.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_multiclass_calibration(y_true, proba_orig, proba_cal, classes, max_plots=6):\n",
        "    to_plot = classes[:min(len(classes), max_plots)]\n",
        "    for c in to_plot:\n",
        "        y_bin = (y_true == c).astype(int)\n",
        "        fig, ax = plt.subplots(figsize=(6, 5))\n",
        "        ax.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Ideal\")\n",
        "        CalibrationDisplay.from_predictions(y_bin, proba_orig[:, np.where(classes==c)[0][0]],\n",
        "                                            n_bins=10, name=\"Original\", ax=ax)\n",
        "        CalibrationDisplay.from_predictions(y_bin, proba_cal[:,  np.where(classes==c)[0][0]],\n",
        "                                            n_bins=10, name=\"Calibrado (Isotonic)\", ax=ax)\n",
        "        ax.set_title(f\"Calibration curve (clase = {c})\")\n",
        "        ax.legend(loc=\"best\")\n",
        "        plt.show()\n",
        "\n",
        "if n_classes == 2:\n",
        "    pos_label = classes.max()\n",
        "    plot_binary_calibration(\n",
        "        y_true=y_test_full,\n",
        "        proba_orig=proba_orig[:, np.where(classes==pos_label)[0][0]],\n",
        "        proba_cal= proba_cal[:,  np.where(classes==pos_label)[0][0]],\n",
        "        pos_label=pos_label\n",
        "    )\n",
        "else:\n",
        "    plot_multiclass_calibration(\n",
        "        y_true=y_test_full,\n",
        "        proba_orig=proba_orig,\n",
        "        proba_cal=proba_cal,\n",
        "        classes=classes,\n",
        "        max_plots=6\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW4ua_Gm2t7k"
      },
      "source": [
        "Mucho √©xito!\n",
        "\n",
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/55/3d/42/553d42bea9b10e0662a05aa8726fc7f4.gif\" width=300>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "k-ao0mOU64Ru",
        "Jg_9jBqtgRDO",
        "JdcucZhp-M_0",
        "Qfre1YsSDqla",
        "Bv1HOfcNEPF4",
        "poc9HSNBFeKO",
        "uy5VMU6ae_g6",
        "9bL2m8nNojXM",
        "rD8pQ5Zfq8dE",
        "K8DSS3u1xMpB",
        "PTG5cH9r3M9g"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "27f7193e8435d5833318a8779fcc7c01e1e51279cdc9a1fc598f78d31f0d2dc3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
